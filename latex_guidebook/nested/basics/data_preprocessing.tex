\section{Data Pre-processing}

\textcolor{blue}{Data is rarely obtained in a form that is necessary for optimal performance of a learning algorithm. Data can be missing, can contain a mix of categorical and quantitative, can contain values on vastly different scales, etc.}

\textcolor{blue}{It is important to note that any parameters related to data pre-processing, such as feature scaling and dimensionality reduction, are obtained solely from observing the training set. The parameters for these methods obtained on the training set are then later applied to the test set. This is important since if these preprocessing parameters were obtained on the entire dataset and included the test set, the the model performance may be overoptimistic since then when applying the methods to the unseen data.}

\subsection{Handling Missing Data}

\subsubsection{Filtering Out}

\textcolor{blue}{Simply removing any entries that are missing data. This is convenient and easy but may not be practical -- any time data is being removed, potentially useful information is lost and too much data may be removed.}

\textcolor{green}{TODO: Code in jupyter on how to do this with pandas and dropna -- key params - how, thresh, subset}

\subsubsection{Filling In}

\textcolor{blue}{Estimating the missing data}

\subsection{Handling Categorical Data}

\subsubsection{Encoding}

\subsection{Feature Scaling, Normalization}

\subsubsection{Min-Max scaling (Normalization)}

\textcolor{blue}{values are shifted and rescaled so they end up on a [0,1] range}

\subsubsection{Standardization}

\textcolor{blue}{(Eq.~\ref{eq:preprocess_standardization}) first, subtract the sample mean, then divide by standard deviation variance}

\textcolor{blue}{pros: unlike min-max, not bound to specific range}

\textcolor{blue}{standardized values always have a zero mean and a standard deviation of 1.}

\textcolor{blue}{gives our data the property of a standard normal distribution}

\begin{equation}
{X' = \frac{X - \mu}{\sigma}}
\label{eq:preprocess_standardization}
\end{equation}

\textcolor{green}{TODO: create code sample - numpy, and sklearn methods}


\subsection{Others}

\subsubsection{Removing Duplicates}

\subsubsection{Outliers}

\subsubsection{Discretization and Binning}
