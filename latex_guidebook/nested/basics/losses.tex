
\section{losses}

% TODO: not sure where this section belongs
% TODO: It would maybe make sense to have an appendix section that covers the common losses

% potentially ``irrelvant''/~uninterpretible in value to the researcher

\subsection{fit somewhere}

\subsubsection{Contrastive Losses}

\TD{link to secion on self-supervised learning}



\subsection{Overview}

\r{training objective -- continuous}

\subsection{Losses}

\TD{ELBO (Evidence Lower BOund)}

% TODO: index
\TD{Squared logarithmic error (SLE) and Mean SLE (MSLE)}
\TD{Root Mean Squared logarithmic error (RMSLE) and Mean RMSLE (RMSLE)}
\TD{Mean Absolute Percentage Error (MAPE)}


\subsubsection{scalar}

\subsubsection{distribution}


% label smoothing
\subsection{label smoothing}
\TD{Label smoothing}
\TD{When Does Label Smoothing Help? \cite{DBLP:journals/corr/abs-1906-02629}}
\TD{Regularizing Neural Networks by Penalizing Confident Output Distributions \cite{DBLP:journals/corr/PereyraTCKH17}}

