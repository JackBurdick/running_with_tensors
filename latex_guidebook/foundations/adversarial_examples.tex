
\chapter{Adversarial Machine Learning}
%TODO: I'm not convinced this is the right location for this section

\TD{survey \TD{Adversarial Attacks and Defences: {A \cite{DBLP:journals/corr/abs-1810-00069}}}}

\TD{a bit cat and mouse}

% TODO: common attacks and defences

% TODO: robustness

\r{Adversarial Machine Learning, or adversarial ML, is .....}


\r{sometimes refered to as ``optical illusions'' for AI}


\r{adversarial input or ``adversarial example'' as first refered to as by \TD{Intriguing properties of neural networks \cite{Szegedy2014IntriguingPO}}}

\TD{follow up to original \TD{Explaining and Harnessing Adversarial Examples \cite{Goodfellow2015ExplainingAH}}}

\r{other extreme, labeling human unrecognizable images confidently \TD{Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images \cite{DBLP:journals/corr/NguyenYC14}}}

\TD{\cite{papernot2018deep}}

\TD{Towards Evaluating the Robustness of Neural Networks \cite{DBLP:journals/corr/CarliniW16a}}

\TD{Towards Deep Learning Models Resistant to Adversarial Attacks \cite{Madry2018TowardsDL}}

\section{Attacks}

\TD{section on attacks}

\TD{single pixel attack}

\section{Defenses}

\TD{section on defenses}

\r{possible first \TD{Towards Deep Neural Network Architectures Robust to Adversarial Examples \cite{Gu2015TowardsDN}}}

\section{Implications}

\TD{section on implications}