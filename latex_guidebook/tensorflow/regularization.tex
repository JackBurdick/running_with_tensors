\subsection{Regularization}

% TODO: this section/file may belong in basics, not here

\textcolor{blue}{Collection of techniques used to help generalize a model -- which may help prevent overfitting. Typically regularization penalizes complexity of a model.}

% TODO: figure of loss plot showing a steep training and shallow+divergent val/test loss

\textcolor{blue}{Helps prevent the model from memorizing noise in the training data.}


\subsubsection{Why Regularization}

\textcolor{blue}{Overfitting --- too complex --- Occam's razor --- hypothesis with the fewest assumptions is best}


\subsubsection{Types of Regularization}

\textcolor{blue}{Regularization is an active area of research.}

\begin{itemize}
	\item Early Stopping
	\item Parameter Norm Penalties
	\begin{itemize}
		\item L1 regularization
		\item L2 regularization
	\end{itemize}
	\item Dataset Augmentation
	\item Noise Robustness
	\item Sparse Representations
\end{itemize}


\textcolor{blue}{L1 regularization (Lasso) L2 (Ridge).}

\textcolor{blue}{key difference is the penalty term}


\subsubsection{Regularization Methods and Implementations}

\paragraph{L2 Regularization}

\textcolor{blue}{Ridge regression is also known as {Tikhonov regularization}\index{Tikhonov regularization}}

\textcolor{blue}{penalizes model parameters that become too large. Will force most of the parameters to be small, but still non-zero}

% p91(71) of mastering ML w SKL says "when lambda is equal to zero, ridge regression is equal to linear regression"

\paragraph{L1 Regularization}

\textcolor{blue}{LASSO (Least Absolute Shrinkage and Selection Operator) --- produces sparse parameters. This will force coefficients to zero and cause the model to depend on a small subset of the features.}


\paragraph{Elastic Net Regularization}

\textcolor{blue}{Linearly combines the $L^1$ and $L^2$ penalties used by both LASSO and ridge regression.}



% TODO: this may not belong here...
\subsubsection{Normalization}

\textcolor{blue}{TODO: overview para + importance}

\textcolor{green}{TODO: figure showing differences}

\paragraph{Instance normalization}

\textcolor{blue}{see section in preprocessing \textcolor{red}{local ref?}}

\paragraph{Layer normalization}

\paragraph{Batch normalization}

\paragraph{Group normalization}