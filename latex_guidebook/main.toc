\contentsline {part}{I\hspace {1em}Background}{1}
\contentsline {chapter}{\numberline {1}Introduction}{3}
\contentsline {section}{\numberline {1.1}Motivation for this text}{3}
\contentsline {section}{\numberline {1.2}What}{3}
\contentsline {subsection}{\numberline {1.2.1}Rule based vs ``learning''}{4}
\contentsline {subsection}{\numberline {1.2.2}High Level Overview}{4}
\contentsline {subsection}{\numberline {1.2.3}Deep Learning}{4}
\contentsline {subsubsection}{\numberline {1.2.3.1}Why Now?}{4}
\contentsline {section}{\numberline {1.3}Why ML}{6}
\contentsline {section}{\numberline {1.4}Notes}{6}
\contentsline {subsection}{\numberline {1.4.1}Target Audience}{6}
\contentsline {subsection}{\numberline {1.4.2}How to Read this Book}{6}
\contentsline {chapter}{\numberline {2}Resources and Communities}{7}
\contentsline {section}{\numberline {2.1}Online Communities}{7}
\contentsline {section}{\numberline {2.2}Blogs}{7}
\contentsline {section}{\numberline {2.3}Online Courses}{7}
\contentsline {section}{\numberline {2.4}Text Books}{7}
\contentsline {chapter}{\numberline {3}Prerequisites}{9}
\contentsline {section}{\numberline {3.1}Math Notation}{9}
\contentsline {section}{\numberline {3.2}Calculus}{9}
\contentsline {subsection}{\numberline {3.2.1}Derivatives}{11}
\contentsline {subsection}{\numberline {3.2.2}Chain Rule}{12}
\contentsline {section}{\numberline {3.3}Boolean Logic}{12}
\contentsline {section}{\numberline {3.4}Linear Algebra}{12}
\contentsline {subsection}{\numberline {3.4.1}Overview}{12}
\contentsline {subsubsection}{\numberline {3.4.1.1}Scalars (0D tensors)}{12}
\contentsline {subsubsection}{\numberline {3.4.1.2}Vectors (1D tensors)}{12}
\contentsline {subsubsection}{\numberline {3.4.1.3}Matrices (2D tensors)}{13}
\contentsline {subsection}{\numberline {3.4.2}Matrix Arithmetic}{13}
\contentsline {subsubsection}{\numberline {3.4.2.1}Matrices}{13}
\contentsline {paragraph}{\numberline {3.4.2.1.1}Addition, Subtraction}{13}
\contentsline {paragraph}{\numberline {3.4.2.1.2}Multiplication, Division}{13}
\contentsline {subsubsection}{\numberline {3.4.2.2}Scalar}{13}
\contentsline {paragraph}{\numberline {3.4.2.2.1}Addition, Subtraction}{13}
\contentsline {paragraph}{\numberline {3.4.2.2.2}Multiplication, Division}{13}
\contentsline {section}{\numberline {3.5}Graph Theory}{13}
\contentsline {part}{II\hspace {1em}Data}{15}
\contentsline {section}{\numberline {3.6}Bias}{18}
\contentsline {subsection}{\numberline {3.6.1}Types of Bias}{18}
\contentsline {subsubsection}{\numberline {3.6.1.1}Interaction Bias}{18}
\contentsline {subsubsection}{\numberline {3.6.1.2}Latent Bias}{18}
\contentsline {subsubsection}{\numberline {3.6.1.3}Selection Bias}{18}
\contentsline {subsubsection}{\numberline {3.6.1.4}Recency Bias}{18}
\contentsline {subsection}{\numberline {3.6.2}Evaluation}{18}
\contentsline {section}{\numberline {3.7}Data Acquisition}{18}
\contentsline {subsection}{\numberline {3.7.1}Resources}{18}
\contentsline {subsection}{\numberline {3.7.2}Public Indexing}{18}
\contentsline {subsection}{\numberline {3.7.3}Notable Database Sites}{18}
\contentsline {subsection}{\numberline {3.7.4}Datasets to be familiar with}{19}
\contentsline {subsubsection}{\numberline {3.7.4.1}Common}{19}
\contentsline {paragraph}{\numberline {3.7.4.1.1}MNIST}{19}
\contentsline {subsubsection}{\numberline {3.7.4.2}Others (referenced in this text)}{19}
\contentsline {subsection}{\numberline {3.7.5}Data Portal Search}{19}
\contentsline {subsection}{\numberline {3.7.6}Generating Fake Data}{19}
\contentsline {section}{\numberline {3.8}Data Preparation}{19}
\contentsline {subsection}{\numberline {3.8.1}Data Pre-processing}{21}
\contentsline {subsection}{\numberline {3.8.2}Handling Missing Data}{21}
\contentsline {subsubsection}{\numberline {3.8.2.1}Filtering Out}{21}
\contentsline {subsubsection}{\numberline {3.8.2.2}Filling In}{22}
\contentsline {subsubsection}{\numberline {3.8.2.3}Handling Categorical Data}{22}
\contentsline {paragraph}{\numberline {3.8.2.3.1}Encoding}{22}
\contentsline {subsubsection}{\numberline {3.8.2.4}Feature Scaling, Normalization}{22}
\contentsline {paragraph}{\numberline {3.8.2.4.1}Mean Normalization}{23}
\contentsline {paragraph}{\numberline {3.8.2.4.2}Min-Max scaling (Normalization)}{23}
\contentsline {paragraph}{\numberline {3.8.2.4.3}Standardization}{23}
\contentsline {subparagraph}{Robust Scaler}{23}
\contentsline {subsubsection}{\numberline {3.8.2.5}Others}{23}
\contentsline {paragraph}{\numberline {3.8.2.5.1}Removing Duplicates}{23}
\contentsline {paragraph}{\numberline {3.8.2.5.2}Outliers}{23}
\contentsline {paragraph}{\numberline {3.8.2.5.3}Discretization and Binning}{23}
\contentsline {subsubsection}{\numberline {3.8.2.6}Where to do preprocessing}{24}
\contentsline {subsubsection}{\numberline {3.8.2.7}Feature Engineering}{24}
\contentsline {section}{\numberline {3.9}Feature Extraction from Various Datatypes}{24}
\contentsline {subsection}{\numberline {3.9.1}Feature Engineering}{24}
\contentsline {subsubsection}{\numberline {3.9.1.1}Kernel}{24}
\contentsline {subsubsection}{\numberline {3.9.1.2}Feature Crosses}{26}
\contentsline {subsection}{\numberline {3.9.2}2D Images}{26}
\contentsline {subsection}{\numberline {3.9.3}3D Imagery}{26}
\contentsline {subsection}{\numberline {3.9.4}Video}{26}
\contentsline {subsection}{\numberline {3.9.5}Natural Language}{26}
\contentsline {subsubsection}{\numberline {3.9.5.1}Terminology}{27}
\contentsline {subsubsection}{\numberline {3.9.5.2}Pre-processing}{27}
\contentsline {paragraph}{\numberline {3.9.5.2.1}Stop Word Filtering}{27}
\contentsline {paragraph}{\numberline {3.9.5.2.2}Tokenization}{27}
\contentsline {paragraph}{\numberline {3.9.5.2.3}Lemmatization}{27}
\contentsline {paragraph}{\numberline {3.9.5.2.4}Stemming}{27}
\contentsline {subparagraph}{Porter Stemming}{28}
\contentsline {subsubsection}{\numberline {3.9.5.3}Encoding}{28}
\contentsline {paragraph}{\numberline {3.9.5.3.1}Encoding Methods}{28}
\contentsline {subparagraph}{Bag-of-Words}{28}
\contentsline {paragraph}{\numberline {3.9.5.3.2}tf-idf}{28}
\contentsline {subsubsection}{\numberline {3.9.5.4}Embedding}{28}
\contentsline {subparagraph}{glove}{28}
\contentsline {subparagraph}{word2vec}{28}
\contentsline {subsubsection}{\numberline {3.9.5.5}Other Notes}{28}
\contentsline {subsection}{\numberline {3.9.6}Audio}{28}
\contentsline {section}{\numberline {3.10}Partitioning Data}{28}
\contentsline {subsection}{\numberline {3.10.1}Types of Splits}{29}
\contentsline {subsection}{\numberline {3.10.2}k-Fold Cross Validation}{31}
\contentsline {subsubsection}{\numberline {3.10.2.1}k-Fold Validation with shuffling}{31}
\contentsline {subsection}{\numberline {3.10.3}Sampling}{31}
\contentsline {paragraph}{\numberline {3.10.3.0.1}Representative Data}{32}
\contentsline {paragraph}{\numberline {3.10.3.0.2}Representative Data}{32}
\contentsline {part}{III\hspace {1em}Foundations}{33}
\contentsline {chapter}{\numberline {4}Basics}{35}
\contentsline {section}{\numberline {4.1}Overview}{35}
\contentsline {section}{\numberline {4.2}Workflow Overview / Blue Print}{35}
\contentsline {section}{\numberline {4.3}Some Terms}{36}
\contentsline {section}{\numberline {4.4}Type of Learning}{37}
\contentsline {subsection}{\numberline {4.4.1}Supervised vs Unsupervised}{37}
\contentsline {subsection}{\numberline {4.4.2}Classification vs Regression}{37}
\contentsline {subsubsection}{\numberline {4.4.2.1}Regression}{37}
\contentsline {subsubsection}{\numberline {4.4.2.2}Classification}{38}
\contentsline {subsection}{\numberline {4.4.3}Multi-label classification}{38}
\contentsline {subsubsection}{\numberline {4.4.3.1}Approaches: Problem transformation}{38}
\contentsline {paragraph}{\numberline {4.4.3.1.1}Unique set/combination of labels}{38}
\contentsline {paragraph}{\numberline {4.4.3.1.2}Many Binary Classifiers}{39}
\contentsline {subsubsection}{\numberline {4.4.3.2}Evaluating Multi-label Classification}{39}
\contentsline {section}{\numberline {4.5}Training}{39}
\contentsline {subsection}{\numberline {4.5.1}Cost, Loss Function}{39}
\contentsline {subsection}{\numberline {4.5.2}Error Functions}{40}
\contentsline {subsubsection}{\numberline {4.5.2.1}forward pass}{40}
\contentsline {subsubsection}{\numberline {4.5.2.2}backward pass}{40}
\contentsline {subsubsection}{\numberline {4.5.2.3}Least-squares techniques}{40}
\contentsline {paragraph}{\numberline {4.5.2.3.1}Sum-of-squares error function}{40}
\contentsline {paragraph}{\numberline {4.5.2.3.2}Normal Equations}{40}
\contentsline {paragraph}{\numberline {4.5.2.3.3}Singular Value Decomposition (SVD)}{41}
\contentsline {paragraph}{\numberline {4.5.2.3.4}Gradient Descent}{41}
\contentsline {subsubsection}{\numberline {4.5.2.4}Global vs Local Minima}{41}
\contentsline {section}{\numberline {4.6}Quality of Fit}{42}
\contentsline {subsection}{\numberline {4.6.1}Regression Example}{42}
\contentsline {subsection}{\numberline {4.6.2}Classification Example}{42}
\contentsline {section}{\numberline {4.7}Describing Learners}{43}
\contentsline {subsection}{\numberline {4.7.1}Parametric and non-parametric}{43}
\contentsline {subsubsection}{\numberline {4.7.1.1}parametric}{43}
\contentsline {subsubsection}{\numberline {4.7.1.2}nonparametric}{43}
\contentsline {subsubsection}{\numberline {4.7.1.3}parametric vs nonparametric}{44}
\contentsline {subsection}{\numberline {4.7.2}Eager vs Lazy Learners}{44}
\contentsline {subsubsection}{\numberline {4.7.2.1}Eager Learners}{44}
\contentsline {subsubsection}{\numberline {4.7.2.2}Lazy Learners}{44}
\contentsline {subsection}{\numberline {4.7.3}Generative vs Discriminative Models}{44}
\contentsline {subsubsection}{\numberline {4.7.3.1}Discriminative Models}{45}
\contentsline {paragraph}{\numberline {4.7.3.1.1}Probabilistic Discriminative}{45}
\contentsline {paragraph}{\numberline {4.7.3.1.2}Non-probabilistic Discriminative}{45}
\contentsline {subsubsection}{\numberline {4.7.3.2}Generative Models}{45}
\contentsline {subsection}{\numberline {4.7.4}Strong vs Weak Learners}{45}
\contentsline {section}{\numberline {4.8}Online Learning}{45}
\contentsline {section}{\numberline {4.9}Kernel Methods}{46}
\contentsline {subsection}{\numberline {4.9.1}Kernel Trick}{46}
\contentsline {subsection}{\numberline {4.9.2}Kernels}{46}
\contentsline {subsubsection}{\numberline {4.9.2.1}Polynomial}{46}
\contentsline {subsubsection}{\numberline {4.9.2.2}Gaussian / RBF (Radial Basis Function)}{46}
\contentsline {subsection}{\numberline {4.9.3}Less Common Kernels}{47}
\contentsline {section}{\numberline {4.10}Hyper-Parameters}{47}
\contentsline {subsection}{\numberline {4.10.1}Parameters: "tuning knobs"}{47}
\contentsline {subsubsection}{\numberline {4.10.1.1}Learning Rate}{47}
\contentsline {paragraph}{\numberline {4.10.1.1.1}research}{47}
\contentsline {subsubsection}{\numberline {4.10.1.2}Batch size}{47}
\contentsline {subsection}{\numberline {4.10.2}Hyper-Parameter Optimization}{48}
\contentsline {subsubsection}{\numberline {4.10.2.1}Grid Search}{48}
\contentsline {subsubsection}{\numberline {4.10.2.2}Randomized Search}{48}
\contentsline {subsubsection}{\numberline {4.10.2.3}Other Methods}{48}
\contentsline {paragraph}{\numberline {4.10.2.3.1}Bayesian Methods}{48}
\contentsline {chapter}{\numberline {5}Estimating Model Parameters}{49}
\contentsline {section}{\numberline {5.1}Initialization}{49}
\contentsline {subsection}{\numberline {5.1.1}Parameter types}{49}
\contentsline {paragraph}{\numberline {5.1.1.0.1}Weights}{49}
\contentsline {paragraph}{\numberline {5.1.1.0.2}Biases}{49}
\contentsline {subsection}{\numberline {5.1.2}Strategies}{50}
\contentsline {subsubsection}{\numberline {5.1.2.1}glotrot}{50}
\contentsline {subsubsection}{\numberline {5.1.2.2}he}{50}
\contentsline {subsubsection}{\numberline {5.1.2.3}Implementation}{50}
\contentsline {section}{\numberline {5.2}Optimization}{50}
\contentsline {subsection}{\numberline {5.2.1}Descent Direction Methods}{50}
\contentsline {subsection}{\numberline {5.2.2}First-order}{50}
\contentsline {subsubsection}{\numberline {5.2.2.1}Gradient Descent}{51}
\contentsline {paragraph}{\numberline {5.2.2.1.1}Batch Gradient Descent}{51}
\contentsline {paragraph}{\numberline {5.2.2.1.2}Stochastic Gradient Descent}{51}
\contentsline {paragraph}{\numberline {5.2.2.1.3}Mini-batch Gradient Descent}{52}
\contentsline {subsubsection}{\numberline {5.2.2.2}Conjugate Gradient}{52}
\contentsline {subsubsection}{\numberline {5.2.2.3}Momentum Descent}{52}
\contentsline {subsubsection}{\numberline {5.2.2.4}Nesterov Momentum Descent}{52}
\contentsline {subsubsection}{\numberline {5.2.2.5}Adagrad Descent}{52}
\contentsline {paragraph}{\numberline {5.2.2.5.1}Adagrad Extensions: (RMSProp, Adadelta, Adam)}{53}
\contentsline {subparagraph}{RMSProp}{53}
\contentsline {subparagraph}{Adadelta}{53}
\contentsline {subparagraph}{Adam}{53}
\contentsline {subsubsection}{\numberline {5.2.2.6}AdaMax}{53}
\contentsline {subsubsection}{\numberline {5.2.2.7}Hypergradient Descent}{53}
\contentsline {subsubsection}{\numberline {5.2.2.8}FTRL}{53}
\contentsline {subsection}{\numberline {5.2.3}Nadam}{53}
\contentsline {subsubsection}{\numberline {5.2.3.1}AMSGrad}{54}
\contentsline {subsection}{\numberline {5.2.4}second-order}{54}
\contentsline {subsubsection}{\numberline {5.2.4.1}Newton's Method}{54}
\contentsline {subsubsection}{\numberline {5.2.4.2}Secant Method}{54}
\contentsline {subsubsection}{\numberline {5.2.4.3}Quasi-Newton Method}{54}
\contentsline {subsection}{\numberline {5.2.5}Direct methods}{54}
\contentsline {subsection}{\numberline {5.2.6}Stochastic methods}{54}
\contentsline {subsection}{\numberline {5.2.7}Population methods}{54}
\contentsline {subsection}{\numberline {5.2.8}Further optimization information}{54}
\contentsline {subsection}{\numberline {5.2.9}Parallelizing and distributing SGD}{54}
\contentsline {chapter}{\numberline {6}Evaluation}{55}
\contentsline {subsection}{\numberline {6.0.1}Creating a Test Set}{55}
\contentsline {subsection}{\numberline {6.0.2}Qualitative Evaluation}{56}
\contentsline {subsubsection}{\numberline {6.0.2.1}(Over$|$Under)fitting and Capacity}{56}
\contentsline {paragraph}{\numberline {6.0.2.1.1}Overfitting}{56}
\contentsline {paragraph}{\numberline {6.0.2.1.2}Underfitting}{56}
\contentsline {subparagraph}{Solution}{57}
\contentsline {subsubsection}{\numberline {6.0.2.2}Bias Variance Trade-off}{57}
\contentsline {paragraph}{\numberline {6.0.2.2.1}Variance}{57}
\contentsline {paragraph}{\numberline {6.0.2.2.2}Bias}{57}
\contentsline {paragraph}{\numberline {6.0.2.2.3}Trade-Off}{58}
\contentsline {subsection}{\numberline {6.0.3}Qualitative Evalutation: Performance Metrics}{59}
\contentsline {subsubsection}{\numberline {6.0.3.1}Confusion Matrix}{59}
\contentsline {subsubsection}{\numberline {6.0.3.2}Classification Metrics}{60}
\contentsline {subsubsection}{\numberline {6.0.3.3}Precision-Recall curve}{62}
\contentsline {subsubsection}{\numberline {6.0.3.4}Regression Metrics}{62}
\contentsline {subsubsection}{\numberline {6.0.3.5}Additional Metrics}{63}
\contentsline {paragraph}{\numberline {6.0.3.5.1}Linear Evaluation}{63}
\contentsline {paragraph}{\numberline {6.0.3.5.2}Distance Metrics}{63}
\contentsline {paragraph}{\numberline {6.0.3.5.3}Multi-label Classification}{64}
\contentsline {subsubsection}{\numberline {6.0.3.6}Choosing the "right" metrics}{64}
\contentsline {chapter}{\numberline {7}Improving Generalizability}{65}
\contentsline {subsection}{\numberline {7.0.1}Parameter Regularization}{65}
\contentsline {subsubsection}{\numberline {7.0.1.1}Why Regularization}{65}
\contentsline {subsubsection}{\numberline {7.0.1.2}Types of Regularization}{65}
\contentsline {subsubsection}{\numberline {7.0.1.3}Early Stopping}{66}
\contentsline {subsubsection}{\numberline {7.0.1.4}Parameter Norm Penalties}{66}
\contentsline {paragraph}{\numberline {7.0.1.4.1}L2 Regularization}{66}
\contentsline {paragraph}{\numberline {7.0.1.4.2}L1 Regularization}{67}
\contentsline {paragraph}{\numberline {7.0.1.4.3}Elastic Net Regularization}{67}
\contentsline {subsection}{\numberline {7.0.2}Dataset Augmentation}{67}
\contentsline {subsubsection}{\numberline {7.0.2.1}Two Dimensional Data}{67}
\contentsline {subsubsection}{\numberline {7.0.2.2}Learning Augmentation}{68}
\contentsline {paragraph}{\numberline {7.0.2.2.1}AutoAugment}{68}
\contentsline {subsection}{\numberline {7.0.3}Dropout}{68}
\contentsline {subsection}{\numberline {7.0.4}Ensemble Methods}{70}
\contentsline {subsection}{\numberline {7.0.5}Adversarial Training}{70}
\contentsline {subsection}{\numberline {7.0.6}Transfer Learning}{70}
\contentsline {subsubsection}{\numberline {7.0.6.1}Normalization}{70}
\contentsline {paragraph}{\numberline {7.0.6.1.1}Instance normalization}{71}
\contentsline {paragraph}{\numberline {7.0.6.1.2}Layer normalization}{71}
\contentsline {paragraph}{\numberline {7.0.6.1.3}Batch normalization}{71}
\contentsline {paragraph}{\numberline {7.0.6.1.4}Group normalization}{71}
\contentsline {section}{\numberline {7.1}Adversarial Examples}{71}
\contentsline {section}{\numberline {7.2}Output regularization}{72}
\contentsline {chapter}{\numberline {8}Distributed Methods}{73}
\contentsline {subsubsection}{\numberline {8.0.0.1}Data Parallelism}{73}
\contentsline {subsubsection}{\numberline {8.0.0.2}Model Parallelism}{73}
\contentsline {subsubsection}{\numberline {8.0.0.3}Federated learning}{73}
\contentsline {chapter}{\numberline {9}Ethics}{75}
\contentsline {section}{\numberline {9.1}Overview}{75}
\contentsline {section}{\numberline {9.2}Pieces to fit together}{75}
\contentsline {section}{\numberline {9.3}Should something be published}{75}
\contentsline {section}{\numberline {9.4}Further information}{75}
\contentsline {section}{\numberline {9.5}bias}{76}
\contentsline {section}{\numberline {9.6}Thoughts}{76}
\contentsline {part}{IV\hspace {1em}Algorithms}{77}
\contentsline {chapter}{\numberline {10}Foundational Methods}{79}
\contentsline {section}{\numberline {10.1}Regression}{79}
\contentsline {subsection}{\numberline {10.1.1}Simple Linear Regression}{79}
\contentsline {subsubsection}{\numberline {10.1.1.1}OLS}{80}
\contentsline {subsubsection}{\numberline {10.1.1.2}Cost}{80}
\contentsline {subsubsection}{\numberline {10.1.1.3}Evaluation}{81}
\contentsline {subsection}{\numberline {10.1.2}Multiple Linear Regression}{81}
\contentsline {subsection}{\numberline {10.1.3}Polynomial Regression}{81}
\contentsline {section}{\numberline {10.2}Logistic Regression}{82}
\contentsline {section}{\numberline {10.3}Nearest Neighbors}{82}
\contentsline {subsection}{\numberline {10.3.1}Overview}{83}
\contentsline {subsubsection}{\numberline {10.3.1.1}Distance metric}{83}
\contentsline {subsection}{\numberline {10.3.2}K-Nearest Neighbors}{83}
\contentsline {subsubsection}{\numberline {10.3.2.1}Regression Considerations}{83}
\contentsline {subsection}{\numberline {10.3.3}Considering Imbalanced Data}{84}
\contentsline {subsubsection}{\numberline {10.3.3.1}Weighted K-Nearest Neighbors}{84}
\contentsline {subsubsection}{\numberline {10.3.3.2}Distance Weighted K-Nearest Neighbors}{84}
\contentsline {subsection}{\numberline {10.3.4}Considerations}{84}
\contentsline {subsubsection}{\numberline {10.3.4.1}Memory}{84}
\contentsline {subsection}{\numberline {10.3.5}Other Variations}{84}
\contentsline {section}{\numberline {10.4}Support Vector Machines (SVM)}{85}
\contentsline {subsection}{\numberline {10.4.1}Maximizing Geometric Margin}{85}
\contentsline {subsubsection}{\numberline {10.4.1.1}Sequential Minimal Optimization}{85}
\contentsline {subsection}{\numberline {10.4.2}Kernel SVM}{85}
\contentsline {subsubsection}{\numberline {10.4.2.1}The `Kernel Trick'}{85}
\contentsline {section}{\numberline {10.5}Naive Bayes}{85}
\contentsline {subsection}{\numberline {10.5.1}Bayes' Theorem}{86}
\contentsline {section}{\numberline {10.6}Decision Trees}{86}
\contentsline {subsection}{\numberline {10.6.1}Criterion -- Maximizing Information Gain}{87}
\contentsline {subsubsection}{\numberline {10.6.1.1}Gini Impurity}{87}
\contentsline {subsubsection}{\numberline {10.6.1.2}Entropy}{87}
\contentsline {paragraph}{\numberline {10.6.1.2.1}Information Gain}{87}
\contentsline {subsubsection}{\numberline {10.6.1.3}Classification Error}{88}
\contentsline {subsubsection}{\numberline {10.6.1.4}ID3 Algorithm}{88}
\contentsline {subsubsection}{\numberline {10.6.1.5}C4.5 Algorithm}{88}
\contentsline {subsubsection}{\numberline {10.6.1.6}CART Algorithm}{88}
\contentsline {subsection}{\numberline {10.6.2}Pruning}{88}
\contentsline {subsubsection}{\numberline {10.6.2.1}Pre-pruning}{89}
\contentsline {subsubsection}{\numberline {10.6.2.2}Post-pruning}{89}
\contentsline {section}{\numberline {10.7}Random Forests}{89}
\contentsline {chapter}{\numberline {11}Artificial Neural Networks}{91}
\contentsline {section}{\numberline {11.1}Perceptron}{91}
\contentsline {subsection}{\numberline {11.1.1}History}{91}
\contentsline {subsection}{\numberline {11.1.2}Overview}{92}
\contentsline {subsection}{\numberline {11.1.3}Activation Function Basics}{92}
\contentsline {subsection}{\numberline {11.1.4}Limitations}{93}
\contentsline {subsection}{\numberline {11.1.5}Extending to model linearly inseparable data}{93}
\contentsline {subsubsection}{\numberline {11.1.5.1}Kernelization}{93}
\contentsline {subsubsection}{\numberline {11.1.5.2}Directed Graph}{93}
\contentsline {subsection}{\numberline {11.1.6}Notes}{94}
\contentsline {section}{\numberline {11.2}Artificial Neural Networks (ANN)}{94}
\contentsline {subsection}{\numberline {11.2.1}Multi-layer Perceptron}{94}
\contentsline {subsection}{\numberline {11.2.2}Architecture}{94}
\contentsline {subsection}{\numberline {11.2.3}Components}{95}
\contentsline {subsubsection}{\numberline {11.2.3.1}Nodes / units}{95}
\contentsline {paragraph}{\numberline {11.2.3.1.1}Initialization}{95}
\contentsline {subsubsection}{\numberline {11.2.3.2}Activation Function}{95}
\contentsline {subsection}{\numberline {11.2.4}Characterization}{97}
\contentsline {subsubsection}{\numberline {11.2.4.1}Types: Feed-forward vs Feedback}{97}
\contentsline {paragraph}{\numberline {11.2.4.1.1}Feed-forward}{97}
\contentsline {subparagraph}{Layered networks}{97}
\contentsline {subparagraph}{General topologies}{97}
\contentsline {paragraph}{\numberline {11.2.4.1.2}Feedback}{98}
\contentsline {subsubsection}{\numberline {11.2.4.2}Terminology}{98}
\contentsline {subsection}{\numberline {11.2.5}Learning: Backpropagation}{98}
\contentsline {paragraph}{\numberline {11.2.5.0.1}Forward pass}{99}
\contentsline {paragraph}{\numberline {11.2.5.0.2}Backward pass}{99}
\contentsline {subsubsection}{\numberline {11.2.5.1}Back-propagation efficiency}{99}
\contentsline {subsubsection}{\numberline {11.2.5.2}Chain Rule}{99}
\contentsline {subsection}{\numberline {11.2.6}Multi-layer perceptrons}{100}
\contentsline {subsection}{\numberline {11.2.7}Operations}{100}
\contentsline {subsection}{\numberline {11.2.8}Convolution}{100}
\contentsline {subsection}{\numberline {11.2.9}Pooling}{100}
\contentsline {section}{\numberline {11.3}Feed-forward}{103}
\contentsline {section}{\numberline {11.4}Feedback or Recurrent}{103}
\contentsline {subsection}{\numberline {11.4.1}Foundation}{103}
\contentsline {subsection}{\numberline {11.4.2}Simple RNN and Recurrent Neuron}{103}
\contentsline {subsubsection}{\numberline {11.4.2.1}Common Use Cases}{104}
\contentsline {paragraph}{\numberline {11.4.2.1.1}Sequence to Sequence}{104}
\contentsline {subparagraph}{Overview}{104}
\contentsline {paragraph}{\numberline {11.4.2.1.2}Sequence to Vector}{104}
\contentsline {subparagraph}{Overview}{104}
\contentsline {paragraph}{\numberline {11.4.2.1.3}Vector to Sequence}{104}
\contentsline {subparagraph}{Overview}{104}
\contentsline {paragraph}{\numberline {11.4.2.1.4}Delayed Sequence to Sequence}{104}
\contentsline {subparagraph}{Overview}{105}
\contentsline {section}{\numberline {11.5}Common Problems}{105}
\contentsline {subsection}{\numberline {11.5.1}Maintaining States}{105}
\contentsline {subsection}{\numberline {11.5.2}Addressing Vanishing and Exploding Gradients}{105}
\contentsline {section}{\numberline {11.6}Architecture}{105}
\contentsline {subsection}{\numberline {11.6.1}Cell Advancements}{105}
\contentsline {subsubsection}{\numberline {11.6.1.1}LSTM}{105}
\contentsline {paragraph}{\numberline {11.6.1.1.1}Fully Connected Layers}{106}
\contentsline {subparagraph}{Main}{106}
\contentsline {subparagraph}{Forget}{107}
\contentsline {subparagraph}{Input}{107}
\contentsline {subparagraph}{Output}{107}
\contentsline {paragraph}{\numberline {11.6.1.1.2}Other}{107}
\contentsline {subparagraph}{Peephole Connections}{107}
\contentsline {subsubsection}{\numberline {11.6.1.2}GRU}{108}
\contentsline {subsection}{\numberline {11.6.2}Initialization}{109}
\contentsline {subsection}{\numberline {11.6.3}Activation Functions}{109}
\contentsline {subsection}{\numberline {11.6.4}Notes -- add}{109}
\contentsline {chapter}{\numberline {12}Unsupervised}{111}
\contentsline {subsection}{\numberline {12.0.1}TODO}{111}
\contentsline {section}{\numberline {12.1}Clustering}{112}
\contentsline {subsection}{\numberline {12.1.1}Common Algorithms}{112}
\contentsline {subsubsection}{\numberline {12.1.1.1}K-means}{112}
\contentsline {paragraph}{\numberline {12.1.1.1.1}Local Optima}{113}
\contentsline {paragraph}{\numberline {12.1.1.1.2}Selecting K}{113}
\contentsline {paragraph}{\numberline {12.1.1.1.3}Elbow Method}{113}
\contentsline {subsubsection}{\numberline {12.1.1.2}Hierarchical Clustering}{113}
\contentsline {subsubsection}{\numberline {12.1.1.3}DBSCAN}{114}
\contentsline {subsubsection}{\numberline {12.1.1.4}HDBSCAN}{114}
\contentsline {subsection}{\numberline {12.1.2}Evaluating}{114}
\contentsline {subsubsection}{\numberline {12.1.2.1}Silhouette Coefficient}{114}
\contentsline {section}{\numberline {12.2}Dimensionality Reduction}{114}
\contentsline {subsection}{\numberline {12.2.1}Principal Component Analysis}{115}
\contentsline {subsubsection}{\numberline {12.2.1.1}Linear}{115}
\contentsline {paragraph}{\numberline {12.2.1.1.1}Incremental PCA}{115}
\contentsline {paragraph}{\numberline {12.2.1.1.2}Sparse PCA}{116}
\contentsline {subsubsection}{\numberline {12.2.1.2}Nonlinear}{116}
\contentsline {paragraph}{\numberline {12.2.1.2.1}Kernel PCA}{116}
\contentsline {subsection}{\numberline {12.2.2}Singular value decomposition (SVD)}{116}
\contentsline {subsection}{\numberline {12.2.3}Random Projection}{116}
\contentsline {subsubsection}{\numberline {12.2.3.1}Gaussian Random Projection}{116}
\contentsline {subsubsection}{\numberline {12.2.3.2}Sparse Random Projection}{116}
\contentsline {section}{\numberline {12.3}Nonlinear dimensionality reduction}{117}
\contentsline {subsection}{\numberline {12.3.1}Isomap}{117}
\contentsline {subsection}{\numberline {12.3.2}Multidimensional Scaling (MDS)}{117}
\contentsline {subsection}{\numberline {12.3.3}Locally Linear Embedding (LLE)}{117}
\contentsline {subsection}{\numberline {12.3.4}t-Distributed Stochastic Neighbor Embedding (t-SNE)}{117}
\contentsline {section}{\numberline {12.4}Non-geometric, no distance metric}{118}
\contentsline {subsection}{\numberline {12.4.1}Dictionary Learning}{118}
\contentsline {subsection}{\numberline {12.4.2}Independent Component Analysis (ICA)}{118}
\contentsline {subsection}{\numberline {12.4.3}TODO: others}{118}
\contentsline {subsection}{\numberline {12.4.4}Autoencoders}{118}
\contentsline {paragraph}{\numberline {12.4.4.0.1}Undercomplete vs Overcomplete}{119}
\contentsline {subsection}{\numberline {12.4.5}Generative Adversarial Networks}{119}
\contentsline {subsection}{\numberline {12.4.6}Hidden Markov Model}{119}
\contentsline {chapter}{\numberline {13}Semi-supervised}{121}
\contentsline {section}{\numberline {13.1}Semi-Supervised}{121}
\contentsline {subsection}{\numberline {13.1.1}Examples}{121}
\contentsline {chapter}{\numberline {14}Common Architectures}{123}
\contentsline {subsection}{\numberline {14.0.1}Classification}{123}
\contentsline {subsubsection}{\numberline {14.0.1.1}Image Classification}{123}
\contentsline {subsection}{\numberline {14.0.2}Object Detection}{123}
\contentsline {subsection}{\numberline {14.0.3}Semantic Segmentation}{124}
\contentsline {subsection}{\numberline {14.0.4}Instance Segmentation}{124}
\contentsline {section}{\numberline {14.1}Feed Forward}{124}
\contentsline {section}{\numberline {14.2}Recurrent Neural Networks}{124}
\contentsline {section}{\numberline {14.3}Other}{124}
\contentsline {subsection}{\numberline {14.3.1}GANs}{124}
\contentsline {part}{V\hspace {1em}Ensembling}{125}
\contentsline {chapter}{\numberline {15}Ensemble Methods}{127}
\contentsline {section}{\numberline {15.1}Overview}{127}
\contentsline {subsection}{\numberline {15.1.1}Approaches to Creating Ensembles}{127}
\contentsline {subsubsection}{\numberline {15.1.1.1}Bagging}{127}
\contentsline {subsubsection}{\numberline {15.1.1.2}Boosting}{128}
\contentsline {paragraph}{\numberline {15.1.1.2.1}Examples}{128}
\contentsline {subparagraph}{AdaBoost}{128}
\contentsline {subsubsection}{\numberline {15.1.1.3}Bagging Vs Boosting}{129}
\contentsline {subsection}{\numberline {15.1.2}Stacking}{129}
\contentsline {subsection}{\numberline {15.1.3}Examples}{129}
\contentsline {subsubsection}{\numberline {15.1.3.1}Random Forests}{129}
\contentsline {chapter}{\numberline {16}Term dump}{131}
\contentsline {subsection}{\numberline {16.0.1}Distributions}{131}
\contentsline {part}{VI\hspace {1em}Brief Reference}{133}
\contentsline {chapter}{\numberline {17}Mistakes and Bloopers}{135}
\contentsline {chapter}{\numberline {18}Environment}{137}
\contentsline {chapter}{\numberline {19}Common Libraries}{139}
\contentsline {part}{VII\hspace {1em}TensorFlow}{141}
\contentsline {chapter}{\numberline {20}Overview}{143}
\contentsline {section}{\numberline {20.1}Introduction}{143}
\contentsline {section}{\numberline {20.2}TensorFlow Essentials}{143}
\contentsline {subsection}{\numberline {20.2.1}API Hierarchy}{143}
\contentsline {subsection}{\numberline {20.2.2}Working with data}{143}
\contentsline {subsubsection}{\numberline {20.2.2.1}Variables}{143}
\contentsline {subsubsection}{\numberline {20.2.2.2}Placeholder and feed\_dict}{144}
\contentsline {subsubsection}{\numberline {20.2.2.3}Constants}{144}
\contentsline {subsection}{\numberline {20.2.3}Operations}{144}
\contentsline {subsection}{\numberline {20.2.4}Coding Style}{144}
\contentsline {subsection}{\numberline {20.2.5}Graphs}{144}
\contentsline {subsubsection}{\numberline {20.2.5.1}scoping}{145}
\contentsline {subsection}{\numberline {20.2.6}Sessions}{145}
\contentsline {subsection}{\numberline {20.2.7}Tensors}{145}
\contentsline {section}{\numberline {20.3}High-level Overview of Components}{145}
\contentsline {section}{\numberline {20.4}Workflow}{146}
\contentsline {section}{\numberline {20.5}Debugging TensorFlow}{146}
\contentsline {subsection}{\numberline {20.5.1}Common Errors}{146}
\contentsline {subsubsection}{\numberline {20.5.1.1}Shape}{146}
\contentsline {subsubsection}{\numberline {20.5.1.2}Data Type}{146}
\contentsline {subsection}{\numberline {20.5.2}Debugging Tools}{146}
\contentsline {subsubsection}{\numberline {20.5.2.1}tf.Print}{146}
\contentsline {subsubsection}{\numberline {20.5.2.2}tfdbg}{146}
\contentsline {subsubsection}{\numberline {20.5.2.3}TensorBoard}{146}
\contentsline {subsubsection}{\numberline {20.5.2.4}Logging and Verbosity}{147}
\contentsline {chapter}{\numberline {21}Tensorflow API and Components}{149}
\contentsline {section}{\numberline {21.1}Datasets}{149}
\contentsline {subsection}{\numberline {21.1.1}Data}{149}
\contentsline {subsubsection}{\numberline {21.1.1.1}Reading in Data}{149}
\contentsline {paragraph}{\numberline {21.1.1.1.1}Different file formats}{149}
\contentsline {subparagraph}{tf.data.Dataset.TextLineDataset}{149}
\contentsline {subparagraph}{tf.data.Dataset.TFRecordDataset}{149}
\contentsline {subparagraph}{tf.data.Dataset.FixedLengthRecordDataset}{149}
\contentsline {paragraph}{\numberline {21.1.1.1.2}Reading from Sharded Files}{149}
\contentsline {subsubsection}{\numberline {21.1.1.2}Transforming Data}{149}
\contentsline {subsection}{\numberline {21.1.2}Transform}{149}
\contentsline {subsubsection}{\numberline {21.1.2.1}Overview}{149}
\contentsline {subsubsection}{\numberline {21.1.2.2}Installation}{150}
\contentsline {subsubsection}{\numberline {21.1.2.3}Implementation}{150}
\contentsline {section}{\numberline {21.2}Building Architectures}{150}
\contentsline {subsection}{\numberline {21.2.1}Layers}{150}
\contentsline {subsubsection}{\numberline {21.2.1.1}Dense / Fully Connected}{150}
\contentsline {subsubsection}{\numberline {21.2.1.2}Convolution}{150}
\contentsline {subsubsection}{\numberline {21.2.1.3}Pooling}{150}
\contentsline {paragraph}{\numberline {21.2.1.3.1}Max}{151}
\contentsline {paragraph}{\numberline {21.2.1.3.2}Average}{151}
\contentsline {subsection}{\numberline {21.2.2}Estimators}{151}
\contentsline {subsubsection}{\numberline {21.2.2.1}Input data}{151}
\contentsline {paragraph}{\numberline {21.2.2.1.1}Specifying Hyper Parameters}{151}
\contentsline {subparagraph}{Epochs}{151}
\contentsline {paragraph}{\numberline {21.2.2.1.2}In Memory Data}{151}
\contentsline {paragraph}{\numberline {21.2.2.1.3}Out of Memory Data}{151}
\contentsline {subsubsection}{\numberline {21.2.2.2}Checkpoints}{151}
\contentsline {subsubsection}{\numberline {21.2.2.3}Distributed}{152}
\contentsline {paragraph}{\numberline {21.2.2.3.1}tf.estimator.RunConfig}{152}
\contentsline {paragraph}{\numberline {21.2.2.3.2}tf.estimator.TrainSpec}{152}
\contentsline {paragraph}{\numberline {21.2.2.3.3}tf.estimator.EvalSpec}{152}
\contentsline {paragraph}{\numberline {21.2.2.3.4}Notes}{152}
\contentsline {subsubsection}{\numberline {21.2.2.4}TensorBoard}{152}
\contentsline {paragraph}{\numberline {21.2.2.4.1}Adding Custom}{152}
\contentsline {subparagraph}{tf.summary.scalar}{152}
\contentsline {subparagraph}{tf.summary.image}{152}
\contentsline {subparagraph}{tf.summary.audio}{153}
\contentsline {subparagraph}{tf.summary.text}{153}
\contentsline {subparagraph}{tf.summary.histogram}{153}
\contentsline {subsubsection}{\numberline {21.2.2.5}Deployment}{153}
\contentsline {paragraph}{\numberline {21.2.2.5.1}Exporters}{153}
\contentsline {subsection}{\numberline {21.2.3}Eager}{153}
\contentsline {section}{\numberline {21.3}Design and Component Considerations}{153}
\contentsline {subsection}{\numberline {21.3.1}Initialization Strategies}{153}
\contentsline {subsection}{\numberline {21.3.2}Hyperparameters}{153}
\contentsline {subsubsection}{\numberline {21.3.2.1}Training Related}{153}
\contentsline {paragraph}{\numberline {21.3.2.1.1}Learning Rate}{153}
\contentsline {subparagraph}{Too High vs Too Low}{153}
\contentsline {paragraph}{\numberline {21.3.2.1.2}Batch Size}{153}
\contentsline {paragraph}{\numberline {21.3.2.1.3}Number of Training Iterations}{153}
\contentsline {paragraph}{\numberline {21.3.2.1.4}Momentum}{153}
\contentsline {paragraph}{\numberline {21.3.2.1.5}Weight Update}{154}
\contentsline {paragraph}{\numberline {21.3.2.1.6}Stopping Criteria}{154}
\contentsline {subsubsection}{\numberline {21.3.2.2}Model Related}{154}
\contentsline {paragraph}{\numberline {21.3.2.2.1}Architecture}{154}
\contentsline {paragraph}{\numberline {21.3.2.2.2}Weight Initialization}{154}
\contentsline {paragraph}{\numberline {21.3.2.2.3}Weight-decay}{154}
\contentsline {paragraph}{\numberline {21.3.2.2.4}Drop-out}{154}
\contentsline {subsection}{\numberline {21.3.3}Hyper-parameter optimization}{154}
\contentsline {subsubsection}{\numberline {21.3.3.1}Coordinate Descent}{154}
\contentsline {subsubsection}{\numberline {21.3.3.2}Grid Search}{154}
\contentsline {subsubsection}{\numberline {21.3.3.3}Random Search}{154}
\contentsline {subsubsection}{\numberline {21.3.3.4}Grid vs Random Search}{154}
\contentsline {subsubsection}{\numberline {21.3.3.5}Automated / Model-based Methods}{155}
\contentsline {subsection}{\numberline {21.3.4}Optimizers}{155}
\contentsline {subsubsection}{\numberline {21.3.4.1}Overview}{155}
\contentsline {subsubsection}{\numberline {21.3.4.2}What are optimizers}{155}
\contentsline {subsubsection}{\numberline {21.3.4.3}Types of optimizers}{155}
\contentsline {subsubsection}{\numberline {21.3.4.4}TF optimizers}{155}
\contentsline {subsubsection}{\numberline {21.3.4.5}Advanced}{155}
\contentsline {paragraph}{\numberline {21.3.4.5.1}Gradient Computation}{155}
\contentsline {paragraph}{\numberline {21.3.4.5.2}Gradient Clipping}{155}
\contentsline {subsection}{\numberline {21.3.5}Regularization}{155}
\contentsline {subsubsection}{\numberline {21.3.5.1}Early Stopping}{156}
\contentsline {subsubsection}{\numberline {21.3.5.2}Parameter Norm Penalties}{156}
\contentsline {paragraph}{\numberline {21.3.5.2.1}L2 Regularization}{156}
\contentsline {paragraph}{\numberline {21.3.5.2.2}L1 Regularization}{156}
\contentsline {paragraph}{\numberline {21.3.5.2.3}Elastic Net Regularization}{156}
\contentsline {subsubsection}{\numberline {21.3.5.3}Dataset Augmentation: Image Augmentation}{156}
\contentsline {paragraph}{\numberline {21.3.5.3.1}Resizing and Cropping (Zooms, Translation)}{156}
\contentsline {paragraph}{\numberline {21.3.5.3.2}Flipping, Rotating, and Transposing}{156}
\contentsline {paragraph}{\numberline {21.3.5.3.3}Colorspaces}{156}
\contentsline {paragraph}{\numberline {21.3.5.3.4}Image Adjustments}{156}
\contentsline {paragraph}{\numberline {21.3.5.3.5}NOTE: Other Libraries}{156}
\contentsline {subsubsection}{\numberline {21.3.5.4}Dropout}{157}
\contentsline {subsubsection}{\numberline {21.3.5.5}Normalization}{157}
\contentsline {paragraph}{\numberline {21.3.5.5.1}Instance normalization}{157}
\contentsline {paragraph}{\numberline {21.3.5.5.2}Layer normalization}{157}
\contentsline {paragraph}{\numberline {21.3.5.5.3}Batch normalization}{157}
\contentsline {paragraph}{\numberline {21.3.5.5.4}Group normalization}{157}
\contentsline {subsection}{\numberline {21.3.6}Activation Functions}{157}
\contentsline {subsubsection}{\numberline {21.3.6.1}Why Non-linear}{157}
\contentsline {subsubsection}{\numberline {21.3.6.2}Advancements}{157}
\contentsline {subsubsection}{\numberline {21.3.6.3}Popular Activation Functions}{157}
\contentsline {paragraph}{\numberline {21.3.6.3.1}Smooth Non-linear}{158}
\contentsline {subparagraph}{Sigmoid}{158}
\contentsline {subparagraph}{ELU}{158}
\contentsline {subparagraph}{Softplus}{160}
\contentsline {paragraph}{\numberline {21.3.6.3.2}Not Smooth Non-linear}{160}
\contentsline {subparagraph}{ReLU}{160}
\contentsline {subparagraph}{Leaky ReLU}{161}
\contentsline {subparagraph}{ReLU6}{161}
\contentsline {subparagraph}{PReLU}{162}
\contentsline {section}{\numberline {21.4}Fine-Tuning Architectures}{163}
\contentsline {subsection}{\numberline {21.4.1}Profiler}{163}
\contentsline {subsection}{\numberline {21.4.2}Debugger}{163}
\contentsline {section}{\numberline {21.5}Distributed Training}{163}
\contentsline {subsection}{\numberline {21.5.1}Resource Management (GPU RAM)}{163}
\contentsline {paragraph}{\numberline {21.5.1.0.1}Device Visibility}{164}
\contentsline {paragraph}{\numberline {21.5.1.0.2}Device Allocation}{164}
\contentsline {subparagraph}{Allow Growth}{164}
\contentsline {subsection}{\numberline {21.5.2}Device Placement}{165}
\contentsline {section}{\numberline {21.6}Model Evaluation}{166}
\contentsline {subsection}{\numberline {21.6.1}Metrics}{166}
\contentsline {subsection}{\numberline {21.6.2}TensorBoard}{167}
\contentsline {subsection}{\numberline {21.6.3}TFMA: TensorFlow Model Analysis}{167}
\contentsline {subsubsection}{\numberline {21.6.3.1}Key Features}{167}
\contentsline {paragraph}{\numberline {21.6.3.1.1}Sliced Metrics}{167}
\contentsline {paragraph}{\numberline {21.6.3.1.2}Full-pass Metrics}{167}
\contentsline {subsubsection}{\numberline {21.6.3.2}Implementation}{167}
\contentsline {paragraph}{\numberline {21.6.3.2.1}Overview}{167}
\contentsline {paragraph}{\numberline {21.6.3.2.2}Code}{167}
\contentsline {subparagraph}{Exporting the Evaluation Graph}{167}
\contentsline {subparagraph}{Computing Metrics}{167}
\contentsline {subparagraph}{Visualize Metrics (in a notebook)}{168}
\contentsline {section}{\numberline {21.7}Model Persistence}{168}
\contentsline {subsection}{\numberline {21.7.1}Saver}{168}
\contentsline {subsection}{\numberline {21.7.2}Hub}{168}
\contentsline {section}{\numberline {21.8}Deployment with TF Serving}{168}
\contentsline {subsection}{\numberline {21.8.1}Overview}{168}
\contentsline {subsubsection}{\numberline {21.8.1.1}Standard Abstractions}{168}
\contentsline {paragraph}{\numberline {21.8.1.1.1}ServableHandle}{168}
\contentsline {paragraph}{\numberline {21.8.1.1.2}Manager}{168}
\contentsline {paragraph}{\numberline {21.8.1.1.3}Loader}{168}
\contentsline {paragraph}{\numberline {21.8.1.1.4}Source}{169}
\contentsline {subsubsection}{\numberline {21.8.1.2}Plugins into Abstractions}{169}
\contentsline {paragraph}{\numberline {21.8.1.2.1}File System (Source)}{169}
\contentsline {paragraph}{\numberline {21.8.1.2.2}Version Policy (Manager)}{169}
\contentsline {subsubsection}{\numberline {21.8.1.3}FIT}{169}
\contentsline {paragraph}{\numberline {21.8.1.3.1}ServerCore}{169}
\contentsline {paragraph}{\numberline {21.8.1.3.2}Binaries and APIs}{169}
\contentsline {subparagraph}{Predict}{169}
\contentsline {paragraph}{\numberline {21.8.1.3.3}Servables}{169}
\contentsline {paragraph}{\numberline {21.8.1.3.4}Loaders}{170}
\contentsline {subsection}{\numberline {21.8.2}Example}{170}
\contentsline {section}{\numberline {21.9}Other}{170}
\contentsline {subsection}{\numberline {21.9.1}Probability}{170}
\contentsline {subsection}{\numberline {21.9.2}TensorFlow Extended}{170}
\contentsline {subsection}{\numberline {21.9.3}Keras}{170}
\contentsline {subsection}{\numberline {21.9.4}Image}{170}
\contentsline {subsection}{\numberline {21.9.5}Image Augmentation}{170}
\contentsline {subsection}{\numberline {21.9.6}Edward 2.0}{170}
\contentsline {subsection}{\numberline {21.9.7}TensorFlow Lite}{170}
\contentsline {chapter}{\numberline {22}Implementing Common Methodologies}{171}
\contentsline {section}{\numberline {22.1}Artificial Neural Networks}{171}
\contentsline {section}{\numberline {22.2}Convolutional Neural Networks}{171}
\contentsline {section}{\numberline {22.3}Recurrent Neural Networks}{171}
\contentsline {part}{VIII\hspace {1em}End To End Examples}{173}
\contentsline {chapter}{\numberline {23}EndToEnd}{175}
\contentsline {section}{\numberline {23.1}Structured}{175}
\contentsline {subsection}{\numberline {23.1.1}Linear Regression}{175}
\contentsline {subsection}{\numberline {23.1.2}KNN}{175}
\contentsline {section}{\numberline {23.2}Image}{175}
\contentsline {subsection}{\numberline {23.2.1}Image Classification}{175}
\contentsline {subsection}{\numberline {23.2.2}Image Segmentation}{175}
\contentsline {subsection}{\numberline {23.2.3}Adversarial Exmaples}{175}
\contentsline {subsection}{\numberline {23.2.4}AutoEncoder}{175}
\contentsline {subsection}{\numberline {23.2.5}Generative Adversarial Network}{175}
\contentsline {section}{\numberline {23.3}TimeSeries}{176}
\contentsline {section}{\numberline {23.4}Text}{176}
\contentsline {subsection}{\numberline {23.4.1}Sentiment Analysis}{176}
\contentsline {section}{\numberline {23.5}Audio}{176}
\contentsline {subsection}{\numberline {23.5.1}Audio to Text}{176}
\contentsline {part}{IX\hspace {1em}Yeahml}{177}
\contentsline {chapter}{\numberline {24}Overview}{179}
\contentsline {chapter}{\numberline {25}What is YamlFlow}{181}
\contentsline {chapter}{\numberline {26}Introduction}{183}
\contentsline {subsection}{\numberline {26.0.1}Motivation}{183}
\contentsline {chapter}{\numberline {27}End to End Problems Revisited}{185}
\contentsline {part}{X\hspace {1em}Moving Forward}{187}
\contentsline {section}{\numberline {27.1}Conclusion}{189}
\contentsline {part}{XI\hspace {1em}appendix}{191}
\contentsline {chapter}{\numberline {28}TODO:}{193}
\contentsline {section}{\numberline {28.1}Imputing Missing Values}{193}
\contentsline {section}{\numberline {28.2}Anomaly Detection}{193}
\contentsline {subsection}{\numberline {28.2.1}methods}{193}
\contentsline {subsubsection}{\numberline {28.2.1.1}PCA}{193}
\contentsline {section}{\numberline {28.3}labeling data}{194}
\contentsline {section}{\numberline {28.4}Group Segmentation}{194}
\contentsline {part}{XII\hspace {1em}Dump Space}{195}
\contentsline {subsection}{\numberline {28.4.1}Restricted Boltzmann Machines}{200}
\contentsline {part}{XIII\hspace {1em}Research}{203}
\contentsline {chapter}{\numberline {29}Ongoing Research}{205}
