{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: (3, 6, 5, 'final', 0)\n",
      "TensorFlow: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "# download data\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "# set env log level to supress messages, unless an error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# set tf log level\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Helper to make the output consistent\n",
    "SEED = 42\n",
    "def reset_graph(seed=SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "reset_graph()\n",
    "\n",
    "# helper to create dirs if they don't already exist\n",
    "def maybe_create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"{} created\".format(dir_path))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(dir_path))\n",
    "        \n",
    "def maybe_fetch_data(url, file, dir_path):\n",
    "    maybe_create_dir(dir_path)\n",
    "    if not os.path.exists(file):\n",
    "        # download and write data\n",
    "        raw = urlopen(url).read()\n",
    "        with open(file, \"wb\") as f:\n",
    "            f.write(raw)\n",
    "        print(file, \"path written\")\n",
    "    else:\n",
    "        print(\"{} already exists. Please rm to download new data\".format(file))\n",
    "    \n",
    "\n",
    "# Version information\n",
    "print(\"Python: {}\".format(sys.version_info[:]))\n",
    "assert \"1.4\" <= tf.__version__, \"TensorFlow r1.4 or later is needed\"\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "\n",
    "# Check if using GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU found')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../ROOT_DATA/IRIS already exists\n",
      "../ROOT_DATA/IRIS/iris_training.csv already exists. Please rm to download new data\n",
      "../ROOT_DATA/IRIS already exists\n",
      "../ROOT_DATA/IRIS/iris_test.csv already exists. Please rm to download new data\n"
     ]
    }
   ],
   "source": [
    "## Download data paths\n",
    "ROOT_DATA = \"../ROOT_DATA/\"\n",
    "DATA_DIR = os.path.join(ROOT_DATA, \"IRIS\")\n",
    "\n",
    "IRIS_TRAINING_PATH = os.path.join(DATA_DIR, \"iris_training.csv\")\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST_PATH = os.path.join(DATA_DIR, \"iris_test.csv\")\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "maybe_fetch_data(IRIS_TRAINING_URL, IRIS_TRAINING_PATH, DATA_DIR)\n",
    "maybe_fetch_data(IRIS_TEST_URL, IRIS_TEST_PATH, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyper_params(start_fresh=False):\n",
    "    global maybe_create_dir\n",
    "    data_params = {}\n",
    "    data_params['n_epochs'] = 500\n",
    "    data_params['batch_size'] = 32\n",
    "    data_params['buffer_size'] = 128 # for shuffling\n",
    "    data_params['init_lr'] = 1e-2\n",
    "    \n",
    "    # dataset information, this is known information that will be \n",
    "    # used for the features. Header usually includes this info..\n",
    "    data_params['feature_names'] = [\n",
    "        'SepalLength',\n",
    "        'SepalWidth',\n",
    "        'PetalLength',\n",
    "        'PetalWidth']\n",
    "    \n",
    "    data_params['out_dir'] = \"./iris_custom_est\"\n",
    "    \n",
    "    # by default, the project will NOT start fresh\n",
    "    if start_fresh:\n",
    "        if os.path.exists(data_params['out_dir']):\n",
    "            shutil.rmtree(data_params['out_dir'], ignore_errors = True)\n",
    "\n",
    "    if not os.path.exists(data_params['out_dir']):\n",
    "        os.makedirs(data_params['out_dir'])\n",
    "        print(\"{} created\".format(data_params['out_dir']))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(data_params['out_dir']))\n",
    "    \n",
    "    return data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def my_input_fn(file_path, predict=False):\n",
    "    global hyp_params\n",
    "    if hyp_params['feature_names']:\n",
    "        feat_types = [[0.]]*len(hyp_params['feature_names']) + [[0]]\n",
    "        # [[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "        # [feat1, feat2, feat3, feat4, label]\n",
    "    else:\n",
    "        pass\n",
    "        # TODO: this could read the csv header\n",
    "    \n",
    "    def decode_csv(line):\n",
    "        parsed_line = tf.decode_csv(line, feat_types)\n",
    "        label = parsed_line[-1]  # Last element is the label\n",
    "        features = parsed_line[:-1]  # all but last element\n",
    "        d = dict(zip(hyp_params['feature_names'], features)), label\n",
    "        return d\n",
    "\n",
    "    dataset = (tf.data.TextLineDataset(file_path)  # Read text file\n",
    "                 .skip(1)  # Skip header row\n",
    "                 .map(decode_csv)  # Decode each line using custom decode_csv\n",
    "              )\n",
    "    if predict:\n",
    "        dataset = (dataset.shuffle(1)\n",
    "                          .repeat(1))\n",
    "    else:  # (1 == no operation)\n",
    "        dataset = (dataset.shuffle(hyp_params['buffer_size'])\n",
    "                          .repeat(hyp_params['n_epochs']))   # Repeats dataset this # times\n",
    "        \n",
    "    dataset = (dataset.batch(hyp_params['batch_size'])\n",
    "        .prefetch(1)  # Make sure you always have 1 batch ready to serve\n",
    "    )\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_fn(\n",
    "    features, # This is batch_features from input_fn\n",
    "    labels,   # This is batch_labels from input_fn\n",
    "    mode # instance of tf.estimator.ModeKeys\n",
    "    ):    # hyper parameters\n",
    "    \n",
    "    global hyp_params\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        tf.logging.info(\"my_model_fn: PREDICT, {}\".format(mode))\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        tf.logging.info(\"my_model_fn: EVAL, {}\".format(mode))\n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        tf.logging.info(\"my_model_fn: TRAIN, {}\".format(mode))\n",
    "\n",
    "    # TODO: this needs to be customized\n",
    "    if hyp_params['feature_names']:\n",
    "        feature_columns = [\n",
    "            tf.feature_column.numeric_column(hyp_params['feature_names'][0]),\n",
    "            tf.feature_column.numeric_column(hyp_params['feature_names'][1]),\n",
    "            tf.feature_column.numeric_column(hyp_params['feature_names'][2]),\n",
    "            tf.feature_column.numeric_column(hyp_params['feature_names'][3])\n",
    "        ]\n",
    "    else:\n",
    "        pass\n",
    "        # TODO: this logic may have already been performed and\n",
    "        # could read the csv header\n",
    "\n",
    "    # TODO: core model architecture logic\n",
    "    # Create the layer of input\n",
    "    input_layer = tf.feature_column.input_layer(features, feature_columns)\n",
    "    h1 = tf.layers.dense(inputs=input_layer, units=10, activation=tf.nn.elu)\n",
    "    h2 = tf.layers.dense(inputs=h1, units=10, activation=tf.nn.elu)\n",
    "    # TODO: this could be len(features)\n",
    "    logits = tf.layers.dense(inputs=h2, units=3)\n",
    "\n",
    "    # class_ids will be the model prediction for the class (Iris flower type)\n",
    "    # The output node with the highest value is our prediction\n",
    "    predictions = { 'class_ids': tf.argmax(input=logits, axis=1), \n",
    "                    'in_data': tf.identity(input=input_layer)}\n",
    "\n",
    "    # 1. Prediction mode, Return our prediction. no need to add other ops\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(labels, predictions['class_ids'])\n",
    "\n",
    "    # 2. Evaluation mode\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            predictions=predictions,\n",
    "            eval_metric_ops={'my_accuracy': accuracy})\n",
    "\n",
    "    # If mode is not PREDICT nor EVAL, then we must be in TRAIN\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN, \"TRAIN is only ModeKey left\"\n",
    "\n",
    "    # 3. Training mode\n",
    "    # Provide global step counter (used to count gradient updates)\n",
    "    #optimizer = tf.train.AdagradOptimizer(0.05)\n",
    "    optimizer = tf.train.AdamOptimizer(hyp_params['init_lr'])\n",
    "    train_op = optimizer.minimize(\n",
    "        loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "\n",
    "    tf.summary.scalar('my_accuracy', accuracy[1])\n",
    "    \n",
    "    weights = [v for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) \n",
    "               if v.name.endswith('kernel:0')]\n",
    "    bias = [v for v in tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES) \n",
    "               if v.name.endswith('bias:0')]\n",
    "    # assert len\n",
    "    for i,w in enumerate(weights):\n",
    "        name = \"weights_\"+str(i)\n",
    "        b_name = \"bias_\"+str(i)\n",
    "        with tf.variable_scope(str(i)):\n",
    "            w_hist = tf.summary.histogram(name, w)\n",
    "            b_hist = tf.summary.histogram(b_name, bias[i])\n",
    "\n",
    "    # Return training operations: loss and train_op\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode,\n",
    "        loss=loss,\n",
    "        train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./iris_custom_est created\n"
     ]
    }
   ],
   "source": [
    "hyp_params = create_hyper_params(start_fresh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_config = tf.estimator.RunConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:START estimator construction\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './iris_custom_est', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f49d44b3c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:... END estimator construction\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"START estimator construction\")\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model_fn,\n",
    "    model_dir=hyp_params['out_dir'])  # Path to where checkpoints etc are stored\n",
    "tf.logging.info(\"... END estimator construction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:START classifier.train\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:my_model_fn: TRAIN, train\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./iris_custom_est/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.0419426, step = 0\n",
      "INFO:tensorflow:global_step/sec: 402.202\n",
      "INFO:tensorflow:loss = 0.08620682, step = 100 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.558\n",
      "INFO:tensorflow:loss = 0.065184765, step = 200 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.134\n",
      "INFO:tensorflow:loss = 0.01943511, step = 300 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 476.843\n",
      "INFO:tensorflow:loss = 0.031533822, step = 400 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.134\n",
      "INFO:tensorflow:loss = 0.08046347, step = 500 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 433.382\n",
      "INFO:tensorflow:loss = 0.02564273, step = 600 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.906\n",
      "INFO:tensorflow:loss = 0.02810634, step = 700 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 521.011\n",
      "INFO:tensorflow:loss = 0.01608162, step = 800 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.053\n",
      "INFO:tensorflow:loss = 0.013907719, step = 900 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 516.938\n",
      "INFO:tensorflow:loss = 0.007974355, step = 1000 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.128\n",
      "INFO:tensorflow:loss = 0.0036850644, step = 1100 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 477.141\n",
      "INFO:tensorflow:loss = 0.08705143, step = 1200 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.866\n",
      "INFO:tensorflow:loss = 0.055269245, step = 1300 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.421\n",
      "INFO:tensorflow:loss = 0.05839754, step = 1400 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.278\n",
      "INFO:tensorflow:loss = 0.017031398, step = 1500 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.355\n",
      "INFO:tensorflow:loss = 0.025754364, step = 1600 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.012\n",
      "INFO:tensorflow:loss = 0.06442277, step = 1700 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.095\n",
      "INFO:tensorflow:loss = 0.07451916, step = 1800 (0.208 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1875 into ./iris_custom_est/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.034420922.\n",
      "INFO:tensorflow:... END classifier.train\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"START classifier.train\")\n",
    "classifier.train(\n",
    "    input_fn=lambda: my_input_fn(IRIS_TRAINING_PATH),\n",
    "    hooks=None,\n",
    "    steps=None, # NONE = train to dataset OutOfRange\n",
    "    max_steps=None, # NONE = train to dataset OutOfRange\n",
    "    saving_listeners=None)\n",
    "tf.logging.info(\"... END classifier.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:START classifier.evaluate\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:my_model_fn: EVAL, eval\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-07-02:22:13\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./iris_custom_est/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-07-02:22:14\n",
      "INFO:tensorflow:Saving dict for global step 1875: global_step = 1875, loss = 0.11128041, my_accuracy = 0.96666664\n",
      "INFO:tensorflow:... END classifier.evaluate\n",
      "INFO:tensorflow:Evaluation results\n",
      "INFO:tensorflow:   loss, was: 0.1112804114818573\n",
      "INFO:tensorflow:   my_accuracy, was: 0.9666666388511658\n",
      "INFO:tensorflow:   global_step, was: 1875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our model using the examples contained in FILE_TEST\n",
    "# Return value will contain evaluation_metrics such as: loss & average_loss\n",
    "tf.logging.info(\"START classifier.evaluate\")\n",
    "evaluate_result = classifier.evaluate(\n",
    "    input_fn=lambda: my_input_fn(IRIS_TEST_PATH))\n",
    "tf.logging.info(\"... END classifier.evaluate\")\n",
    "tf.logging.info(\"Evaluation results\")\n",
    "for key in evaluate_result:\n",
    "    tf.logging.info(\"   {}, was: {}\".format(key, evaluate_result[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Prediction on test file\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:my_model_fn: PREDICT, infer\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./iris_custom_est/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:..pred: [4.2 1.5 5.9 3. ], is Versicolor\n",
      "INFO:tensorflow:..pred: [5.4 2.1 6.9 3.1], is Virginica\n",
      "INFO:tensorflow:..pred: [1.7 0.5 5.1 3.3], is Setosa\n",
      "INFO:tensorflow:..pred: [4.5 1.6 6.  3.4], is Versicolor\n",
      "INFO:tensorflow:..pred: [4.  1.3 5.5 2.5], is Versicolor\n",
      "INFO:tensorflow:..pred: [4.3 1.3 6.2 2.9], is Versicolor\n",
      "INFO:tensorflow:..pred: [1.4 0.2 5.5 4.2], is Setosa\n",
      "INFO:tensorflow:..pred: [5.1 1.5 6.3 2.8], is Versicolor\n",
      "INFO:tensorflow:..pred: [4.1 1.3 5.6 3. ], is Versicolor\n",
      "INFO:tensorflow:..pred: [5.8 1.8 6.7 2.5], is Virginica\n",
      "INFO:tensorflow:..pred: [5.9 2.1 7.1 3. ], is Virginica\n",
      "INFO:tensorflow:..pred: [1.1 0.1 4.3 3. ], is Setosa\n",
      "INFO:tensorflow:..pred: [4.9 2.  5.6 2.8], is Virginica\n",
      "INFO:tensorflow:..pred: [4.  1.3 5.5 2.3], is Versicolor\n",
      "INFO:tensorflow:..pred: [4.  1.  6.  2.2], is Versicolor\n",
      "INFO:tensorflow:..pred: [1.4 0.2 5.1 3.5], is Setosa\n",
      "INFO:tensorflow:..pred: [3.5 1.  5.7 2.6], is Versicolor\n",
      "INFO:tensorflow:..pred: [1.9 0.2 4.8 3.4], is Setosa\n",
      "INFO:tensorflow:..pred: [1.5 0.2 5.1 3.4], is Setosa\n",
      "INFO:tensorflow:..pred: [5.  2.  5.7 2.5], is Virginica\n",
      "INFO:tensorflow:..pred: [1.7 0.2 5.4 3.4], is Setosa\n",
      "INFO:tensorflow:..pred: [4.5 1.5 5.6 3. ], is Versicolor\n",
      "INFO:tensorflow:..pred: [5.6 1.8 6.3 2.9], is Virginica\n",
      "INFO:tensorflow:..pred: [4.9 1.5 6.3 2.5], is Versicolor\n",
      "INFO:tensorflow:..pred: [3.9 1.2 5.8 2.7], is Versicolor\n",
      "INFO:tensorflow:..pred: [4.6 1.4 6.1 3. ], is Versicolor\n",
      "INFO:tensorflow:..pred: [1.5 0.1 5.2 4.1], is Setosa\n",
      "INFO:tensorflow:..pred: [4.7 1.5 6.7 3.1], is Versicolor\n",
      "INFO:tensorflow:..pred: [5.7 2.5 6.7 3.3], is Virginica\n",
      "INFO:tensorflow:..pred: [4.3 1.3 6.4 2.9], is Versicolor\n"
     ]
    }
   ],
   "source": [
    "# PREDICT the type of some Iris flowers.\n",
    "# from FILE_TEST, repeat only once (predict=True).\n",
    "predict_results = classifier.predict(\n",
    "    input_fn=lambda: my_input_fn(IRIS_TEST_PATH, predict=True),\n",
    "    predict_keys=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,  # If None: latest checkpoint in model_dir is used.\n",
    "    yield_single_examples=True)\n",
    "tf.logging.info(\"Prediction on test file\")\n",
    "for idx, prediction in enumerate(predict_results):\n",
    "    # Will print the predicted class, i.e: 0, 1, or 2 if the prediction\n",
    "    # is Iris Setosa, Vericolor, Virginica, respectively.    \n",
    "    iris_type = prediction[\"class_ids\"]  # Get the predicted class (index)\n",
    "    if iris_type == 0:\n",
    "        tf.logging.info(\"..pred: {}, is Setosa\".format(prediction['in_data']))\n",
    "    elif iris_type == 1:\n",
    "        tf.logging.info(\"..pred: {}, is Versicolor\".format(prediction['in_data']))\n",
    "    else:\n",
    "        tf.logging.info(\"..pred: {}, is Virginica\".format(prediction['in_data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input = [[5.9, 3.0, 4.2, 1.5],  # -> 1, Iris Versicolor\n",
    "                    [6.9, 3.1, 5.4, 2.1],  # -> 2, Iris Virginica\n",
    "                    [5.1, 3.3, 1.7, 0.5],  # -> 0, Iris Setosa\n",
    "                    [5.7, 2.5, 6.7, 3.3]]  # -> 2, Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_input_fn():\n",
    "    global hyp_params\n",
    "    def decode(x):\n",
    "        # TODO: this is hardcoded currently\n",
    "        x = tf.split(x, 4)  # Need to split into our 4 features\n",
    "        return dict(zip(hyp_params['feature_names'], x))  # To build a dict of them\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(prediction_input)\n",
    "    dataset = dataset.map(decode)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    next_feature_batch = iterator.get_next()\n",
    "    return next_feature_batch, None  # In prediction, we have no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all our prediction_input\n",
    "predict_results = classifier.predict(input_fn=new_input_fn,\n",
    "    predict_keys=None,\n",
    "    hooks=None,\n",
    "    checkpoint_path=None,  # If None: latest checkpoint in model_dir is used.\n",
    "    yield_single_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Predictions on memory\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:my_model_fn: PREDICT, infer\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./iris_custom_est/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:...I think: [5.9, 3.0, 4.2, 1.5], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [6.9, 3.1, 5.4, 2.1], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [5.1, 3.3, 1.7, 0.5], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [5.7, 2.5, 6.7, 3.3], is Iris Virginica\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"Predictions on memory\")\n",
    "for idx, prediction in enumerate(predict_results):\n",
    "    type = prediction[\"class_ids\"]  # Get the predicted class (index)\n",
    "    if type == 0:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Setosa\".format(prediction_input[idx]))\n",
    "    elif type == 1:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Versicolor\".format(prediction_input[idx]))\n",
    "    else:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Virginica\".format(prediction_input[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What if we want to compare the ground truth to the prediction value for each entry?\n",
    "We have to do a bit more work and manually build/run the graph w/checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:my_model_fn: EVAL, eval\n",
      "INFO:tensorflow:Restoring parameters from ./iris_custom_est/model.ckpt-1875\n"
     ]
    }
   ],
   "source": [
    "# Rebuild the model\n",
    "features, labels = my_input_fn(IRIS_TEST_PATH, predict=True)\n",
    "predictions = my_model_fn(features, labels, tf.estimator.ModeKeys.EVAL).predictions\n",
    "\n",
    "# Manually load the latest checkpoint\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    ckpt = tf.train.get_checkpoint_state(hyp_params['out_dir'])\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    # Loop batches and store predictions and labels\n",
    "    prediction_values = []\n",
    "    label_values = []\n",
    "    while True:\n",
    "        try:\n",
    "            preds, lbls = sess.run([predictions, labels])\n",
    "            prediction_values.append(preds['class_ids']) \n",
    "            label_values.append(lbls)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: 1, GT: 1 == True\n",
      "pred: 2, GT: 2 == True\n",
      "pred: 0, GT: 0 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 0, GT: 0 == True\n",
      "pred: 1, GT: 2 == False\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 2, GT: 2 == True\n",
      "pred: 2, GT: 2 == True\n",
      "pred: 0, GT: 0 == True\n",
      "pred: 2, GT: 2 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 0, GT: 0 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 0, GT: 0 == True\n",
      "pred: 0, GT: 0 == True\n",
      "pred: 2, GT: 2 == True\n",
      "pred: 0, GT: 0 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 2, GT: 2 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 0, GT: 0 == True\n",
      "pred: 1, GT: 1 == True\n",
      "pred: 2, GT: 2 == True\n",
      "pred: 1, GT: 1 == True\n"
     ]
    }
   ],
   "source": [
    "assert len(prediction_values[0]) == len(label_values[0]), \"wrong size\"\n",
    "for i,pred in enumerate(prediction_values[0]):\n",
    "    gt = label_values[0][i]\n",
    "    print(\"pred: {}, GT: {} == {}\".format(pred, gt, pred == gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#tensorboard --logdir \"./slow\"\n",
    "# bad idea since I would need to stop it also..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used to wipe logs / TF board\n",
    "#shutil.rmtree(hyp_params['out_dir'], ignore_errors = True) # start fresh each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_edge",
   "language": "python",
   "name": "dl_edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
