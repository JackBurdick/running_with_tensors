{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: (3, 6, 5, 'final', 0)\n",
      "TensorFlow: 1.8.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "# download data\n",
    "from six.moves.urllib.request import urlopen\n",
    "\n",
    "# set env log level to supress messages, unless an error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# set tf log level\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Helper to make the output consistent\n",
    "SEED = 42\n",
    "def reset_graph(seed=SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "reset_graph()\n",
    "\n",
    "# helper to create dirs if they don't already exist\n",
    "def maybe_create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"{} created\".format(dir_path))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(dir_path))\n",
    "        \n",
    "def maybe_fetch_data(url, file, dir_path):\n",
    "    maybe_create_dir(dir_path)\n",
    "    if not os.path.exists(file):\n",
    "        # download and write data\n",
    "        raw = urlopen(url).read()\n",
    "        with open(file, \"wb\") as f:\n",
    "            f.write(raw)\n",
    "        print(file, \"path written\")\n",
    "    else:\n",
    "        print(\"{} already exists. Please rm to download new data\".format(file))\n",
    "    \n",
    "\n",
    "# Version information\n",
    "print(\"Python: {}\".format(sys.version_info[:]))\n",
    "assert \"1.4\" <= tf.__version__, \"TensorFlow r1.4 or later is needed\"\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "\n",
    "# Check if using GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU found')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../ROOT_DATA/IRIS already exists\n",
      "../ROOT_DATA/IRIS/iris_training.csv already exists. Please rm to download new data\n",
      "../ROOT_DATA/IRIS already exists\n",
      "../ROOT_DATA/IRIS/iris_test.csv already exists. Please rm to download new data\n"
     ]
    }
   ],
   "source": [
    "## Download data paths\n",
    "ROOT_DATA = \"../ROOT_DATA/\"\n",
    "DATA_DIR = os.path.join(ROOT_DATA, \"IRIS\")\n",
    "\n",
    "IRIS_TRAINING_PATH = os.path.join(DATA_DIR, \"iris_training.csv\")\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST_PATH = os.path.join(DATA_DIR, \"iris_test.csv\")\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "maybe_fetch_data(IRIS_TRAINING_URL, IRIS_TRAINING_PATH, DATA_DIR)\n",
    "maybe_fetch_data(IRIS_TEST_URL, IRIS_TEST_PATH, DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hyper_params(start_fresh=False):\n",
    "    global maybe_create_dir\n",
    "    data_params = {}\n",
    "    data_params['n_epochs'] = 500\n",
    "    data_params['batch_size'] = 32\n",
    "    data_params['buffer_size'] = 128 # for shuffling\n",
    "    data_params['init_lr'] = 1e-2\n",
    "    \n",
    "    # dataset information, this is known information that will be \n",
    "    # used for the features. Header usually includes this info..\n",
    "    data_params['feature_names'] = [\n",
    "        'SepalLength',\n",
    "        'SepalWidth',\n",
    "        'PetalLength',\n",
    "        'PetalWidth']\n",
    "    \n",
    "    data_params['out_dir'] = \"./iris_custom_est\"\n",
    "    \n",
    "    # by default, the project will NOT start fresh\n",
    "    if start_fresh:\n",
    "        if os.path.exists(data_params['out_dir']):\n",
    "            shutil.rmtree(data_params['out_dir'], ignore_errors = True)\n",
    "\n",
    "    if not os.path.exists(data_params['out_dir']):\n",
    "        os.makedirs(data_params['out_dir'])\n",
    "        print(\"{} created\".format(data_params['out_dir']))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(data_params['out_dir']))\n",
    "    \n",
    "    return data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def my_input_fn(file_path, predict=False):\n",
    "    global hyp_params\n",
    "    if hyp_params['feature_names']:\n",
    "        feat_types = [[0.]]*len(hyp_params['feature_names']) + [[0]]\n",
    "        # [[0.0], [0.0], [0.0], [0.0], [0]]\n",
    "        # [feat1, feat2, feat3, feat4, label]\n",
    "    else:\n",
    "        pass\n",
    "        # TODO: this could read the csv header\n",
    "    \n",
    "    def decode_csv(line):\n",
    "        parsed_line = tf.decode_csv(line, feat_types)\n",
    "        label = parsed_line[-1]  # Last element is the label\n",
    "        features = parsed_line[:-1]  # all but last element\n",
    "        d = dict(zip(hyp_params['feature_names'], features)), label\n",
    "        return d\n",
    "\n",
    "    dataset = (tf.data.TextLineDataset(file_path)  # Read text file\n",
    "        .skip(1)  # Skip header row\n",
    "        .map(decode_csv)  # Decode each line using custom decode_csv\n",
    "        .shuffle(hyp_params['buffer_size'])  # (1 == no operation)\n",
    "              )\n",
    "    if predict:\n",
    "        dataset = (dataset.repeat(1))\n",
    "    else:\n",
    "        dataset = (dataset.repeat(hyp_params['n_epochs']))    # Repeats dataset this # times\n",
    "        \n",
    "    dataset = (dataset.batch(hyp_params['batch_size'])\n",
    "        .prefetch(1)  # Make sure you always have 1 batch ready to serve\n",
    "    )\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model_fn(\n",
    "    features, # This is batch_features from input_fn\n",
    "    labels,   # This is batch_labels from input_fn\n",
    "    mode # instance of tf.estimator.ModeKeys\n",
    "    ):    # hyper parameters\n",
    "    \n",
    "    global hyp_params\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        tf.logging.info(\"my_model_fn: PREDICT, {}\".format(mode))\n",
    "    elif mode == tf.estimator.ModeKeys.EVAL:\n",
    "        tf.logging.info(\"my_model_fn: EVAL, {}\".format(mode))\n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        tf.logging.info(\"my_model_fn: TRAIN, {}\".format(mode))\n",
    "\n",
    "    # TODO: this needs to be customized\n",
    "    if hyp_params['feature_names']:\n",
    "        feature_columns = [\n",
    "            tf.feature_column.numeric_column(hyp_params['feature_names'][0]),\n",
    "            tf.feature_column.numeric_column(hyp_params['feature_names'][1]),\n",
    "            tf.feature_column.numeric_column(hyp_params['feature_names'][2]),\n",
    "            tf.feature_column.numeric_column(hyp_params['feature_names'][3])\n",
    "        ]\n",
    "    else:\n",
    "        pass\n",
    "        # TODO: this logic may have already been performed and\n",
    "        # could read the csv header\n",
    "\n",
    "    # TODO: core model architecture logic\n",
    "    # Create the layer of input\n",
    "    input_layer = tf.feature_column.input_layer(features, feature_columns)\n",
    "    h1 = tf.layers.dense(inputs=input_layer, units=10, activation=tf.nn.selu)\n",
    "    h2 = tf.layers.dense(inputs=h1, units=10, activation=tf.nn.selu)\n",
    "    # TODO: this could be len(features)\n",
    "    logits = tf.layers.dense(inputs=h2, units=3)\n",
    "\n",
    "    # class_ids will be the model prediction for the class (Iris flower type)\n",
    "    # The output node with the highest value is our prediction\n",
    "    predictions = { 'class_ids': tf.argmax(input=logits, axis=1), 'in_data': tf.identity(input=input_layer) }\n",
    "\n",
    "    # 1. Prediction mode, Return our prediction. no need to add other ops\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "    # --- Evaluation and Training mode\n",
    "    # Calculate the loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(labels, predictions['class_ids'])\n",
    "\n",
    "    # 2. Evaluation mode\n",
    "    # Return our loss (which is used to evaluate our model)\n",
    "    # Set the TensorBoard scalar my_accurace to the accuracy\n",
    "    # Obs: This function only sets value during mode == ModeKeys.EVAL\n",
    "    # To set values during training, see tf.summary.scalar\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops={'my_accuracy': accuracy})\n",
    "\n",
    "    # If mode is not PREDICT nor EVAL, then we must be in TRAIN\n",
    "    assert mode == tf.estimator.ModeKeys.TRAIN, \"TRAIN is only ModeKey left\"\n",
    "\n",
    "    # 3. Training mode\n",
    "    # Provide global step counter (used to count gradient updates)\n",
    "    #optimizer = tf.train.AdagradOptimizer(0.05)\n",
    "    optimizer = tf.train.AdamOptimizer(hyp_params['init_lr'])\n",
    "    train_op = optimizer.minimize(\n",
    "        loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "\n",
    "    # Set the TensorBoard scalar my_accuracy to the accuracy\n",
    "    # Obs: This function only sets the value during mode == ModeKeys.TRAIN\n",
    "    # To set values during evaluation, see eval_metrics_ops\n",
    "    tf.summary.scalar('my_accuracy', accuracy[1])\n",
    "\n",
    "    # Return training operations: loss and train_op\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode,\n",
    "        loss=loss,\n",
    "        train_op=train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./iris_custom_est created\n"
     ]
    }
   ],
   "source": [
    "hyp_params = create_hyper_params(start_fresh=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:START estimator construction\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './iris_custom_est', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe2b3cc0b70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:... END estimator construction\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"START estimator construction\")\n",
    "classifier = tf.estimator.Estimator(\n",
    "    model_fn=my_model_fn,\n",
    "    model_dir=hyp_params['out_dir'])  # Path to where checkpoints etc are stored\n",
    "tf.logging.info(\"... END estimator construction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:START classifier.train\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:my_model_fn: TRAIN, train\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into ./iris_custom_est/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.377738, step = 0\n",
      "INFO:tensorflow:global_step/sec: 393.238\n",
      "INFO:tensorflow:loss = 0.17761636, step = 100 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.392\n",
      "INFO:tensorflow:loss = 0.12993188, step = 200 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 308.074\n",
      "INFO:tensorflow:loss = 0.02929898, step = 300 (0.324 sec)\n",
      "INFO:tensorflow:global_step/sec: 311.446\n",
      "INFO:tensorflow:loss = 0.13593495, step = 400 (0.327 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.382\n",
      "INFO:tensorflow:loss = 0.026356565, step = 500 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.046\n",
      "INFO:tensorflow:loss = 0.12579603, step = 600 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.62\n",
      "INFO:tensorflow:loss = 0.07545714, step = 700 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 416.316\n",
      "INFO:tensorflow:loss = 0.09272083, step = 800 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 518.247\n",
      "INFO:tensorflow:loss = 0.0760297, step = 900 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.537\n",
      "INFO:tensorflow:loss = 0.082953155, step = 1000 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 550.706\n",
      "INFO:tensorflow:loss = 0.011738388, step = 1100 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.537\n",
      "INFO:tensorflow:loss = 0.043962028, step = 1200 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.454\n",
      "INFO:tensorflow:loss = 0.071825154, step = 1300 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 485.647\n",
      "INFO:tensorflow:loss = 0.027890787, step = 1400 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 468.921\n",
      "INFO:tensorflow:loss = 0.028165659, step = 1500 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.94\n",
      "INFO:tensorflow:loss = 0.054571357, step = 1600 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.949\n",
      "INFO:tensorflow:loss = 0.049220853, step = 1700 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.528\n",
      "INFO:tensorflow:loss = 0.021909133, step = 1800 (0.214 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1875 into ./iris_custom_est/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.23883224.\n",
      "INFO:tensorflow:... END classifier.train\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"START classifier.train\")\n",
    "classifier.train(\n",
    "    input_fn=lambda: my_input_fn(IRIS_TRAINING_PATH))\n",
    "tf.logging.info(\"... END classifier.train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:START classifier.evaluate\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:my_model_fn: EVAL, eval\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-06-17:05:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./iris_custom_est/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-06-17:05:12\n",
      "INFO:tensorflow:Saving dict for global step 1875: global_step = 1875, loss = 0.062088244, my_accuracy = 0.96666664\n",
      "INFO:tensorflow:... END classifier.evaluate\n",
      "INFO:tensorflow:Evaluation results\n",
      "INFO:tensorflow:   loss, was: 0.062088243663311005\n",
      "INFO:tensorflow:   my_accuracy, was: 0.9666666388511658\n",
      "INFO:tensorflow:   global_step, was: 1875\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our model using the examples contained in FILE_TEST\n",
    "# Return value will contain evaluation_metrics such as: loss & average_loss\n",
    "tf.logging.info(\"START classifier.evaluate\")\n",
    "evaluate_result = classifier.evaluate(\n",
    "    input_fn=lambda: my_input_fn(IRIS_TEST_PATH))\n",
    "tf.logging.info(\"... END classifier.evaluate\")\n",
    "tf.logging.info(\"Evaluation results\")\n",
    "for key in evaluate_result:\n",
    "    tf.logging.info(\"   {}, was: {}\".format(key, evaluate_result[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Prediction on test file\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:my_model_fn: PREDICT, infer\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./iris_custom_est/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:...I think: [5.  2.  5.7 2.5], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [5.7 2.5 6.7 3.3], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [1.1 0.1 4.3 3. ], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [4.9 2.  5.6 2.8], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [4.5 1.5 5.6 3. ], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [4.  1.3 5.5 2.5], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [4.9 1.5 6.3 2.5], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [4.6 1.4 6.1 3. ], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [4.3 1.3 6.2 2.9], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [3.5 1.  5.7 2.6], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [5.4 2.1 6.9 3.1], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [1.4 0.2 5.1 3.5], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [4.  1.  6.  2.2], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [1.7 0.5 5.1 3.3], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [3.9 1.2 5.8 2.7], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [5.6 1.8 6.3 2.9], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [1.5 0.1 5.2 4.1], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [5.9 2.1 7.1 3. ], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [4.5 1.6 6.  3.4], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [4.1 1.3 5.6 3. ], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [5.8 1.8 6.7 2.5], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [1.4 0.2 5.5 4.2], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [4.  1.3 5.5 2.3], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [4.3 1.3 6.4 2.9], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [5.1 1.5 6.3 2.8], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [1.9 0.2 4.8 3.4], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [4.2 1.5 5.9 3. ], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [4.7 1.5 6.7 3.1], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [1.5 0.2 5.1 3.4], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [1.7 0.2 5.4 3.4], is Iris Setosa\n"
     ]
    }
   ],
   "source": [
    "# Predict the type of some Iris flowers.\n",
    "# predict the examples in FILE_TEST, repeat only once (predict=True).\n",
    "predict_results = classifier.predict(\n",
    "    input_fn=lambda: my_input_fn(IRIS_TEST_PATH, predict=True))\n",
    "tf.logging.info(\"Prediction on test file\")\n",
    "for idx, prediction in enumerate(predict_results):\n",
    "    # Will print the predicted class, i.e: 0, 1, or 2 if the prediction\n",
    "    # is Iris Setosa, Vericolor, Virginica, respectively.    \n",
    "    iris_type = prediction[\"class_ids\"]  # Get the predicted class (index)\n",
    "    if iris_type == 0:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Setosa\".format(prediction['in_data']))\n",
    "    elif iris_type == 1:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Versicolor\".format(prediction['in_data']))\n",
    "    else:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Virginica\".format(prediction['in_data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_input = [[5.9, 3.0, 4.2, 1.5],  # -> 1, Iris Versicolor\n",
    "                    [6.9, 3.1, 5.4, 2.1],  # -> 2, Iris Virginica\n",
    "                    [5.1, 3.3, 1.7, 0.5],  # -> 0, Iris Setosa\n",
    "                    [5.7, 2.5, 6.7, 3.3]]  # -> 2, Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_input_fn():\n",
    "    global hyp_params\n",
    "    def decode(x):\n",
    "        # TODO: this is hardcoded currently\n",
    "        x = tf.split(x, 4)  # Need to split into our 4 features\n",
    "        return dict(zip(hyp_params['feature_names'], x))  # To build a dict of them\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(prediction_input)\n",
    "    dataset = dataset.map(decode)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    next_feature_batch = iterator.get_next()\n",
    "    return next_feature_batch, None  # In prediction, we have no labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all our prediction_input\n",
    "predict_results = classifier.predict(input_fn=new_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Predictions on memory\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:my_model_fn: PREDICT, infer\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./iris_custom_est/model.ckpt-1875\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:...I think: [5.9, 3.0, 4.2, 1.5], is Iris Versicolor\n",
      "INFO:tensorflow:...I think: [6.9, 3.1, 5.4, 2.1], is Iris Virginica\n",
      "INFO:tensorflow:...I think: [5.1, 3.3, 1.7, 0.5], is Iris Setosa\n",
      "INFO:tensorflow:...I think: [5.7, 2.5, 6.7, 3.3], is Iris Virginica\n"
     ]
    }
   ],
   "source": [
    "tf.logging.info(\"Predictions on memory\")\n",
    "for idx, prediction in enumerate(predict_results):\n",
    "    type = prediction[\"class_ids\"]  # Get the predicted class (index)\n",
    "    if type == 0:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Setosa\".format(prediction_input[idx]))\n",
    "    elif type == 1:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Versicolor\".format(prediction_input[idx]))\n",
    "    else:\n",
    "        tf.logging.info(\"...I think: {}, is Iris Virginica\".format(prediction_input[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%bash\n",
    "#tensorboard --logdir \"./slow\"\n",
    "# bad idea since I would need to stop it also..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used to wipe logs / TF board\n",
    "#shutil.rmtree(\"./slow\", ignore_errors = True) # start fresh each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_edge",
   "language": "python",
   "name": "dl_edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
