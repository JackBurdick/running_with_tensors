{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: (3, 5, 4, 'final', 0)\n",
      "TensorFlow: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this is a custom cell that contains the common imports I personally \n",
    "# use these may/may not be necessary for the following examples\n",
    "\n",
    "# DL framework\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# common packages\n",
    "import numpy as np\n",
    "import os # handling file i/o\n",
    "import sys\n",
    "import math\n",
    "import time # timing epochs\n",
    "import random\n",
    "\n",
    "# for ordered dict when building layer components\n",
    "import collections\n",
    "\n",
    "# plotting pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors # making colors consistent\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # colorbar helper\n",
    "\n",
    "\n",
    "# from imageio import imread # read image from disk\n",
    "# + data augmentation\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "\n",
    "\n",
    "import pickle # manually saving best params\n",
    "from sklearn.utils import shuffle # shuffling data batches\n",
    "from tqdm import tqdm # display training progress bar\n",
    "\n",
    "# const\n",
    "SEED = 42\n",
    "\n",
    "# Helper to make the output consistent\n",
    "def reset_graph(seed=SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# helper to create dirs if they don't already exist\n",
    "def maybe_create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"{} created\".format(dir_path))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(dir_path))\n",
    "    \n",
    "def make_standard_dirs(saver=True, best_params=True, tf_logs=True):\n",
    "    # `saver/` will hold tf saver files\n",
    "    maybe_create_dir(\"saver\")\n",
    "    # `best_params/` will hold a serialized version of the best params\n",
    "    # I like to keep this as a backup in case I run into issues with\n",
    "    # the saver files\n",
    "    maybe_create_dir(\"best_params\")\n",
    "    # `tf_logs/` will hold the logs that will be visable in tensorboard\n",
    "    maybe_create_dir(\"tf_logs\")\n",
    "\n",
    "    \n",
    "# set tf log level to supress messages, unless an error\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Important Version information\n",
    "print(\"Python: {}\".format(sys.version_info[:]))\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "\n",
    "# Check if using GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saver already exists\n",
      "best_params already exists\n",
      "tf_logs already exists\n"
     ]
    }
   ],
   "source": [
    "make_standard_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS_PATH = \"new_best_params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these two functions (get_model_params and restore_model_params) are \n",
    "# ad[a|o]pted from; \n",
    "# https://github.com/ageron/handson-ml/blob/master/11_deep_learning.ipynb\n",
    "def get_model_params():\n",
    "    global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {global_vars.op.name: value for global_vars, value in \n",
    "            zip(global_vars, tf.get_default_session().run(global_vars))}\n",
    "\n",
    "def restore_model_params(model_params, g, sess):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: g.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    sess.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "# these two functions are used to manually save the best\n",
    "# model params to disk\n",
    "def save_obj(obj, name):\n",
    "    with open('best_params/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('best_params/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte.gz\n",
      "train-images-idx3-ubyte.gz\n",
      "train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "ROOT_DATA = \"../../ROOT_DATA/\"\n",
    "DATA_DIR = \"mnist_data\"\n",
    "\n",
    "MNIST_TRAINING_PATH = os.path.join(ROOT_DATA, DATA_DIR)\n",
    "# ensure we have the correct directory\n",
    "for _, _, files in os.walk(MNIST_TRAINING_PATH):\n",
    "    files = sorted(files)\n",
    "    for filename in files:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../ROOT_DATA/mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets(MNIST_TRAINING_PATH, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_hyper_params():\n",
    "    data_params = {}\n",
    "    data_params['n_epochs'] = 50\n",
    "    data_params['batch_size'] = 128\n",
    "    data_params['buffer_size'] = 128 # for shuffling\n",
    "\n",
    "    data_params['init_lr'] = 1e-2\n",
    "\n",
    "    return data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(data_params):\n",
    "    g = tf.Graph()\n",
    "    n_outputs = 10\n",
    "    IMG_HEIGHT = 28\n",
    "    IMG_WIDTH = 28\n",
    "    CHANNELS = 1\n",
    "    with g.as_default():\n",
    "        with tf.name_scope(\"inputs\"):\n",
    "            X = tf.placeholder(tf.float32, shape=(None, 784), name=\"data\") # Input\n",
    "            X_reshaped = tf.reshape(X, shape=[-1, IMG_HEIGHT, IMG_WIDTH, CHANNELS])\n",
    "            y = tf.placeholder(tf.int32, shape=(None, n_outputs), name=\"labels\") # Target\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            h_1 = tf.layers.conv2d(X_reshaped, filters=32, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_1\")\n",
    "            h_2 = tf.layers.conv2d(h_1, filters=64, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_2\")\n",
    "            h_3 = tf.layers.conv2d(h_1, filters=36, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=2, name=\"conv_3\")\n",
    "            h_4 = tf.layers.max_pooling2d(h_3, pool_size=[2,2],\n",
    "                                          strides=2, name=\"max_pool_01\")\n",
    "            last_shape = int(np.prod(h_4.get_shape()[1:]))\n",
    "            h_4_flat = tf.reshape(h_4, shape=[-1, last_shape])\n",
    "            h_5 = tf.layers.dense(h_4_flat, 64, name=\"layer_05\", activation=tf.nn.elu)\n",
    "            logits = tf.layers.dense(h_5, n_outputs, name=\"logits\")\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            batch_loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(data_params['init_lr'])\n",
    "            training_op = optimizer.minimize(batch_loss)\n",
    "            \n",
    "        with tf.name_scope(\"save_session\"):\n",
    "            init_global = tf.global_variables_initializer()\n",
    "            init_local = tf.local_variables_initializer()\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "        # Ops: training metrics\n",
    "        with tf.name_scope(\"metrics\"):\n",
    "            # ================================== performance\n",
    "            with tf.name_scope(\"common\"):\n",
    "                preds = tf.nn.softmax(logits, name=\"prediction\")\n",
    "                y_true_cls = tf.argmax(y,1)\n",
    "                y_pred_cls = tf.argmax(preds,1)\n",
    "                correct_prediction = tf.equal(y_pred_cls, y_true_cls, name=\"correct_predictions\")\n",
    "                batch_acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            with tf.name_scope(\"train_metrics\") as scope:\n",
    "                train_auc, train_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                train_acc, train_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                train_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_met_reset_op = tf.variables_initializer(train_acc_vars, name=\"train_met_reset_op\")\n",
    "            with tf.name_scope(\"val_metrics\") as scope:\n",
    "                val_auc, val_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                val_acc, val_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                val_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_met_reset_op = tf.variables_initializer(val_acc_vars, name=\"val_met_reset_op\")\n",
    "            with tf.name_scope(\"test_metrics\") as scope:\n",
    "                test_auc, test_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                test_acc, test_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                test_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_acc_reset_op = tf.variables_initializer(test_acc_vars, name=\"test_met_reset_op\")\n",
    "\n",
    "            # =============================================== loss \n",
    "            with tf.name_scope(\"train_loss_eval\") as scope:\n",
    "                train_mean_loss, train_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                train_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_loss_reset_op = tf.variables_initializer(train_loss_vars, name=\"train_loss_reset_op\")\n",
    "            with tf.name_scope(\"val_loss_eval\") as scope:\n",
    "                val_mean_loss, val_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                val_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_loss_reset_op = tf.variables_initializer(val_loss_vars, name=\"val_loss_reset_op\")\n",
    "            with tf.name_scope(\"test_loss_eval\")as scope:\n",
    "                test_mean_loss, test_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                test_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_loss_reset_op = tf.variables_initializer(test_loss_vars, name=\"test_loss_rest_op\")\n",
    "\n",
    "        # --- create collections\n",
    "        for node in (saver, init_global, init_local):\n",
    "            g.add_to_collection(\"save_init\", node)\n",
    "        for node in (X, X_reshaped, y, training_op):\n",
    "            g.add_to_collection(\"main_ops\", node)\n",
    "        for node in (preds, y_true_cls, y_pred_cls):\n",
    "            g.add_to_collection(\"preds\", node)\n",
    "        for node in (train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op):\n",
    "            g.add_to_collection(\"train_metrics\", node)\n",
    "        for node in (val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op):\n",
    "            g.add_to_collection(\"val_metrics\", node)\n",
    "        for node in (test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op):\n",
    "            g.add_to_collection(\"test_metrics\", node)\n",
    "        for node in (train_mean_loss, train_mean_loss_update, train_loss_reset_op):\n",
    "            g.add_to_collection(\"train_loss\", node)\n",
    "        for node in (val_mean_loss, val_mean_loss_update, val_loss_reset_op):\n",
    "            g.add_to_collection(\"val_loss\", node)\n",
    "        for node in (test_mean_loss, test_mean_loss_update, test_loss_reset_op):\n",
    "            g.add_to_collection(\"test_loss\", node)\n",
    "        g.add_to_collection(\"logits\", logits)\n",
    "            \n",
    "        # ===================================== tensorboard\n",
    "        with tf.name_scope(\"tensorboard_writer\") as scope:\n",
    "            epoch_train_loss_scalar = tf.summary.scalar('train_epoch_loss', train_mean_loss)\n",
    "            epoch_train_acc_scalar = tf.summary.scalar('train_epoch_acc', train_acc)\n",
    "            epoch_train_auc_scalar = tf.summary.scalar('train_epoch_auc', train_auc)\n",
    "            epoch_train_write_op = tf.summary.merge([epoch_train_loss_scalar, epoch_train_acc_scalar, epoch_train_auc_scalar], name=\"epoch_train_write_op\")\n",
    "\n",
    "            # ===== epoch, validation\n",
    "            epoch_validation_loss_scalar = tf.summary.scalar('validation_epoch_loss', val_mean_loss)\n",
    "            epoch_validation_acc_scalar = tf.summary.scalar('validation_epoch_acc', val_acc)\n",
    "            epoch_validation_auc_scalar = tf.summary.scalar('validation_epoch_auc', val_auc)\n",
    "            epoch_validation_write_op = tf.summary.merge([epoch_validation_loss_scalar, epoch_validation_acc_scalar, epoch_validation_auc_scalar], name=\"epoch_validation_write_op\")\n",
    "        \n",
    "        for node in (epoch_train_write_op, epoch_validation_write_op):\n",
    "            g.add_to_collection(\"tensorboard\", node)\n",
    "            \n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_graph(g):\n",
    "    global BEST_PARAMS_PATH\n",
    "    saver, init_global, init_local = g.get_collection(\"save_init\")\n",
    "    X, X_reshaped, y, training_op = g.get_collection(\"main_ops\")\n",
    "    preds, y_true_cls, y_pred_cls = g.get_collection(\"preds\")\n",
    "    train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op = g.get_collection(\"train_metrics\")\n",
    "    val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op = g.get_collection(\"val_metrics\")\n",
    "    train_mean_loss, train_mean_loss_update, train_loss_reset_op = g.get_collection(\"train_loss\")\n",
    "    val_mean_loss, val_mean_loss_update, val_loss_reset_op = g.get_collection(\"val_loss\")\n",
    "    epoch_train_write_op, epoch_validation_write_op = g.get_collection(\"tensorboard\")\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(os.path.join(\"tf_logs\",\"train\"))\n",
    "    val_writer = tf.summary.FileWriter(os.path.join(\"tf_logs\",\"validation\"))\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    with tf.Session(graph=g) as sess:\n",
    "        sess.run([init_global, init_local])\n",
    "        \n",
    "        for e in tqdm(range(1,data_params['n_epochs']+1)):\n",
    "            sess.run([val_met_reset_op,val_loss_reset_op,train_met_reset_op,train_loss_reset_op])\n",
    "            \n",
    "            n_batches = int(MNIST.train.num_examples/data_params['batch_size'])\n",
    "            for i in range(1, n_batches+1):\n",
    "                data, target = MNIST.train.next_batch(data_params['batch_size'])\n",
    "                sess.run([training_op, train_auc_update, train_acc_update, train_mean_loss_update], feed_dict={X:data, y:target})\n",
    "        \n",
    "            # write average for epoch\n",
    "            summary = sess.run(epoch_train_write_op)    \n",
    "            train_writer.add_summary(summary, e)\n",
    "            train_writer.flush()\n",
    "\n",
    "            # run validation\n",
    "            n_batches = int(MNIST.validation.num_examples/data_params['batch_size'])\n",
    "            for i in range(1,n_batches+1):\n",
    "                Xb, yb = MNIST.validation.next_batch(data_params['batch_size'])\n",
    "                sess.run([val_auc_update, val_acc_update, val_mean_loss_update], feed_dict={X:data, y:target})\n",
    "\n",
    "            # check for (and save) best validation params here\n",
    "            cur_loss, cur_acc = sess.run([val_mean_loss, val_acc])\n",
    "            if cur_loss < best_val_loss:\n",
    "                best_val_loss = cur_loss\n",
    "                best_params = get_model_params()\n",
    "                save_obj(best_params, BEST_PARAMS_PATH)\n",
    "                print(\"best params saved: acc: {:.3f}% loss: {:.4f}\".format(cur_acc*100, cur_loss))\n",
    "\n",
    "            summary = sess.run(epoch_validation_write_op) \n",
    "            val_writer.add_summary(summary, e)\n",
    "            val_writer.flush()\n",
    "        \n",
    "        train_writer.close()\n",
    "        val_writer.close()\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:04<03:33,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 89.844% loss: 0.3478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 2/50 [00:08<03:12,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 89.844% loss: 0.3413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 3/50 [00:11<03:03,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 96.875% loss: 0.1485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:27<02:46,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 98.438% loss: 0.0724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [00:38<02:33,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 96.094% loss: 0.0719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:45<02:25,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 99.219% loss: 0.0431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [01:23<01:55,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 99.219% loss: 0.0400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 22/50 [01:29<01:53,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 99.219% loss: 0.0330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [01:49<01:32,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [01:57<01:24,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [02:48<00:32,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [03:18<00:00,  3.96s/it]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "data_params = create_hyper_params()\n",
    "g = build_graph(data_params)\n",
    "sess = train_graph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "This is a checkpoint - in that training can be skipped if previous best params are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 120.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 99.953% acc: 98.518% loss: 0.04541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "data_params = create_hyper_params()\n",
    "g2 = build_graph(data_params)\n",
    "best_params = load_obj(BEST_PARAMS_PATH)\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "    X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "    preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "    test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "    test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "    \n",
    "    restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "    sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "    \n",
    "    n_batches = int(MNIST.test.num_examples/data_params['batch_size'])\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        Xb, yb = MNIST.test.next_batch(data_params['batch_size'])\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "    # print\n",
    "    final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "    print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                              final_test_acc*100,\n",
    "                                                              final_test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Sample Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEj+EEj+E+hcCnalwnc/eIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe601e4beb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_idx = 26\n",
    "some_image = MNIST.test.images[some_idx]\n",
    "some_label_enc = MNIST.test.labels[some_idx]\n",
    "some_label_dec = np.argmax(some_label_enc)\n",
    "some_digit_image = some_image.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the current architecture classify the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function needs some work, but it currently serves it's purpose\n",
    "def display_figure_and_prob(img, probs, save_path):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "    ax1.imshow(img, cmap = matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "    y_pos = np.arange(10)\n",
    "    ax2.bar(y_pos, probs, align='center', alpha=0.5)\n",
    "    plt.title('Confidence')\n",
    "    plt.grid('off')\n",
    "    plt.tight_layout()\n",
    "    save_path = \"./output_images/\" + save_path + \".png\"\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 100.000% acc: 100.000% loss: 0.00475\n",
      "true_class: [4]\n",
      "pred_class [4]\n",
      "confidence: 99.5265%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAEYCAYAAABGExyUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe60210ef60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_model(img, label):\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g2 = build_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g2) as sess:\n",
    "        saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "        X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "        logz = g2.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "        Xb, yb = np.expand_dims(img,0), np.expand_dims(label, 0)\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "        pred_value, true_cls_value, pred_cls_value = sess.run([preds, y_true_cls, y_pred_cls],\n",
    "                                                              feed_dict={X:Xb,y:yb})\n",
    "        logits_val = sess.run([logz], feed_dict={X:Xb,y:yb})[0]\n",
    "        print\n",
    "        final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "        print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                                   final_test_acc*100,\n",
    "                                                                   final_test_loss))\n",
    "        pred_idx = pred_cls_value[0]\n",
    "        print(\"true_class: {}\\npred_class {}\".format(true_cls_value, pred_cls_value))\n",
    "        \n",
    "        confidence = pred_value[0][pred_idx]*100\n",
    "        print(\"confidence: {:.4f}%\".format(confidence))\n",
    "\n",
    "        jack = np.argmax(pred_value[0])\n",
    "        name = \"mnist_\" + str(jack) + \"_conf_\" + str(confidence)\n",
    "        display_figure_and_prob(some_digit_image, pred_value[0], name)\n",
    "        \n",
    "    return pred_idx, confidence\n",
    "        \n",
    "pred_label, pred_confidence = test_model(some_image, some_label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_adv_graph(data_params):\n",
    "    g = tf.Graph()\n",
    "    n_outputs = 10\n",
    "    IMG_HEIGHT = 28\n",
    "    IMG_WIDTH = 28\n",
    "    CHANNELS = 1\n",
    "    with g.as_default():\n",
    "        with tf.name_scope(\"inputs\"):\n",
    "            #X = tf.placeholder(tf.float32, shape=(None, 784), name=\"data\") # Input\n",
    "            #X_reshaped = tf.reshape(X, shape=[-1, IMG_HEIGHT, IMG_WIDTH, CHANNELS])\n",
    "            Xx = tf.Variable(tf.zeros((28, 28, 1)))\n",
    "            Xxx = tf.expand_dims(Xx, 0)\n",
    "            y = tf.placeholder(tf.int32, shape=(None, n_outputs), name=\"labels\") # Target\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            h_1 = tf.layers.conv2d(Xxx, filters=32, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_1\")\n",
    "            h_2 = tf.layers.conv2d(h_1, filters=64, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_2\")\n",
    "            h_3 = tf.layers.conv2d(h_1, filters=36, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=2, name=\"conv_3\")\n",
    "            h_4 = tf.layers.max_pooling2d(h_3, pool_size=[2,2],\n",
    "                                          strides=2, name=\"max_pool_01\")\n",
    "            last_shape = int(np.prod(h_4.get_shape()[1:]))\n",
    "            h_4_flat = tf.reshape(h_4, shape=[-1, last_shape])\n",
    "            h_5 = tf.layers.dense(h_4_flat, 64, name=\"layer_05\", activation=tf.nn.elu)\n",
    "            logits = tf.layers.dense(h_5, n_outputs, name=\"logits\")\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            batch_loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(data_params['init_lr'])\n",
    "            training_op = optimizer.minimize(batch_loss)\n",
    "            \n",
    "        with tf.name_scope(\"save_session\"):\n",
    "            init_global = tf.global_variables_initializer()\n",
    "            init_local = tf.local_variables_initializer()\n",
    "            saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.name_scope(\"adv\"):\n",
    "            x = tf.placeholder(tf.float32, (28, 28, 1), name=\"jack\") # Input\n",
    "            x_hat = Xx\n",
    "            assign_op = tf.assign(x_hat, x)\n",
    "\n",
    "            y_hat = tf.placeholder(tf.int32, ())\n",
    "            labels = tf.one_hot(y_hat, 10)\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels, name=\"adv_loss\")\n",
    "            optim_step = tf.train.GradientDescentOptimizer(1e-1).minimize(loss, var_list=[Xx])\n",
    "            \n",
    "            epsilon = tf.placeholder(tf.float32, ())\n",
    "            below = x - epsilon\n",
    "            above = x + epsilon\n",
    "            projected = tf.clip_by_value(tf.clip_by_value(x_hat, below, above), 0, 1)\n",
    "\n",
    "            with tf.control_dependencies([projected]):\n",
    "                project_step = tf.assign(x_hat, projected)\n",
    "                \n",
    "            for node in (assign_op, x, optim_step, loss, y_hat, epsilon, x_hat, project_step):\n",
    "                g.add_to_collection(\"adv\", node)\n",
    "\n",
    "        # Ops: training metrics\n",
    "        with tf.name_scope(\"metrics\"):\n",
    "            # ================================== performance\n",
    "            with tf.name_scope(\"common\"):\n",
    "                preds = tf.nn.softmax(logits, name=\"prediction\")\n",
    "                y_true_cls = tf.argmax(y,1)\n",
    "                y_pred_cls = tf.argmax(preds,1)\n",
    "                correct_prediction = tf.equal(y_pred_cls, y_true_cls, name=\"correct_predictions\")\n",
    "                batch_acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            with tf.name_scope(\"train_metrics\") as scope:\n",
    "                train_auc, train_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                train_acc, train_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                train_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_met_reset_op = tf.variables_initializer(train_acc_vars, name=\"train_met_reset_op\")\n",
    "            with tf.name_scope(\"val_metrics\") as scope:\n",
    "                val_auc, val_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                val_acc, val_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                val_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_met_reset_op = tf.variables_initializer(val_acc_vars, name=\"val_met_reset_op\")\n",
    "            with tf.name_scope(\"test_metrics\") as scope:\n",
    "                test_auc, test_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                test_acc, test_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                test_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_acc_reset_op = tf.variables_initializer(test_acc_vars, name=\"test_met_reset_op\")\n",
    "\n",
    "            # =============================================== loss \n",
    "            with tf.name_scope(\"train_loss_eval\") as scope:\n",
    "                train_mean_loss, train_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                train_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_loss_reset_op = tf.variables_initializer(train_loss_vars, name=\"train_loss_reset_op\")\n",
    "            with tf.name_scope(\"val_loss_eval\") as scope:\n",
    "                val_mean_loss, val_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                val_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_loss_reset_op = tf.variables_initializer(val_loss_vars, name=\"val_loss_reset_op\")\n",
    "            with tf.name_scope(\"test_loss_eval\")as scope:\n",
    "                test_mean_loss, test_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                test_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_loss_reset_op = tf.variables_initializer(test_loss_vars, name=\"test_loss_rest_op\")\n",
    "\n",
    "        # --- create collections\n",
    "        for node in (saver, init_global, init_local):\n",
    "            g.add_to_collection(\"save_init\", node)\n",
    "        for node in (X, Xx, y, training_op):\n",
    "            g.add_to_collection(\"main_ops\", node)\n",
    "        for node in (preds, y_true_cls, y_pred_cls):\n",
    "            g.add_to_collection(\"preds\", node)\n",
    "        for node in (train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op):\n",
    "            g.add_to_collection(\"train_metrics\", node)\n",
    "        for node in (val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op):\n",
    "            g.add_to_collection(\"val_metrics\", node)\n",
    "        for node in (test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op):\n",
    "            g.add_to_collection(\"test_metrics\", node)\n",
    "        for node in (train_mean_loss, train_mean_loss_update, train_loss_reset_op):\n",
    "            g.add_to_collection(\"train_loss\", node)\n",
    "        for node in (val_mean_loss, val_mean_loss_update, val_loss_reset_op):\n",
    "            g.add_to_collection(\"val_loss\", node)\n",
    "        for node in (test_mean_loss, test_mean_loss_update, test_loss_reset_op):\n",
    "            g.add_to_collection(\"test_loss\", node)\n",
    "        g.add_to_collection(\"logits\", logits)\n",
    "            \n",
    "        # ===================================== tensorboard\n",
    "        with tf.name_scope(\"tensorboard_writer\") as scope:\n",
    "            epoch_train_loss_scalar = tf.summary.scalar('train_epoch_loss', train_mean_loss)\n",
    "            epoch_train_acc_scalar = tf.summary.scalar('train_epoch_acc', train_acc)\n",
    "            epoch_train_auc_scalar = tf.summary.scalar('train_epoch_auc', train_auc)\n",
    "            epoch_train_write_op = tf.summary.merge([epoch_train_loss_scalar, epoch_train_acc_scalar, epoch_train_auc_scalar], name=\"epoch_train_write_op\")\n",
    "\n",
    "            # ===== epoch, validation\n",
    "            epoch_validation_loss_scalar = tf.summary.scalar('validation_epoch_loss', val_mean_loss)\n",
    "            epoch_validation_acc_scalar = tf.summary.scalar('validation_epoch_acc', val_acc)\n",
    "            epoch_validation_auc_scalar = tf.summary.scalar('validation_epoch_auc', val_auc)\n",
    "            epoch_validation_write_op = tf.summary.merge([epoch_validation_loss_scalar, epoch_validation_acc_scalar, epoch_validation_auc_scalar], name=\"epoch_validation_write_op\")\n",
    "        \n",
    "        for node in (epoch_train_write_op, epoch_validation_write_op):\n",
    "            g.add_to_collection(\"tensorboard\", node)\n",
    "            \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1045/50000 [00:02<01:55, 425.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000, loss=0.036253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2055/50000 [00:04<01:50, 434.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000, loss=0.0360171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3063/50000 [00:06<01:47, 438.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000, loss=0.035759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4059/50000 [00:09<01:44, 437.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4000, loss=0.0357264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5066/50000 [00:11<01:42, 438.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5000, loss=0.0356782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6021/50000 [00:13<01:40, 435.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6000, loss=0.0356666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7068/50000 [00:16<01:40, 426.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7000, loss=0.0356649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8076/50000 [00:18<01:37, 428.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8000, loss=0.0356275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9054/50000 [00:21<01:36, 424.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9000, loss=0.0356482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10084/50000 [00:23<01:34, 422.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000, loss=0.0356613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11065/50000 [00:26<01:32, 422.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11000, loss=0.0356412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12064/50000 [00:28<01:29, 424.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12000, loss=0.0356924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13058/50000 [00:30<01:26, 425.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13000, loss=0.0356875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14066/50000 [00:32<01:24, 426.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14000, loss=0.035673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15059/50000 [00:35<01:21, 427.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15000, loss=0.0356572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16088/50000 [00:37<01:19, 427.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16000, loss=0.0356306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17067/50000 [00:40<01:17, 424.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17000, loss=0.0356651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18054/50000 [00:42<01:15, 424.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18000, loss=0.0356475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19072/50000 [00:44<01:12, 424.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19000, loss=0.0356296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20063/50000 [00:47<01:10, 424.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20000, loss=0.0355922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21049/50000 [00:49<01:08, 423.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 21000, loss=0.0356358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22080/50000 [00:52<01:05, 424.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22000, loss=0.0356353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23044/50000 [00:54<01:03, 424.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 23000, loss=0.0356192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24070/50000 [00:57<01:01, 421.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24000, loss=0.0355962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25083/50000 [00:59<00:59, 421.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25000, loss=0.0355877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26045/50000 [01:01<00:56, 422.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26000, loss=0.035621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27047/50000 [01:04<00:54, 420.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 27000, loss=0.0355791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28046/50000 [01:06<00:52, 420.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 28000, loss=0.0356361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29029/50000 [01:09<00:49, 419.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 29000, loss=0.0355936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30058/50000 [01:12<00:47, 416.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30000, loss=0.0356211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31075/50000 [01:14<00:45, 415.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 31000, loss=0.0356236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32063/50000 [01:17<00:43, 415.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32000, loss=0.0356046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33025/50000 [01:19<00:40, 415.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 33000, loss=0.0356342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34067/50000 [01:22<00:38, 413.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 34000, loss=0.0355954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35069/50000 [01:24<00:36, 412.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35000, loss=0.0355927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36042/50000 [01:27<00:33, 412.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 36000, loss=0.0356458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37033/50000 [01:30<00:31, 410.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 37000, loss=0.0355906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38040/50000 [01:32<00:29, 410.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 38000, loss=0.0356242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39059/50000 [01:35<00:26, 409.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 39000, loss=0.0356264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40071/50000 [01:37<00:24, 409.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40000, loss=0.0355874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41046/50000 [01:40<00:21, 409.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 41000, loss=0.0356091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42073/50000 [01:43<00:19, 408.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 42000, loss=0.0355999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43066/50000 [01:45<00:16, 408.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 43000, loss=0.035607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44056/50000 [01:47<00:14, 409.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44000, loss=0.0356234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45050/50000 [01:49<00:12, 410.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 45000, loss=0.0355929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46073/50000 [01:52<00:09, 410.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46000, loss=0.0356327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47057/50000 [01:54<00:07, 410.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 47000, loss=0.0356168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48066/50000 [01:56<00:04, 411.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48000, loss=0.0356276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49080/50000 [01:59<00:02, 411.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49000, loss=0.0355859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [02:01<00:00, 411.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50000, loss=0.0356427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def produce_targeted_adv_image(img, adv_target=0,adv_eps=0.07,adv_lr=1e-1,adv_steps=50000):\n",
    "    \n",
    "    #TODO: learning rate is currently hardcoded\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g3 = build_adv_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g3) as sess:\n",
    "        saver, init_global, init_local = g3.get_collection(\"save_init\")\n",
    "        X, Xx, y, training_op = g3.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g3.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g3.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g3.get_collection(\"test_loss\")\n",
    "        logz = g3.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g3, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "\n",
    "        # execution\n",
    "        assign_op, x, optim_step, loss, y_hat, epsilon, x_hat, project_step = g3.get_collection(\"adv\")\n",
    "\n",
    "        # initialization step\n",
    "        sess.run(assign_op, feed_dict={x: img})\n",
    "\n",
    "        # projected gradient descent\n",
    "        for i in tqdm(range(1, adv_steps+1)):\n",
    "            # gradient descent step\n",
    "            _, loss_value = sess.run(\n",
    "                [optim_step, loss],\n",
    "                feed_dict={y_hat: adv_target})\n",
    "            # project step\n",
    "            sess.run(project_step, feed_dict={x: img, epsilon: adv_eps})\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print('step %d, loss=%g' % (i+1, loss_value))\n",
    "\n",
    "        adv_out = x_hat.eval() # retrieve the adversarial example\n",
    "        \n",
    "    return adv_out\n",
    "adv_out = produce_targeted_adv_image(some_image.reshape(28,28,1), adv_target=9)\n",
    "adv_flat = adv_out.reshape((784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 88.889% acc: 0.000% loss: 3.46935\n",
      "true_class: [4]\n",
      "pred_class [9]\n",
      "confidence: 96.4996%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAEYCAYAAABGExyUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLdZ7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe6017a9828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_adversarial(img, label):\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g2 = build_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g2) as sess:\n",
    "        saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "        X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "        logz = g2.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "        Xb, yb = np.expand_dims(img,0), np.expand_dims(label, 0)\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "        pred_value, true_cls_value, pred_cls_value = sess.run([preds, y_true_cls, y_pred_cls],\n",
    "                                                              feed_dict={X:Xb,y:yb})\n",
    "        logits_val = sess.run([logz], feed_dict={X:Xb,y:yb})[0]\n",
    "\n",
    "        final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "        print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                                   final_test_acc*100,\n",
    "                                                                   final_test_loss))\n",
    "        pred_idx = pred_cls_value[0]\n",
    "        print(\"true_class: {}\\npred_class {}\".format(true_cls_value, pred_cls_value))\n",
    "        confidence = pred_value[0][pred_idx]*100\n",
    "        print(\"confidence: {:.4f}%\".format(confidence))\n",
    "\n",
    "        jack = np.argmax(pred_value[0])\n",
    "        name = \"mnist_\" + str(jack) + \"_conf_\" + str(confidence) + \"_adv\"\n",
    "        display_figure_and_prob(adv_flat.reshape(28, 28), pred_value[0], name)\n",
    "\n",
    "    return pred_idx, confidence\n",
    "\n",
    "a_pred_label, a_pred_confidence = test_adversarial(adv_flat, some_label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAAEtCAYAAAAP0yF9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xm8HFWZ//HvN4GwJAQCCcgWAooL\n4oAakPmhA+PCoKMiCioOCuKICow6M6iog6IOio6izuCgKBhUFpGoMOMGgwuIgCTsm4oQtrAkkgSS\nsCV5fn/Uaehc7q1Tt7pud997P+/XK6/cW+f0qafqdj9dp6q6H0eEAAAAAADDN6HXAQAAAADAaMWE\nCgAAAABqYkIFAAAAADUxoQIAAACAmphQAQAAAEBNTKgAAAAAoCYmVABQk+1Dbf+213Hk2P667WMr\n9v217X8c6Zh6ZTj7osP1HGf7eyXtC2y/cqTj6IaxtC0YvWzPsf3vPVx/6WseYxsTKqylG2+MJB30\nuzSpWGJ7vV7H0oSIeG9EfKaJsWzvaPts24tsP2T7T7b/y/Y2TYzfpMEmvE3uCwDdVyU/297b9t3d\njKtMN+PhBEdvMKECgDa2Z0l6maSQ9PoexbBOg2NNbHCsZ0m6QtJCSS+MiKmS9pT0Z0kvbWo9FWNp\nbB/hKSO5X23Psr1gpMbH2Net/Ex+wXAxocKgWmd2bX8xnQm63far29p/bftztn9ve5nt82xvmtqe\ndiamdcbE9r6SPibpLbaX2762u1sGZL1D0uWS5kg6pL3B9ma2z09XZn4v6ZltbV+3/cUB/c+z/S/p\n561sz01Xdm63/f62fsfZPtf292w/JOlQ27vbnpfWdb/tE9v6/8D2fem1d7Ht57e1zbF9su2f2l4h\n6W/bb4WxPc32/6Y4lqSfq15dOk7SpRHxLxFxtyRFxAMR8ZWIOLsthtfavsb2Utu/s/1XbW0LbB9t\n+7oU//dtrz+Mx37E9nWSVthex/Yxtv9s+2HbN9neP/V9nqSvS/rrlGuWtu2ff28b8922b7X9YPrb\nbtXWFrbfm67CLbH9NduuuK8kaf20fQ/bvsr2LoN1GiSmtXJo2XOnU0M89ya07de/2D6nld/TY95u\n+47U9vGmYgEqGDI/t9ieLOlnkrZKr/3l6TU05PPaxWQ/bL/L9p2SfpmW75Hy0FLb19reu20929v+\nTXp9XyhpetWNcHEM9Rnbl6bHX2B7+oBYDre90Pa9tv+17bFD5gvb35U0U9L/pO3+cNWY0BkmVCjz\nEkl/UJEkviDp1AEHE++QdJikrSStkvSfuQEj4ueSPivp+xExJSIGPcAAeugdks5I//7O9hZtbV+T\n9KikLVU89w9raztTxYkCS8XERdI+ks62PUHS/0i6VtLWkl4h6YO2/67t8ftJOlfSJmndX5X01XQV\n6JmSzmnr+zNJO0raXNJVqX+7t0k6XtJGkgZ+xmuCpG9L2k7FG+8jkk7K7ZTklZLmlnWw/SJJp0l6\nj6TNJH1D0vle+/acN0vaV9L2kv5K0qHDeOxBkv5e0iYRsUrF1bGXSdpY0qckfc/2lhFxs6T3Sros\n5ZpNBon15ZI+l+LZUtIdks4e0O21knaTtEvq93fpsTPTQdbMkt2xn6QfSNpUxfPjx7bXLen/NLnn\nju2XtiaLHRj43Hu/pDdI2ktFfl+i4rkv2ztJOlnS21PbZpKenJA3FA8wlLL8LEmKiBWSXi1pYXrt\nT4mIhSp5XrfZS9Lz0thbS/qJpH9X8Ro+WtJc2zNS3zMlzVdxjPQZDTHBK/E2Se9UkccnpfHb/a2K\nPL+PpGNc4Ta+iHi7pDslvS5t9xeGGRNqYkKFMndExDcjYrWk01UccLQnr+9GxA0peR0r6c1u8PYi\noNtsv1TFROOciJiv4mD9baltoqQ3SfpERKyIiBtUvC5aLlFxG8rL0u8HqDiYX6jigHxGRHw6Ih6P\niNskfVPSW9sef1lE/Dgi1kTEI5KekPQs29MjYnlEXN7qGBGnRcTDEfGYiqtGu9jeuG2s8yLi0jTW\no+3bGBF/iYi5EbEyIh5WMfHaq+Iumi7pvrb9dVSaVCy3/c20+N2SvhERV0TE6og4XdJjkvZoG+c/\nI2JhRDyoYrKw6zAfe1faR4qIH6Sx1kTE9yX9SdLuFbfnHySdFhFXpX35URVXtGa19TkhIpZGxJ2S\nftWKNSLujIhN0vKhzI+IcyPiCUknSlp/wLZUUfrciYjfDjZZHKaBz733SPp4RNzd9hw7wMVtUAdI\n+t+IuDi1HStpTWughuIBnqYsP1dU9rxuOS7l90ckHSzppxHx0/TauFDSPEmvSSdSdpN0bEQ8FhEX\nq8hlw/HtiPhjWtc5eioPtnwqxXK9ipNgBw1zfHQREyqUefLAKSJWph+ntLXf1fbzHZLW1TAueQN9\n6BBJF0TE4vT7mXrqrOMMSevo6c97SVJEhIqrG603vbfpqStH26m4/WRp65+KW1/bT1C0jytJ75L0\nbEm32L7S9mulYmJn+4R028pDkhak/u2vvYFjPcn2hra/kW7ZekjSxZI2qXgy5C8qTqy0tvmkdPD8\nFRWv/9a2/uuAbd1WxRnhlvvafl6pp/JKlceutW223+GnbhFcKmlnVc9DW2ntv+HytI1bV4i1iidj\njYg1ku7W2ttSRZXnzpPabnFanrl6Nmicbev8Udv6bpa0Oq1zK629XStU7LNB2X5b2zjXSZrZvi3D\niBEoy89VlD2vW+4a0P/AAa+9l6rIgVtJWpKe/y13aHhyuWXge81wcwe6iA/doRPbtv08U8UZ9cWS\nVkjasNWQDtRmtPWNrkQHDIPtDVTc0jXRduuNbj0Vk41dJN2g4tbWbSXdktoHHgyeJekC2yeouGV2\n/7T8Lkm3R8SOJSGs9bqIiD9JOijd8vVGSefa3iz9vJ+K2+8WqLjVbYkkDzXWAP8q6TmSXhIR99ne\nVdLVAx4/lIvS+r9d0ucuScdHxPEVxqvz2Ce3zfZ2Kq7WvELFVZbVtq/RU9uSyzULVRw0tcabrOIW\ntntqxD6YJ3Nk+jtuk9Y50Fo5U9Iz2n6u8tx5UkQMZ8L35MMG/H6XpMMi4tKBHW3fq+KWqNbvG6rY\nZ0PFc6aKA9/WFwr8OiJm1YgR41guP0fEwM9jD/baL3tezxrkcXepuBPn3YP0307SNNuT2yZVM4dY\nb10D32tauaMsX6jhGFARV6jQiYNt75TeUD8t6dx0e+AfVXwY++/T5wX+TUXia7lf0qx0gAH0izeo\nOFu5k4pbL3ZVceB4iaR3pOf2DyUdl67y7KQBZ0cj4mpJiyR9S9IvIqL1WZLfS3rIxRcqbJCuMu1s\ne7ehgrF9sO0Z6cpGa5zVKj4X9ZiKqwIbqvhM4nBspOJzU0tdfCD7k8N47HGSXmb7xPT5Arn4IPXz\n2vp8U9J7bb/EhckpF2xUYfzhPnayioOHRSmWd6q4QtVyv6RtbE8a4vFnSnqn7V1dfE7rs5KuiIgF\nFWKt4sW235huKfqgir/b5YP0u0bFbUSb2n5G6tsy7OfOQC6+zOPQYcT9dUnHp4NG2Z5he7/Udq6k\n17r4rNQkFbmfXI6RVpqfB+l/v6TNvPat0GXP68F8T9LrbP9det2t7+ILILaJiDtU3P73KduTXNyO\n+LpON3KAY9N7zfNVfNbq+2l5Wb6Qim3foeFYkEESRCe+q+Kbdu5T8dmA90tSRCyTdISKg8p7VJxN\naf/Wvx+k//9i+6puBQtkHKLinvY7I+K+1j8VX9jwD+mg+CgVt2Xcp+K5P9iVmrNUXD06s7UgTcZe\np+Ig4HYVV3K/peLq0lD2lXSj7eUqvqDirenzUN9RcfvHPZJu0uAH6GW+ImmDFMPlkn5e9YER8UcV\nnwHaRtK1th+WdKmKM6fHpj7zVHwW6iQVV85uVfrSiQrjD+uxEXGTpC9JukzFQcQLUjwtv5R0o6T7\nbC8e5PEXpbjnSrpXxZd/vHVgv8G4+FKK3G1150l6S9qWt0t6Y/o81UDfVfGlEwskXaCnDpyyzx3b\nL0vPkaHinKTiCtJwnidflXS+iqutD6fHviTFc6OkI1U8v+9N29b+jYSl8QA1VcnPT4qIW1Tk4tvS\n7XpbqeR5PZiIuEvF3QAfU3HS5i5JH9JTx85vS49/UMWJqe80trWF36jIgRdJ+mJEXJCWD5kvks9J\n+re03QO/6AIjxMVt/8Dw2P61pO9FxLd6HQsAYHDpzPmREcEH2oFRIN1+eLukdaP4JlOMAnyGCgCA\nMSoifqunf3U+AKBB3PIHAAAAADVxyx8AAAAA1MQVKgAAAACoiQkVAAAAANTU0ZdS2N5XxddQTpT0\nrYg4oaz/9OnTY9asWZ2sEkCPzJ8/f3FEzMj37I5h5x+baqK98OIX9zqC6u68M99n0aLO17PuuuXt\nTwz2zeo9Mm1aefsOI1/uZsGCBVq8eHGVwtNdM5z8s9lmm8XMmWXfro+RMHHixF6HUNmaNWuyfcbb\nR3Ts8pf8hAnduSZU9din9oTK9kRJX5P0KhU1KK60fX6qCzKoWbNmad68eXVXCaCHbN/R6xhaauUf\nFVUY0V1x5ejZ6z7yiHynk0/ufEXTp5e333tv5+toyiteUdoc5/ygtL0Ju+02e8TXMRzDzT8zZ87U\nL3/5y26GCEnTcicD+sjKlSuzfR577LGO15ObpPTTpG3SpKHqsRcmT57clTiqHvt0Mr3bXdKtEXFb\nRDwu6WwVBdAAYKSRfwD0CvkHwFo6mVBtraJqdMvdaRkAjDTyD4BeIf8AWEsnE6rBrhs+7Vqh7cNt\nz7M9b1ET954DQJ3804WgAIwL2fzTnnsWL17cpbAA9EonE6q7JW3b9vs2khYO7BQRp0TE7IiYPWNG\n33yeHcDoNvz807XQAIxx2fzTnnum5z4zB2DU62RCdaWkHW1vb3uSpLdKOr+ZsACgFPkHQK+QfwCs\npfa3/EXEKttHSfqFiq8NPS0ibmwsMgAYAvkHQK+QfwAM1FEdqoj4qaSfNhQLAFRG/gHQK+QfAO06\nmlABwHgSa/I1OjwhU390jz3yK7r88vL2ww/Pj3HKKfk+XeBjPpLtEyd8vvP15Pa7JG25ZXl7E/Wf\nVq3K92niMzWZejKSpFxNmTlz8mMcemh5GMsfzo8xdWq+D0pVqam0ZMmS0vZ11skf8q3KPH/XW2+9\n7BhN1EtqwiOPPJLts8EGG3S8ntx+l/JFaKsU9s2p8hxZunRpx+tpQpUaUitWrOh4jCp/m6Z0p8ww\nAAAAAIxBTKgAAAAAoCYmVAAAAABQExMqAAAAAKiJCRUAAAAA1MSECgAAAABqYkIFAAAAADVRhwrA\n+PCMZ0jvfGd5n899rrTZz9giv55zzilvP//8/Bi77lre/tvfZodopGZWE77whXyfBupQVXLsseXt\nRxyRH2OffcrbK9T6yTr33HyfhQvzfd7//vL23LZIUq4+Tqa+DiTbWn/99Uv7PProo6XtVeoH5ery\nPPHEE9kxcnWmcnWqpGZqZjUht0+lZupQVZH7+69cuTI7xrrrrlva3sQ+nTJlSrZPlZpZue3JbYuU\nfx51s8ZUFWRCAAAAAKiJCRUAAAAA1MSECgAAAABqYkIFAAAAADUxoQIAAACAmphQAQAAAEBNTKgA\nAAAAoCYmVAAAAABQE4V9AYwP992XLdyb9cAD+T5veUt5+zOfmR/j1lurxVPCn/5UvtNnP1ve/rGP\ndRxHlQLDXVOlcG/OBRd0PkbO8cfn+1QojJn10EP5Pltt1fl6xrmIqFRkNjdGzooVK0rbJ1Qowlyl\naGtOEwV1H3nkkY7jqFJguFuqFO7NqVKYuVNN7PcqqjyfqxSz7idcoQIAAACAmphQAQAAAEBNTKgA\nAAAAoCYmVAAAAABQExMqAAAAAKiJCRUAAAAA1MSECgAAAABqog4VADRp7tzS5njD/l0Jw6pQ/6lC\nXZrRokq9K09wFyJpwNVX5/tMn975ep773GyXvqgjttvsXkcwKkyZMqW0fd0mapc1ZMmSJb0OoTFV\n6l2Nlu1dvXp1to/deR5dtmxZtk8/1RGrYuy8mwIAAABAlzGhAgAAAICamFABAAAAQE1MqAAAAACg\nJiZUAAAAAFATEyoAAAAAqIkJFQAAAADUxIQKAAAAAGrqqLCv7QWSHpa0WtKqiKD6HoCuGHb+efGL\nFVfOKx9zYuYcU4WihzlVCu6GOi+cWGUMr1kz4nH0kyaK1HajOHBfFNNFqeHkn4kTJ2aLlOYKv462\nIqc5Y217cprY3m4UBx5vf5cmdTShSv42IhY3MA4ADBf5B0CvkH8ASOKWPwAAAACordMJVUi6wPZ8\n24c3ERAAVET+AdAr5B8AT+r0lr89I2Kh7c0lXWj7loi4uL1DSjSHS9LMmTM7XB0APIn8A6BXSvMP\nuQcYXzq6QhURC9P/D0j6kaTdB+lzSkTMjojZM2bM6GR1APAk8g+AXsnlH3IPML7UnlDZnmx7o9bP\nkvaRdENTgQHAUMg/AHqF/ANgoE5u+dtC0o9st8Y5MyJ+3khUAFCO/AOgV8g/ANZSe0IVEbdJ2qXB\nWDBCPvKRj2T7rFixorT9pJNOaiocoGMjln9+9avy9tNOy49x443l7VtvnR3C739/eYdnPSsfxxvf\nmO/zla+UtzdQD2lChfsg+qXeVZX6T+OtRpQPe2d5hzlz8oNk6p2NNiORfzbaaKPS9scffzw7xupM\nnbw0ASy1/vrrl7YvW7YsO8akSZOyfR599NHS9ibqIX3+85/P9rn22mtL27/2ta91HEcVVbZ3vNWI\nyh2XVnlNdHOf8bXpAAAAAFATEyoAAAAAqIkJFQAAAADUxIQKAAAAAGpiQgUAAAAANTGhAgAAAICa\nmFABAAAAQE1MqAAAAACgptqFfTF6nH322dk+L3jBC7oQCdBDd94pH3lEaZf42n+Xj/E3ezUY0NCs\nTPHYD30oP8iRR+b7HH10tYAwbsVp3y7vkGuX5Be9sHwdV109nJBGnTVr1mjlypWlfTbccMMuRdOZ\nXOFfSVpvvfUaGadTVY59uhEH6pk8eXJH7ZL00EMPlbZPnTp1WDGV4QoVAAAAANTEhAoAAAAAamJC\nBQAAAAA1MaECAAAAgJqYUAEAAABATUyoAAAAAKAmJlQAAAAAUBMTKgAAAACoicK+Y8All1xS2v6X\nv/wlO8aXv/zlpsLpuT/84Q/ZPldeeWVp+8EHH9xUOOgXM2fmC/f2iwcfLG2OI4/KDuHfX5Ffz/Ll\n5e1bbZ0dYkIDp+VyhYxD7nwlVeKY0KX1ZLZ3zZquhFGJt96qtD3uWZgdY6wX7s2ZMGHCqCncG1H+\n3KxStHf16tUdr2eddfKHpzfccENp++LFi7NjXHPNNdk+3bBkyZKOx7jllluyfZYuXVra/upXv7rj\nOJqybNmy0vaNN944O0aThXtzuEIFAAAAADUxoQIAAACAmphQAQAAAEBNTKgAAAAAoCYmVAAAAABQ\nExMqAAAAAKiJCRUAAAAA1EQdqjHgox/9aGn7C17wguwYW2yxRVPh9Nx73/vebJ/f/e53pe1V9tku\nu+xSOSagpVKto+c+t3yMKVPyY8ybVzGikvXsvnu2T+j35WNkai5JUnY15asYc6rU9mqiVlUTdbcq\njfHAA6XNMX1Gx3Egr0qto4kTJ3a8nip1qJqI48ADDyxtr/I+vtlmm5W2N1EfqluqHPvcf//9pe25\nGp2StO2221aOaShN7NcqY2yyySal7XZztQe5QgUAAAAANTGhAgAAAICamFABAAAAQE1MqAAAAACg\nJiZUAAAAAFATEyoAAAAAqIkJFQAAAADUxIQKAAAAAGrKFva1fZqk10p6ICJ2Tss2lfR9SbMkLZD0\n5ogYPdXPRpHzzjsv2ydXpPaPf/xjdoypU6dWjqnfrVq1Kttn8uTJpe0U7e0Pjeaf+fM7L2Ra4bWk\no4/ubB2SdMstHQ8Ra/IFdXOqFJiNO+8qbz/gJfkxLr8iE0g+jtEk1EAxySp/m8xzoMpzpIniv9p8\n8/J1dL6GEdFU/lm9enXHhUw33njjbJ+VK1d2tA6pmaK806ZN63iMSy65JNvnlkyePOOMMzqOYzR5\n4oknsn1yhX2nVCgaX+W5nHsOVHmONFH8d+nSpR2PUVWVt6k5kvYdsOwYSRdFxI6SLkq/A0DT5oj8\nA6A35oj8A6CC7IQqIi6W9OCAxftJOj39fLqkNzQcFwCQfwD0DPkHQFV1b6TYIiLulaT0f/n1fABo\nDvkHQK+QfwA8zYjfmW77cNvzbM9btGjRSK8OAJ60Vv7pdTAAxo323LN48eJehwNghNWdUN1ve0tJ\nSv8/MFTHiDglImZHxOwZM2bUXB0APKle/ulaeADGsEr5pz33TJ8+vasBAui+uhOq8yUdkn4+RFL+\nq+gAoBnkHwC9Qv4B8DTZCZXtsyRdJuk5tu+2/S5JJ0h6le0/SXpV+h0AGkX+AdAr5B8AVWXrUEXE\nQUM0vaLhWDCIo446Ktvn3e9+d2n79ttv31Q4QFf1Xf559rN7sto6GqkfpAp1imZuW9p+/fWZGlOS\ndm4k1gasWZPtkqsh1cx+b4Z3yOT+BQu6Esdo1U/5Z9myZd1eZW1N1A+qcuxzzDHl31j/ohe9KDtG\nE7E2oYnaXf0k93xdUyHXjjZjrFwiAAAAAHQPEyoAAAAAqIkJFQAAAADUxIQKAAAAAGpiQgUAAAAA\nNTGhAgAAAICamFABAAAAQE1MqAAAAACgpmxhX4ysk046qbR94cKF2TE+8pGPlLZPnDhxWDEBQFOe\n//wGBnnhC7NdYv5V2T7ZorsTKpxjXFNe7NgViiHn5IoHV9YvhXv/+Z/L2089tbx9+fLmYkFf+K//\n+q/S9iaOfZpQ5fhp6tSp2T65AsJVCgzniv/uuOOO2TEee+yxbJ8m9Evh3vXXX7+0vcn9wRUqAAAA\nAKiJCRUAAAAA1MSECgAAAABqYkIFAAAAADUxoQIAAACAmphQAQAAAEBNTKgAAAAAoCbqUPXYCSec\nUNr+rne9KzvGdttt11Q4I+7ee+8tbb/ooouyY3zpS18qbb/55puzY7zvfe/L9sEYs+mm0mteU9ol\nvvPd0vZsHaMqli7N99lkk87XM2dOtosPPaTj1Vx/fcdDKDK1nfpJlVJVfeOCC8rb99mn83Vk6glJ\nUhx5VHmHL51Y3r7b7GEE1H9sa9KkSaV9Jk+eXNpepU5RziYV8srSKvkpI7ctknTuueeWtlc59qmy\nPTm52k5Nueeee0rbf/nLX2bHOO+880rbb7rppuwYRxxxRLZPEzbaaKPS9ocffrjjdWy44YbZPuut\nt15p+wYbbNBxHC2j6a0BAAAAAPoKEyoAAAAAqIkJFQAAAADUxIQKAAAAAGpiQgUAAAAANTGhAgAA\nAICamFABAAAAQE1MqAAAAACgJgr79tiKFStK2z/60Y9mx5g4cWLHcTzyyCOl7XPnzs2OkSu4K0l3\n3HFHafvmm2+eHWOvvfYqbb/mmmuyY7z+9a/P9sEYM2OG9J73dDRE1wrQZtbjxYuyQ8T0Gfn1HFox\nnhLPf37nYzRSMHkUCXVpe3OFey+5JDtE7PnS0nZvXuF5lins6796Qfnjb701v44+ZjtbYDSnWwVo\nc+uJyOdAO//8Xr58eWl7lWOfJixcuLC0PVeAWJJOPDFTmFr5Y58ZM/Kvo1yx46uvvjo7xk477ZTt\n04Rc4d5c4V9JWmed8ilKlSLUudfdQw89lB2jKq5QAQAAAEBNTKgAAAAAoCYmVAAAAABQExMqAAAA\nAKiJCRUAAAAA1MSECgAAAABqYkIFAAAAADUxoQIAAACAmrKFfW2fJum1kh6IiJ3TsuMkvVtSq7rk\nxyLipyMV5GhVpcDsypUrS9svvfTS7BhnnXVWafujjz6aHeOHP/xhafvixYuzY7z97W/P9jnggANK\n23fZZZfsGN/73vdK20855ZTsGBgdGs0/U6bki5QqU7RyQgPnoD74wWyXOPHL5e0VivY2EWqVmofj\nrShvE26/rfx5tv0ODe3Txx8vb580KTtEE5H4i/9R3uGGGxpYS/Oayj+2s0VKc5YsWdLR46V8kVNJ\n2nDDDUvbqxTtvfPOO7N9csc+P/nJT7JjzJ8/v7T9sccey44xd+7c0va//OUv2TEOPvjgbJ8DDzyw\ntH3XXXfNjnHZZZeVtn/jG9/IjlGlgHATcgWim3g+V5E7/l29enVj66ryljtH0r6DLP9yROya/jGZ\nAjAS5oj8A6A35oj8A6CC7IQqIi6W9GAXYgGAtZB/APQK+QdAVZ3cFHKU7etsn2a7/NoeADSL/AOg\nV8g/ANZSd0J1sqRnStpV0r2SvjRUR9uH255ne96iRYuG6gYAVZF/APRKpfxD7gHGl1oTqoi4PyJW\nR8QaSd+UtHtJ31MiYnZEzO7Wh+EAjF3kHwC9UjX/kHuA8aXWhMr2lm2/7i+pP7+iB8CYQ/4B0Cvk\nHwCDqfK16WdJ2lvSdNt3S/qkpL1t7yopJC2Q9J4RjBHAOEX+AdAr5B8AVWUnVBFx0CCLTx2BWMac\nKnUFnvGMZ5S2f+pTn8qOkatvUaW203HHHVfavtdee2XH6NZtDffcc09X1oPe63b+iVzVnTWZOlUV\n+M3l9UiasmZNvk+uVtVGU7tTYypb/6uCKtvbiAbqe+2wQ3l7NPHHk6Rbb82sJ7/fvTjz+Z8pU/Jx\nZGob6ZZbytvf9Kb8OkZAPx3/5Or6VLFixYoGIsmbOXNmts+WW25Z2n7UUUdlx1h33XVL26sc+5xx\nxhml7VWOfSZOnJjt04Qmjn023njj0vYqz7MqNaTWZHJYlfVElOenKjXRcrHm9sdwNPDWAAAAAADj\nExMqAAAAAKiJCRUAAAAA1MSECgAAAABqYkIFAAAAADUxoQIAAACAmphQAQAAAEBNTKgAAAAAoKZs\nYV+MrEsvvbS0PVf4V8oX9h1rfv7zn5e2T548OTvGdttt11Q4wLDEOT/odQiVXfa7fOHXPfbofD3d\nqsnbL975zkyHKkV7c8VwJenZz64UT6nNN+98jJznPnfk14FK743dkjv22TBXDHoc+tnPflbaXuXv\nmzumrFK0t0ox3AlVcljG0qVLOx4jZ9myZY2NxRUqAAAAAKiJCRUAAAAA1MSECgAAAABqYkIFAAAA\nADUxoQIAAACAmphQAQAAAED5o9ReAAAdq0lEQVRNTKgAAAAAoKbxVcCoD22zzTa9DqGvrFq1Ktvn\n0UcfLW3ff//9s2PssMMOlWMCmuQXvTDbJ666uguRSGtGSQEoT3BX1nPF5fm6W6HyWKz8GKedmunz\n7ewQlWpM5WKt5Kqryttf9KL8GN/6Vnn7YYeVt++2W34dyHrooYeyfaZOndqFSEZPnakqdZmaMG3a\ntGyfm266qbT9jW98Y3aMLbbYorS9yvY2UWOqitxzscrzOVeba9KkScOKqQxXqAAAAACgJiZUAAAA\nAFATEyoAAAAAqIkJFQAAAADUxIQKAAAAAGpiQgUAAAAANTGhAgAAAICamFABAAAAQE0U9kVfWb16\ndbZPrvjvww8/3FQ4GGNyRVebKITqTTYu71ChGCF64yV7VPj7H3BAefu5+SHyxYErqFKc/Lbby9cz\nuUJx1cgXKs561rPK23PbsnBh5zGMA0uXLi1tjyb+lhgR9913X7aPXZ4ZunXss2zZsmyfjTcufx/s\nVsHkXBHiKttSeV2NjQQAAAAA4wwTKgAAAACoiQkVAAAAANTEhAoAAAAAamJCBQAAAAA1MaECAAAA\ngJqYUAEAAABATdShQl+pUpvgzjvvLG3fd999mwoHY8n8+VKmJoVf+cryMc4+O7+eTC2YfuJ5V5Z3\n2H337gTSgFiTr7HjCQ3UGTv3Bx2PkfXhD+f7fOELna/ngguyXWLPl5a2+4dz8+t573vL2xcsyI8x\niq1evTr73rbOOuWHY1OmTMmuZ5NNNhlWXL2Uqzn50Ciq1zdt2rRsn9zfv8qxT66O2I477pgdI2f9\n9dfP9nn00Uc7Xs9GG22U7ZN7TTzxxBPZMVauXFnavmbNmuwYVWWvUNne1vavbN9s+0bbH0jLN7V9\noe0/pf/zzygAGAbyD4BeIPcAGI4qt/ytkvSvEfE8SXtIOtL2TpKOkXRRROwo6aL0OwA0ifwDoBfI\nPQAqy06oIuLeiLgq/fywpJslbS1pP0mnp26nS3rDSAUJYHwi/wDoBXIPgOEY1pdS2J4l6YWSrpC0\nRUTcKxWJR9LmTQcHAC3kHwC9QO4BkFN5QmV7iqS5kj4YEZU/LWj7cNvzbM9btGhRnRgBjHON5J+R\nCw/AGNVE7lm8ePHIBQigL1SaUNleV0VCOSMifpgW3297y9S+paQHBntsRJwSEbMjYvaMGTOaiBnA\nONJY/ulOuADGiKZyz/Tp07sTMICeqfItf5Z0qqSbI+LEtqbzJR2Sfj5E0nnNhwdgPCP/AOgFcg+A\n4ahSh2pPSW+XdL3ta9Kyj0k6QdI5tt8l6U5JB45MiADGMfIPgF4g9wCoLDuhiojfShqqGuIrmg0H\n491NN92U7ZMr+Lfffvs1FQ56rOv552MfK28/9tj8GPfcU95+/vn5MSoUqW1CzN6ttL3zMrioI074\nfLaP77uv8xW97GX59WTaqxRU1hvfVC2eoew2u7PH19Dt3LPBBhuUtj/yyCPZMXJFSqsUQq1SpLYJ\nEydO7Mp6Rosbb7wx22fZsmWl7U0c++Seh1IzxXAffvjhjseo8lxdd911O15PVcP6lj8AAAAAwFOY\nUAEAAABATUyoAAAAAKAmJlQAAAAAUBMTKgAAAACoiQkVAAAAANTEhAoAAAAAamJCBQAAAAA1ZQv7\nAt00b968bJ+NN964tH2LLbZoKhyMNy9/eXn78uX5MQ48sOMwrPJiqdGlkruVirY2wBNGTwnheO7z\nStt9y83diWPO6V1ZT06Vv123nkejWa7QaZUipsur5KdRolsFhpcsWdKV9eRUOfZZunRpaXu3jn0m\nT57clfXkVPnbdet5JHGFCgAAAABqY0IFAAAAADUxoQIAAACAmphQAQAAAEBNTKgAAAAAoCYmVAAA\nAABQExMqAAAAAKiJOlQYdQ477LDS9h133LFLkWDcmTIl3+fxx8vbP/CB/BgTys91VanaNJZq/zS1\nLblxKtXDuuWW0uY1a4YTUQdxLF6c7RKbbtZ5MA3Ibs9RR5W333lnc8GMUk3U3Fm5cmUj6+k0jtGk\nqW1pYpxDDjmktH2zzTp/vVf5+2+yySbZPnZ/1BbMbc96663X2Lq4QgUAAAAANTGhAgAAAICamFAB\nAAAAQE1MqAAAAACgJiZUAAAAAFATEyoAAAAAqIkJFQAAAADUxIQKAAAAAGqisC9GnZkzZ/Y6BGBo\nkyaVt1ep/HryyR2HUak4bBN23rm8/YYbuhNHn6iy37OFiu+7L7+iKsU1NUqKO590Uq8jGBNyRUyr\nFJd97LHHRjyOpkycOLG0ffXq1V2Jo1tyxz5NFH8eTUV7m9DE872FK1QAAAAAUBMTKgAAAACoiQkV\nAAAAANTEhAoAAAAAamJCBQAAAAA1MaECAAAAgJqYUAEAAABATdShwqizxx579DoEoL4JDZzHqvIa\nuPzyztdTRRfqTHWtplaXdG17qtQ8y8jWzKpgrP39Rqsm6kOts07+sHHVqlUdr6eKbtSZ6lZNrSqa\nOPbp1vZUqXnWjTG6+ffLvrPb3tb2r2zfbPtG2x9Iy4+zfY/ta9K/14x8uADGE/IPgF4g9wAYjipX\nqFZJ+teIuMr2RpLm274wtX05Ir44cuEBGOfIPwB6gdwDoLLshCoi7pV0b/r5Yds3S9p6pAMDAPIP\ngF4g9wAYjmHdzG97lqQXSroiLTrK9nW2T7M96M2Otg+3Pc/2vEWLFnUULIDxq+P806U4AYwtneae\nxYsXdylSAL1SeUJle4qkuZI+GBEPSTpZ0jMl7ariLM6XBntcRJwSEbMjYvaMGTMaCBnAeNNI/ula\ntADGiiZyz/Tp07sWL4DeqDShsr2uioRyRkT8UJIi4v6IWB0RayR9U9LuIxcmgPGK/AOgF8g9AKqq\n8i1/lnSqpJsj4sS25Vu2ddtf0sh/dy6AcYX8A6AXyD0AhqPKt/ztKentkq63fU1a9jFJB9neVVJI\nWiDpPSMSIYDxjPwDoBfIPQAqc0TnRfuqmj17dsybN69r6wPQHNvzI2J2r+Ooa/bs2XHllZ3lH8/5\ndr7TYYd1tA6gKU0U5e0Hu+02W/PmzRu11YGbOPZ5/PHHs31WrFjR0TqApjRRlLdfVD32Gda3/AEA\nAAAAnsKECgAAAABqYkIFAAAAADUxoQIAAACAmphQAQAAAEBNTKgAAAAAoCYmVAAAAABQU5XCvgAA\nSXHoO7N9TB0q9AlPKC/dNFbqVI0HkyZNyvahDhX6xZIlS0rbx1KdqhauUAEAAABATUyoAAAAAKAm\nJlQAAAAAUBMTKgAAAACoiQkVAAAAANTEhAoAAAAAamJCBQAAAAA1MaECAAAAgJoc0b3CfrYXSbqj\nbdF0SYu7FkBniHVkEGvzRirO7SJixgiM2xXkn64ZLbGOljglYh1ruUcaPX/T0RKnRKwjZbzHWin/\ndHVC9bSV2/MiYnbPAhgGYh0ZxNq80RJnr42m/USszRstcUrEOhaNlv00WuKUiHWkEGs13PIHAAAA\nADUxoQIAAACAmno9oTqlx+sfDmIdGcTavNESZ6+Npv1ErM0bLXFKxDoWjZb9NFrilIh1pBBrBT39\nDBUAAAAAjGa9vkIFAAAAAKNWzyZUtve1/Qfbt9o+pldxVGF7ge3rbV9je16v42ln+zTbD9i+oW3Z\nprYvtP2n9P+0XsbYMkSsx9m+J+3ba2y/ppcxppi2tf0r2zfbvtH2B9LyvtuvJbH23X7tF+SeZpB7\nRsZoyT/knnrIP80g/zRvtOSeTKw92689ueXP9kRJf5T0Kkl3S7pS0kERcVPXg6nA9gJJsyOi776H\n3/bfSFou6TsRsXNa9gVJD0bECSlhT4uIj/QyzhTXYLEeJ2l5RHyxl7G1s72lpC0j4irbG0maL+kN\nkg5Vn+3XkljfrD7br/2A3NMccs/IGC35h9wzfOSf5pB/mjdaco/Un/mnV1eodpd0a0TcFhGPSzpb\n0n49imVUi4iLJT04YPF+kk5PP5+u4knWc0PE2nci4t6IuCr9/LCkmyVtrT7cryWxYnDknoaQe0bG\naMk/5J5ayD8NIf80b7TkHqk/80+vJlRbS7qr7fe71d+JOCRdYHu+7cN7HUwFW0TEvVLxpJO0eY/j\nyTnK9nXpsnjPLyW3sz1L0gslXaE+368DYpX6eL/2ELlnZPX1a2QQff0aGS35h9xTGflnZPXta2QI\nffs6GS25R+qf/NOrCZUHWdbPXze4Z0S8SNKrJR2ZLt+iGSdLeqakXSXdK+lLvQ3nKbanSJor6YMR\n8VCv4ykzSKx9u197jNyDlr5+jYyW/EPuGRbyD1r69nUyWnKP1F/5p1cTqrslbdv2+zaSFvYolqyI\nWJj+f0DSj1Rctu9n96f7S1v3mT7Q43iGFBH3R8TqiFgj6Zvqk31re10VL9IzIuKHaXFf7tfBYu3X\n/doHyD0jqy9fI4Pp59fIaMk/5J5hI/+MrL57jQylX18noyX3SP2Xf3o1obpS0o62t7c9SdJbJZ3f\no1hK2Z6cPvAm25Ml7SPphvJH9dz5kg5JPx8i6bwexlKq9SJN9lcf7FvblnSqpJsj4sS2pr7br0PF\n2o/7tU+Qe0ZW371GhtKvr5HRkn/IPbWQf0ZWX71GyvTj62S05B6pP/NPzwr7uvgqw69ImijptIg4\nvieBZNjeQcWZGUlaR9KZ/RSr7bMk7S1puqT7JX1S0o8lnSNppqQ7JR0YET3/QOQQse6t4tJsSFog\n6T2te3V7xfZLJV0i6XpJa9Lij6m4P7ev9mtJrAepz/ZrvyD3NIPcMzJGS/4h99RD/mkG+ad5oyX3\nSP2Zf3o2oQIAAACA0a5nhX0BAAAAYLRjQgUAAAAANTGhAgAAAICamFABAAAAQE1MqAAAAACgJiZU\nAAAAAFATE6oStlfbvsb2DbZ/YHvDDsba2/b/ZvrMsv2I7WsGLJ9o++r2x9s+w/aDtg8YZJx1bZ9g\n+08p9t/bfnXNuGfYviKt/2W2f2p7k0H6HWf76DrraJLtz6dtvsH2W9qWv9z2VWn56bbXGeLxrb/5\nNbbPb1t+hu0/pMeflip0t9r2Tv1vtP2btGyG7d+m/m9o63ue7a1GZusxmtkO299t+30d24sG5o30\nHLpswLL/tH1s2+8ft/21CutcXrVPyk9vq7ItVaTXzTLbPx2ifT3b37d9a8pBs4bot296bd5q+5i2\n5Ze0vZYX2v5xWu60v261fZ3tF7U95pCUN/9k+5C25b+yvdz27BrbOcf27bbfO5a2C2Ob++D4x/YH\n0vpvtP3BtuX/Yfu+oY45bB9t+5b02Gttv6Nm3OvZ/r+0H95i+1u2dxqk36G2T6qzjiYNtb9S2z+l\nfHKj7S8M8fgFtq9P2zuvbfmmti9M+eNC29PS8kFzju3n2J6f9v1fp2XrpH1Z+3nU9yKCf0P8k7S8\n7eczJP3LgHZLmlBxrL0l/W+mzyxJNwyy/F8knTnw8ZLmSDpgkP4nSDpd0nrp9y0kvbnmPnirpNMr\n9DtO0tE9/nv9vaQLVRQhnCxpnqSpKk4c3CXp2anfpyW9K/c3H7D8NenvbUlnSXpfWr6JpJskzUy/\nb57+f7+kd0vaSNKladnrJH2yl/uIf/37T9JySVdL2iD9/mpJ17S/7tPz7S5JN0vavm35VEm3SdpB\n0vaSbpe0SZV1Vu1TJYcNc3tLx5N0hKSvp5/fKun7g/SZKOnPabsnSbpW0k6D9Jsr6R3p59dI+ll6\nLe8h6Yq0fNO0DzeVNC39PK1tjF9Lml0S7yxJvx5k+Vp5erRtF//G5z/1+PhH0s6SbpC0oYr39P+T\ntGNb+3Ea5JhD0nsl/ULS1PT7xpIOqbkP9pD0mwr9DpV0Uo//XkPuL0l/m35vHRNuPsQYCyRNH2T5\nFyQdk34+RtLn089D5ZwTJb1K0o6S5qZl/1T37zBa/nGFqrpLJD0rnUW52fZ/S7pK0ra297F9mYsr\nID+wPUV68gzjLbZ/K+mNdVZqexsVE4VvVey/oYoD+X+KiMckKSLuj4hzUvtB6QzEDbY/3/a45baP\nT2cULre9he1dVbyQXpPOWGyQzmBMT4/5eDrj8X+SntM21jNt/zydobjE9nPT8jnpbMbvbN/mtqtr\ntj+c4rrW9gll45TYSUXyWxURK1QchOwraTNJj0XEH1O/CyW9qcr+bImIn0Yi6feStklNb5P0w4i4\nM/V7IC1/QtIGktaTtMbFFbEPSvqP4awX487PVLzepaLi+1kD2t8k6X8kna3iYFySFBEPSfq4pJMk\nfU3SJyJi6cDBbW+fctWVtj8zoO1Dafl1tj81SGwnSHpZygX/nHLhJSnvXWX7/9Xc5qHsp+LEkCSd\nK+kVtj2gz+6Sbo2I2yLicRX7Zb8B27WRpJdL+nHbuN9JL+fLJW1ie0tJfyfpwoh4MCKWqMgT+za8\nTWN5uzB29eL453mSLo+IlRGxStJvJO1f4XEfk3REyomKiGURcXqK6RUu7ra53sWdJuul5Qtsfypt\nw/W2n2t7c0nfk7RrynnPtP1rp6u5tt9p+48u7krZs7VyF3enzE259Erbe6blx6V1/jod/7y/7THv\nSHn3Wqe7FIYap+b+ep+kE9qOCR8YYoyhtOes0yW9oW35YDmndfyzoaQnXNzV9DpJ3xnmekcVJlQV\npIPhV0u6Pi16joon0QslrZD0b5JeGREvUnFV5F9sry/pmyqeRC+T9Iy28WbbrjRBkvQVSR+WtKZi\n/2dJurOVTAZsx1aSPq/iTXhXSbv5qdvRJqt4Me4i6WJJ746IayR9QsUZ1F0j4pG2sV6s4oDuhSqS\n5W5tqzpFxYTuxZKOlvTfbW1bSnqppNeqOECTi9sR3yDpJWn9Xygbx/brbX96kG2/VtKrbW+YJn1/\nK2lbSYslreunbms5IC0fzPq256VJ5RsGNrq41e/tkn6eFj1b0rSUJOf7qVsLzlRxIPNzFWfSjlDx\nnFk5xHoBKU2UUv74K0lXDGhvTbLOSj8/KSLOUnEFYmpEfFeD+6qkkyNiN0n3tRba3kfF2cTdVeSG\nF9v+mwGPPUbSJSkXfFnSA5JelfLeWyT9Z9t416hzW6u4Gqd0gLBMxcmRQfskd6dl7faXdFFbThzq\nMVXGasJY3S6MQT08/rlB0t/Y3szFieLXaOj37dbYG0naKCL+PEjb+iquFr8lIl6g4irO+9q6LE7b\ncLKKK18PSPpHPZXz/tw21paSPqViIvUqFSdzW74q6cspx75Ja58Mf66K44LdJX3Sxccznq/iZNjL\n0/HPB8rGKdl/Zfvr2SpOhl1h+ze2dxvk8ZIUki5IxzKHty3fIiLulaT0/+Zp+VC55Wsq7qz6uqTP\nqjiOPD6dkB6zBv0cCZ60QduBwSWSTpW0laQ70mxcKi5z7iTp0nSScZKky1S8cG6PiD9Jku3vSTpc\nkiJinooXainbr5X0QETMt713A9uzm4pbUhal8c+Q9DcqznA+Lql1j/N8FUmizMsk/ag1QXD6vFE6\nO/X/JP2g7aTrem2P+3FErJF0k+0t0rJXSvp2a6yIeLBsnIg4X9L5GiAiLkiJ4neSFqn4O6yKiLD9\nVklfTmekLpC0aojtmhkRC23vIOmXtq8fkJz/W9LFEXFJ+n0dSS+W9AoVZ2Qus315uhr292mfTJP0\nEUlvtP1NFQe9X4qItT4HA0TEdS4+U3OQpLU+W5ReL8+S9Nv0nF5le+eIuCG1b6PiwCVsT4mIwT4f\ntaeeujr7XRUnWCRpn/Tv6vT7FBUTrItLwl1X0kkurmSvVvGm3dqOXattcamBV22k4g1/uH0O0toH\nNUM9pspYT2P7Rypus5wkaWbbe8ZXI+Lbgz2kwnp6vl0Y93p6/BMRN7u4i+ZCFbdDX6uh37dbrKGf\n289JMbXuVDld0pEqTlpL0g/T//OVv6L2Eq19LPV9PZX/Xilpp7bjlqlpoidJP0lXiR6z/YCKj2O8\nXNK5EbFYKo5/ysYZav9l9tc6Ko479lBxHHiO7R0GmeDsmY5/Npd0oe1bIqLsPWDQ3JLu2Nk77Ztn\nqXje3JKuvk2SdGzb32HMYEJV7pGBBwbpyb2ifZGK2ykOGtBvV3X+prWnpNfbfo2k9VW8oL4XEQeX\nPOZWFW/qG0XEwwPaBnvytzzR9uJarWrPjcG2b4KkpSUHVI8NEs9gSTA3zuABRRwv6XhJsn2mpD+l\n5ZepmAS2zsY/e4jHL0z/32b71yquwP05Pe6TkmZIek/bQ+5WcWZrhaQVti+WtIuk9mTxiRTTQSqS\n9ZmSzlNxBQ0Y6HxJX1TxhtR+5eItKt4Ub095aKqKq8T/ltq/quJq6PMkfVLSh4YYf7DXrSV9LiK+\nMYw4/1nS/Sqe7xMkPVrW2fZLJLXG/4Skhwa0H690EiK97u9WcYb17nSWfGNJD2ptrT4t20ha2Dbm\nZirOBu9f4TF3Kx0EtC3/ddk2pVj3T+uaJWlOROxd1l+jZLsw7vX6+EcRcaqKiZxsf1bFc7ms/0O2\nV6TJwm0DmsuOf6Snjk06Of6Rilz41+139EhP7rv245/WeoaaBA46TmlAQ++vu1V8NCEk/d72GknT\nVZx4bn986/jngXSiaHcVJ9Xut71lRNybrs490DbukHkqOV7Fe9T7VXwWb4GK96d/qLpdowW3/HXu\nckl7plm40u1mz5Z0i6TtbT8z9TtoqAGGEhEfjYhtImKWigOnX2YmU0pXeU6V9J+2J6WYtrR9sIrb\nh/ayPd32xBTTb4YbV3KxpP1dfK5qIxWX9luf5bjd9oFp3ba9S2asCyQdli5Ty/amdcZx8W2Im6Wf\n/0rFLVMXpN83T/+vp+Jq0dcHefw0P3VP9XQVE9qb0u//qOJS/UHpClvLeSoupa+T4n+Jii8MaI25\no6StIuI3Ku4nXqMiea6f2ScYv06T9OmIuH7A8oMk7RsRs1JOaN1227ptdnMV96h/RsVr82nfRiXp\nUj312av2N7RfqHgNtj7/sHXrNdPmYRVfstKysaR70+vh7Sq+SGFIEXFFunVm13SVeWD7x1vtadH5\nklrfSHeAivw38MDjSkk7uvhs2KS0be1jH6jiw/Dtk73zJb0j5ZQ9JC1Lt7H8QtI+KQ9MU3HF7hdl\n21TTWN0ujD8jdvyTxmu9b89UcdVo4GdKB/M5SV+zPTU9dqqL29dukTSrFauKnFX3+OcKSXu7uL1u\nXRWvx5YLJB3Vtg25k8IXSXpz27HLpjXHKdtfP1ZxJUzp7zNJxUch2h87uXUlzfZkFXnihtTcnrMO\nUXHc01o+WM5pjbmXpHvSlcrW8c/q9POYw4SqQ+mS76GSzrJ9nYoE89z0Rne4pJ+4+FDmHa3HeHif\noarj31ScebjJ9g0qXkyL0hP9o5J+peJy8FURcd7QwwwtIq6S9H0V30I2V8UtAS3/IOldtq+VdKMG\nfJh6kLF+ruKFOc/FLQatr0IddBwP/RmqdSVdYvsmFZ+/OjiKzyhI0ods3yzpOkn/ExG/TGO1/y2e\nl2K4VsU+OiEibkptX1dxef4yFx9Q/USK/WYVn5O6TsWXVXyrdQtW0jo7IxXJ7VAVz5Evlu0TjF8R\ncXdEfLV9Wbr6MVPFc6fV73ZJD6U3ra+o+CB2pKulH1bxBRUDfUDSkbavVDEhao11gYorp5fZvl7F\nlyVsNOCx10la5eKD0/+s4vbXQ2xfruKK75Nnrt3MZ6hOlbSZ7VtV3I9/TBp7K6evWk+v76NUTBBu\nlnRORNzYNsZb9fSDsJ+q+Ka7W1V8zuOINNaDKiajV6Z/n267/aZJY3W7MM504fhnbno//x9JR0bx\npSo5J6t4/74yHf/8RtLKFNM7VXyM4HoVB/dPO7FaRTqWOk7F7Y3/p+ILOlreL2m2iy+ZuEnFtw6W\njXWjiuOE36RjjxPLxsnsv6H212mSdkj742wV37YX7TlHxfHNb1MMv1dxe2Lrs+InSHqV7T+p+DjI\nCWn5oDknxWkVxz6tLz86JT1ursbo8Y+ffmIMvZIOmv43Inau2H9O6n/uCIYFAI1z8bnQoyPitb2O\npQoXtwAfnT7DMJzHzVEf5+m62wU0qcbxz3Eqvtp9TB6cY/ThClV/WS1p4ypnd118ocReynxuAQD6\n1OOSdvYQhX37ie1fqagJ9USNhy+T9Bmnwr79pMPtApo0nOOf/5B0sNb+PBfQU1yhAgAAAICauEIF\nAAAAADUxoQIAAACAmphQAQAAAEBNTKgAAAAAoCYmVAAAAABQ0/8HEqRRmKWbSv4AAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe60166df28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_adv_array(img, adv, pred_label, pred_confidence, \n",
    "                   a_pred_label, a_pred_confidence):\n",
    "    diff = adv - some_digit_image\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "    ax1.imshow(img, cmap = matplotlib.cm.binary,\n",
    "                   interpolation=\"nearest\")\n",
    "    cmapx = plt.get_cmap('bwr')\n",
    "    ax1.set_title(\"Input\")\n",
    "    ax1.set_xlabel(\"Pred: [{}] Confidence: {:.3f}%\".format(pred_label, pred_confidence))\n",
    "    ax2.imshow(diff, cmap = cmapx,\n",
    "                   interpolation=\"nearest\")\n",
    "    ax2.set_title(\"Adversarial Generation: blue:-, red:+\")\n",
    "    ax2.set_xlabel(\"MAX delta: -[{:.4f}] +[{:.4f}]\".format(np.min(diff), np.max(diff)))\n",
    "    ax3.imshow(adv, cmap = matplotlib.cm.binary,\n",
    "                   interpolation=\"nearest\")\n",
    "    ax3.set_title(\"Altered Input\")\n",
    "    ax3.set_xlabel(\"Pred: [{}] Confidence: {:.3f}%\".format(a_pred_label, a_pred_confidence))\n",
    "    plt.grid('off')\n",
    "    plt.tight_layout()\n",
    "    name = \"./output_images/\" + \"adv_array_\" + str(pred_label) + \"_to_\" + str(a_pred_label) + \".png\"\n",
    "    plt.savefig(name, bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "plot_adv_array(some_digit_image, adv_flat.reshape(28, 28), pred_label, pred_confidence, a_pred_label, a_pred_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_edge",
   "language": "python",
   "name": "tf_edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
