{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: (3, 5, 4, 'final', 0)\n",
      "TensorFlow: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this is a custom cell that contains the common imports I personally \n",
    "# use these may/may not be necessary for the following examples\n",
    "\n",
    "# DL framework\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# common packages\n",
    "import numpy as np\n",
    "import os # handling file i/o\n",
    "import sys\n",
    "import math\n",
    "import time # timing epochs\n",
    "import random\n",
    "\n",
    "# for ordered dict when building layer components\n",
    "import collections\n",
    "\n",
    "# plotting pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors # making colors consistent\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # colorbar helper\n",
    "\n",
    "\n",
    "# from imageio import imread # read image from disk\n",
    "# + data augmentation\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "\n",
    "\n",
    "import pickle # manually saving best params\n",
    "from sklearn.utils import shuffle # shuffling data batches\n",
    "from tqdm import tqdm # display training progress bar\n",
    "\n",
    "# const\n",
    "SEED = 42\n",
    "\n",
    "# Helper to make the output consistent\n",
    "def reset_graph(seed=SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# helper to create dirs if they don't already exist\n",
    "def maybe_create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"{} created\".format(dir_path))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(dir_path))\n",
    "    \n",
    "def make_standard_dirs(saver=True, best_params=True, tf_logs=True):\n",
    "    # `saver/` will hold tf saver files\n",
    "    maybe_create_dir(\"saver\")\n",
    "    # `best_params/` will hold a serialized version of the best params\n",
    "    # I like to keep this as a backup in case I run into issues with\n",
    "    # the saver files\n",
    "    maybe_create_dir(\"best_params\")\n",
    "    # `tf_logs/` will hold the logs that will be visable in tensorboard\n",
    "    maybe_create_dir(\"tf_logs\")\n",
    "\n",
    "    \n",
    "# set tf log level to supress messages, unless an error\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Important Version information\n",
    "print(\"Python: {}\".format(sys.version_info[:]))\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "\n",
    "# Check if using GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saver already exists\n",
      "best_params already exists\n",
      "tf_logs already exists\n"
     ]
    }
   ],
   "source": [
    "make_standard_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS_PATH = \"new_best_params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these two functions (get_model_params and restore_model_params) are \n",
    "# ad[a|o]pted from; \n",
    "# https://github.com/ageron/handson-ml/blob/master/11_deep_learning.ipynb\n",
    "def get_model_params():\n",
    "    global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {global_vars.op.name: value for global_vars, value in \n",
    "            zip(global_vars, tf.get_default_session().run(global_vars))}\n",
    "\n",
    "def restore_model_params(model_params, g, sess):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: g.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    sess.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "# these two functions are used to manually save the best\n",
    "# model params to disk\n",
    "def save_obj(obj, name):\n",
    "    with open('best_params/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('best_params/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte.gz\n",
      "train-images-idx3-ubyte.gz\n",
      "train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "ROOT_DATA = \"../../ROOT_DATA/\"\n",
    "DATA_DIR = \"mnist_data\"\n",
    "\n",
    "MNIST_TRAINING_PATH = os.path.join(ROOT_DATA, DATA_DIR)\n",
    "# ensure we have the correct directory\n",
    "for _, _, files in os.walk(MNIST_TRAINING_PATH):\n",
    "    files = sorted(files)\n",
    "    for filename in files:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../ROOT_DATA/mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets(MNIST_TRAINING_PATH, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_hyper_params():\n",
    "    data_params = {}\n",
    "    data_params['n_epochs'] = 50\n",
    "    data_params['batch_size'] = 128\n",
    "    data_params['buffer_size'] = 128 # for shuffling\n",
    "\n",
    "    data_params['init_lr'] = 1e-2\n",
    "\n",
    "    return data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(data_params):\n",
    "    g = tf.Graph()\n",
    "    n_outputs = 10\n",
    "    IMG_HEIGHT = 28\n",
    "    IMG_WIDTH = 28\n",
    "    CHANNELS = 1\n",
    "    with g.as_default():\n",
    "        with tf.name_scope(\"inputs\"):\n",
    "            X = tf.placeholder(tf.float32, shape=(None, 784), name=\"data\") # Input\n",
    "            X_reshaped = tf.reshape(X, shape=[-1, IMG_HEIGHT, IMG_WIDTH, CHANNELS])\n",
    "            y = tf.placeholder(tf.int32, shape=(None, n_outputs), name=\"labels\") # Target\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            h_1 = tf.layers.conv2d(X_reshaped, filters=32, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_1\")\n",
    "            h_2 = tf.layers.conv2d(h_1, filters=64, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_2\")\n",
    "            h_3 = tf.layers.max_pooling2d(h_2, pool_size=[2,2],\n",
    "                                          strides=2, name=\"max_pool_01\")\n",
    "            last_shape = int(np.prod(h_3.get_shape()[1:]))\n",
    "            h_3_flat = tf.reshape(h_3, shape=[-1, last_shape])\n",
    "            h_4 = tf.layers.dense(h_3_flat, 64, name=\"layer_04\", activation=tf.nn.elu)\n",
    "            logits = tf.layers.dense(h_4, n_outputs, name=\"logits\")\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            batch_loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(data_params['init_lr'])\n",
    "            training_op = optimizer.minimize(batch_loss)\n",
    "            \n",
    "        with tf.name_scope(\"save_session\"):\n",
    "            init_global = tf.global_variables_initializer()\n",
    "            init_local = tf.local_variables_initializer()\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "        # Ops: training metrics\n",
    "        with tf.name_scope(\"metrics\"):\n",
    "            # ================================== performance\n",
    "            with tf.name_scope(\"common\"):\n",
    "                preds = tf.nn.softmax(logits, name=\"prediction\")\n",
    "                y_true_cls = tf.argmax(y,1)\n",
    "                y_pred_cls = tf.argmax(preds,1)\n",
    "                correct_prediction = tf.equal(y_pred_cls, y_true_cls, name=\"correct_predictions\")\n",
    "                batch_acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            with tf.name_scope(\"train_metrics\") as scope:\n",
    "                train_auc, train_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                train_acc, train_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                train_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_met_reset_op = tf.variables_initializer(train_acc_vars, name=\"train_met_reset_op\")\n",
    "            with tf.name_scope(\"val_metrics\") as scope:\n",
    "                val_auc, val_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                val_acc, val_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                val_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_met_reset_op = tf.variables_initializer(val_acc_vars, name=\"val_met_reset_op\")\n",
    "            with tf.name_scope(\"test_metrics\") as scope:\n",
    "                test_auc, test_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                test_acc, test_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                test_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_acc_reset_op = tf.variables_initializer(test_acc_vars, name=\"test_met_reset_op\")\n",
    "\n",
    "            # =============================================== loss \n",
    "            with tf.name_scope(\"train_loss_eval\") as scope:\n",
    "                train_mean_loss, train_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                train_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_loss_reset_op = tf.variables_initializer(train_loss_vars, name=\"train_loss_reset_op\")\n",
    "            with tf.name_scope(\"val_loss_eval\") as scope:\n",
    "                val_mean_loss, val_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                val_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_loss_reset_op = tf.variables_initializer(val_loss_vars, name=\"val_loss_reset_op\")\n",
    "            with tf.name_scope(\"test_loss_eval\")as scope:\n",
    "                test_mean_loss, test_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                test_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_loss_reset_op = tf.variables_initializer(test_loss_vars, name=\"test_loss_rest_op\")\n",
    "\n",
    "        # --- create collections\n",
    "        for node in (saver, init_global, init_local):\n",
    "            g.add_to_collection(\"save_init\", node)\n",
    "        for node in (X, X_reshaped, y, training_op):\n",
    "            g.add_to_collection(\"main_ops\", node)\n",
    "        for node in (preds, y_true_cls, y_pred_cls):\n",
    "            g.add_to_collection(\"preds\", node)\n",
    "        for node in (train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op):\n",
    "            g.add_to_collection(\"train_metrics\", node)\n",
    "        for node in (val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op):\n",
    "            g.add_to_collection(\"val_metrics\", node)\n",
    "        for node in (test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op):\n",
    "            g.add_to_collection(\"test_metrics\", node)\n",
    "        for node in (train_mean_loss, train_mean_loss_update, train_loss_reset_op):\n",
    "            g.add_to_collection(\"train_loss\", node)\n",
    "        for node in (val_mean_loss, val_mean_loss_update, val_loss_reset_op):\n",
    "            g.add_to_collection(\"val_loss\", node)\n",
    "        for node in (test_mean_loss, test_mean_loss_update, test_loss_reset_op):\n",
    "            g.add_to_collection(\"test_loss\", node)\n",
    "        g.add_to_collection(\"logits\", logits)\n",
    "            \n",
    "        # ===================================== tensorboard\n",
    "        with tf.name_scope(\"tensorboard_writer\") as scope:\n",
    "            epoch_train_loss_scalar = tf.summary.scalar('train_epoch_loss', train_mean_loss)\n",
    "            epoch_train_acc_scalar = tf.summary.scalar('train_epoch_acc', train_acc)\n",
    "            epoch_train_auc_scalar = tf.summary.scalar('train_epoch_auc', train_auc)\n",
    "            epoch_train_write_op = tf.summary.merge([epoch_train_loss_scalar, epoch_train_acc_scalar, epoch_train_auc_scalar], name=\"epoch_train_write_op\")\n",
    "\n",
    "            # ===== epoch, validation\n",
    "            epoch_validation_loss_scalar = tf.summary.scalar('validation_epoch_loss', val_mean_loss)\n",
    "            epoch_validation_acc_scalar = tf.summary.scalar('validation_epoch_acc', val_acc)\n",
    "            epoch_validation_auc_scalar = tf.summary.scalar('validation_epoch_auc', val_auc)\n",
    "            epoch_validation_write_op = tf.summary.merge([epoch_validation_loss_scalar, epoch_validation_acc_scalar, epoch_validation_auc_scalar], name=\"epoch_validation_write_op\")\n",
    "        \n",
    "        for node in (epoch_train_write_op, epoch_validation_write_op):\n",
    "            g.add_to_collection(\"tensorboard\", node)\n",
    "            \n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_graph(g):\n",
    "    global BEST_PARAMS_PATH\n",
    "    saver, init_global, init_local = g.get_collection(\"save_init\")\n",
    "    X, X_reshaped, y, training_op = g.get_collection(\"main_ops\")\n",
    "    preds, y_true_cls, y_pred_cls = g.get_collection(\"preds\")\n",
    "    train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op = g.get_collection(\"train_metrics\")\n",
    "    val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op = g.get_collection(\"val_metrics\")\n",
    "    train_mean_loss, train_mean_loss_update, train_loss_reset_op = g.get_collection(\"train_loss\")\n",
    "    val_mean_loss, val_mean_loss_update, val_loss_reset_op = g.get_collection(\"val_loss\")\n",
    "    epoch_train_write_op, epoch_validation_write_op = g.get_collection(\"tensorboard\")\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(os.path.join(\"tf_logs\",\"train\"))\n",
    "    val_writer = tf.summary.FileWriter(os.path.join(\"tf_logs\",\"validation\"))\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    with tf.Session(graph=g) as sess:\n",
    "        sess.run([init_global, init_local])\n",
    "        \n",
    "        for e in tqdm(range(1,data_params['n_epochs']+1)):\n",
    "            sess.run([val_met_reset_op,val_loss_reset_op,train_met_reset_op,train_loss_reset_op])\n",
    "            \n",
    "            n_batches = int(MNIST.train.num_examples/data_params['batch_size'])\n",
    "            for i in range(1, n_batches+1):\n",
    "                data, target = MNIST.train.next_batch(data_params['batch_size'])\n",
    "                sess.run([training_op, train_auc_update, train_acc_update, train_mean_loss_update], feed_dict={X:data, y:target})\n",
    "        \n",
    "            # write average for epoch\n",
    "            summary = sess.run(epoch_train_write_op)    \n",
    "            train_writer.add_summary(summary, e)\n",
    "            train_writer.flush()\n",
    "\n",
    "            # run validation\n",
    "            n_batches = int(MNIST.validation.num_examples/data_params['batch_size'])\n",
    "            for i in range(1,n_batches+1):\n",
    "                Xb, yb = MNIST.validation.next_batch(data_params['batch_size'])\n",
    "                sess.run([val_auc_update, val_acc_update, val_mean_loss_update], feed_dict={X:data, y:target})\n",
    "\n",
    "            # check for (and save) best validation params here\n",
    "            cur_loss, cur_acc = sess.run([val_mean_loss, val_acc])\n",
    "            if cur_loss < best_val_loss:\n",
    "                best_val_loss = cur_loss\n",
    "                best_params = get_model_params()\n",
    "                save_obj(best_params, BEST_PARAMS_PATH)\n",
    "                print(\"best params saved: acc: {:.3f}% loss: {:.4f}\".format(cur_acc*100, cur_loss))\n",
    "\n",
    "            summary = sess.run(epoch_validation_write_op) \n",
    "            val_writer.add_summary(summary, e)\n",
    "            val_writer.flush()\n",
    "        \n",
    "        train_writer.close()\n",
    "        val_writer.close()\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:05<04:26,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 95.312% loss: 0.1767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [00:14<03:43,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 98.438% loss: 0.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [00:33<03:27,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 99.219% loss: 0.0425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [00:58<03:05,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [01:35<02:22,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [01:45<02:14,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [02:16<01:56,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [02:29<01:48,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [03:19<00:56,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [03:34<00:40,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 100.000% loss: 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [04:09<00:00,  4.99s/it]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "data_params = create_hyper_params()\n",
    "g = build_graph(data_params)\n",
    "sess = train_graph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "This is a checkpoint - in that training can be skipped if previous best params are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:00<00:00, 106.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 99.906% acc: 98.027% loss: 0.06035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "data_params = create_hyper_params()\n",
    "g2 = build_graph(data_params)\n",
    "best_params = load_obj(BEST_PARAMS_PATH)\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "    X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "    preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "    test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "    test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "    \n",
    "    restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "    sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "    \n",
    "    n_batches = int(MNIST.test.num_examples/data_params['batch_size'])\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        Xb, yb = MNIST.test.next_batch(data_params['batch_size'])\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "    # print\n",
    "    final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "    print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                              final_test_acc*100,\n",
    "                                                              final_test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Sample Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEj+EEj+E+hcCnalwnc/eIQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34cccacc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_idx = 26\n",
    "some_image = MNIST.test.images[some_idx]\n",
    "some_label_enc = MNIST.test.labels[some_idx]\n",
    "some_label_dec = np.argmax(some_label_enc)\n",
    "some_digit_image = some_image.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the current architecture classify the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function needs some work, but it currently serves it's purpose\n",
    "def display_figure_and_prob(img, probs, save_path):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "    ax1.imshow(img, cmap = matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "    y_pos = np.arange(10)\n",
    "    ax2.bar(y_pos, probs, align='center', alpha=0.5)\n",
    "    plt.title('Confidence')\n",
    "    plt.grid('off')\n",
    "    plt.tight_layout()\n",
    "    save_path = \"./output_images/\" + save_path + \".png\"\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 100.000% acc: 100.000% loss: 0.00154\n",
      "true_class: [4]\n",
      "pred_class [4]\n",
      "confidence: 99.8460%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAEYCAYAAABGExyUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMpIkqVkGGUmS1CyDjCRJatb/B0iPuzbVKXlPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34c8229d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_model(img, label):\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g2 = build_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g2) as sess:\n",
    "        saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "        X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "        logz = g2.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "        Xb, yb = np.expand_dims(img,0), np.expand_dims(label, 0)\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "        pred_value, true_cls_value, pred_cls_value = sess.run([preds, y_true_cls, y_pred_cls],\n",
    "                                                              feed_dict={X:Xb,y:yb})\n",
    "        logits_val = sess.run([logz], feed_dict={X:Xb,y:yb})[0]\n",
    "        print\n",
    "        final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "        print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                                   final_test_acc*100,\n",
    "                                                                   final_test_loss))\n",
    "        pred_idx = pred_cls_value[0]\n",
    "        print(\"true_class: {}\\npred_class {}\".format(true_cls_value, pred_cls_value))\n",
    "        \n",
    "        confidence = pred_value[0][pred_idx]*100\n",
    "        print(\"confidence: {:.4f}%\".format(confidence))\n",
    "\n",
    "        jack = np.argmax(pred_value[0])\n",
    "        name = \"mnist_\" + str(jack) + \"_conf_\" + str(confidence)\n",
    "        display_figure_and_prob(some_digit_image, pred_value[0], name)\n",
    "        \n",
    "    return pred_idx, confidence\n",
    "        \n",
    "pred_label, pred_confidence = test_model(some_image, some_label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_adv_graph(data_params):\n",
    "    g = tf.Graph()\n",
    "    n_outputs = 10\n",
    "    IMG_HEIGHT = 28\n",
    "    IMG_WIDTH = 28\n",
    "    CHANNELS = 1\n",
    "    with g.as_default():\n",
    "        with tf.name_scope(\"inputs\"):\n",
    "            #X = tf.placeholder(tf.float32, shape=(None, 784), name=\"data\") # Input\n",
    "            #X_reshaped = tf.reshape(X, shape=[-1, IMG_HEIGHT, IMG_WIDTH, CHANNELS])\n",
    "            Xx = tf.Variable(tf.zeros((28, 28, 1)))\n",
    "            Xxx = tf.expand_dims(Xx, 0)\n",
    "            y = tf.placeholder(tf.int32, shape=(None, n_outputs), name=\"labels\") # Target\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            h_1 = tf.layers.conv2d(Xxx, filters=32, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_1\")\n",
    "            h_2 = tf.layers.conv2d(h_1, filters=64, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_2\")\n",
    "            h_3 = tf.layers.max_pooling2d(h_2, pool_size=[2,2],\n",
    "                                          strides=2, name=\"max_pool_01\")\n",
    "            last_shape = int(np.prod(h_3.get_shape()[1:]))\n",
    "            h_3_flat = tf.reshape(h_3, shape=[-1, last_shape])\n",
    "            h_4 = tf.layers.dense(h_3_flat, 64, name=\"layer_04\", activation=tf.nn.elu)\n",
    "            logits = tf.layers.dense(h_4, n_outputs, name=\"logits\")\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            batch_loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(data_params['init_lr'])\n",
    "            training_op = optimizer.minimize(batch_loss)\n",
    "            \n",
    "        with tf.name_scope(\"save_session\"):\n",
    "            init_global = tf.global_variables_initializer()\n",
    "            init_local = tf.local_variables_initializer()\n",
    "            saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.name_scope(\"adv\"):\n",
    "            x = tf.placeholder(tf.float32, (28, 28, 1), name=\"jack\") # Input\n",
    "            x_hat = Xx\n",
    "            assign_op = tf.assign(x_hat, x)\n",
    "\n",
    "            y_hat = tf.placeholder(tf.int32, ())\n",
    "            labels = tf.one_hot(y_hat, 10)\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels, name=\"adv_loss\")\n",
    "            optim_step = tf.train.GradientDescentOptimizer(1e-1).minimize(loss, var_list=[Xx])\n",
    "            \n",
    "            epsilon = tf.placeholder(tf.float32, ())\n",
    "            below = x - epsilon\n",
    "            above = x + epsilon\n",
    "            projected = tf.clip_by_value(tf.clip_by_value(x_hat, below, above), 0, 1)\n",
    "\n",
    "            with tf.control_dependencies([projected]):\n",
    "                project_step = tf.assign(x_hat, projected)\n",
    "                \n",
    "            for node in (assign_op, x, optim_step, loss, y_hat, epsilon, x_hat, project_step):\n",
    "                g.add_to_collection(\"adv\", node)\n",
    "\n",
    "        # Ops: training metrics\n",
    "        with tf.name_scope(\"metrics\"):\n",
    "            # ================================== performance\n",
    "            with tf.name_scope(\"common\"):\n",
    "                preds = tf.nn.softmax(logits, name=\"prediction\")\n",
    "                y_true_cls = tf.argmax(y,1)\n",
    "                y_pred_cls = tf.argmax(preds,1)\n",
    "                correct_prediction = tf.equal(y_pred_cls, y_true_cls, name=\"correct_predictions\")\n",
    "                batch_acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            with tf.name_scope(\"train_metrics\") as scope:\n",
    "                train_auc, train_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                train_acc, train_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                train_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_met_reset_op = tf.variables_initializer(train_acc_vars, name=\"train_met_reset_op\")\n",
    "            with tf.name_scope(\"val_metrics\") as scope:\n",
    "                val_auc, val_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                val_acc, val_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                val_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_met_reset_op = tf.variables_initializer(val_acc_vars, name=\"val_met_reset_op\")\n",
    "            with tf.name_scope(\"test_metrics\") as scope:\n",
    "                test_auc, test_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                test_acc, test_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                test_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_acc_reset_op = tf.variables_initializer(test_acc_vars, name=\"test_met_reset_op\")\n",
    "\n",
    "            # =============================================== loss \n",
    "            with tf.name_scope(\"train_loss_eval\") as scope:\n",
    "                train_mean_loss, train_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                train_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_loss_reset_op = tf.variables_initializer(train_loss_vars, name=\"train_loss_reset_op\")\n",
    "            with tf.name_scope(\"val_loss_eval\") as scope:\n",
    "                val_mean_loss, val_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                val_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_loss_reset_op = tf.variables_initializer(val_loss_vars, name=\"val_loss_reset_op\")\n",
    "            with tf.name_scope(\"test_loss_eval\")as scope:\n",
    "                test_mean_loss, test_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                test_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_loss_reset_op = tf.variables_initializer(test_loss_vars, name=\"test_loss_rest_op\")\n",
    "\n",
    "        # --- create collections\n",
    "        for node in (saver, init_global, init_local):\n",
    "            g.add_to_collection(\"save_init\", node)\n",
    "        for node in (X, Xx, y, training_op):\n",
    "            g.add_to_collection(\"main_ops\", node)\n",
    "        for node in (preds, y_true_cls, y_pred_cls):\n",
    "            g.add_to_collection(\"preds\", node)\n",
    "        for node in (train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op):\n",
    "            g.add_to_collection(\"train_metrics\", node)\n",
    "        for node in (val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op):\n",
    "            g.add_to_collection(\"val_metrics\", node)\n",
    "        for node in (test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op):\n",
    "            g.add_to_collection(\"test_metrics\", node)\n",
    "        for node in (train_mean_loss, train_mean_loss_update, train_loss_reset_op):\n",
    "            g.add_to_collection(\"train_loss\", node)\n",
    "        for node in (val_mean_loss, val_mean_loss_update, val_loss_reset_op):\n",
    "            g.add_to_collection(\"val_loss\", node)\n",
    "        for node in (test_mean_loss, test_mean_loss_update, test_loss_reset_op):\n",
    "            g.add_to_collection(\"test_loss\", node)\n",
    "        g.add_to_collection(\"logits\", logits)\n",
    "            \n",
    "        # ===================================== tensorboard\n",
    "        with tf.name_scope(\"tensorboard_writer\") as scope:\n",
    "            epoch_train_loss_scalar = tf.summary.scalar('train_epoch_loss', train_mean_loss)\n",
    "            epoch_train_acc_scalar = tf.summary.scalar('train_epoch_acc', train_acc)\n",
    "            epoch_train_auc_scalar = tf.summary.scalar('train_epoch_auc', train_auc)\n",
    "            epoch_train_write_op = tf.summary.merge([epoch_train_loss_scalar, epoch_train_acc_scalar, epoch_train_auc_scalar], name=\"epoch_train_write_op\")\n",
    "\n",
    "            # ===== epoch, validation\n",
    "            epoch_validation_loss_scalar = tf.summary.scalar('validation_epoch_loss', val_mean_loss)\n",
    "            epoch_validation_acc_scalar = tf.summary.scalar('validation_epoch_acc', val_acc)\n",
    "            epoch_validation_auc_scalar = tf.summary.scalar('validation_epoch_auc', val_auc)\n",
    "            epoch_validation_write_op = tf.summary.merge([epoch_validation_loss_scalar, epoch_validation_acc_scalar, epoch_validation_auc_scalar], name=\"epoch_validation_write_op\")\n",
    "        \n",
    "        for node in (epoch_train_write_op, epoch_validation_write_op):\n",
    "            g.add_to_collection(\"tensorboard\", node)\n",
    "            \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1068/50000 [00:02<02:00, 406.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000, loss=0.22078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2049/50000 [00:04<01:54, 419.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000, loss=0.220718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3069/50000 [00:07<01:51, 422.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000, loss=0.220721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4083/50000 [00:09<01:48, 423.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4000, loss=0.220731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5058/50000 [00:12<01:48, 414.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5000, loss=0.220786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6068/50000 [00:14<01:46, 412.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6000, loss=0.220713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7066/50000 [00:17<01:44, 411.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7000, loss=0.220715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8042/50000 [00:19<01:41, 411.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8000, loss=0.220738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9063/50000 [00:22<01:39, 410.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9000, loss=0.220715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10043/50000 [00:25<01:39, 399.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000, loss=0.220735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11081/50000 [00:27<01:37, 398.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 11000, loss=0.220757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12078/50000 [00:30<01:34, 400.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 12000, loss=0.220729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13015/50000 [00:32<01:33, 395.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 13000, loss=0.220763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14040/50000 [00:35<01:31, 393.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 14000, loss=0.220733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15058/50000 [00:38<01:28, 394.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 15000, loss=0.220762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16067/50000 [00:40<01:26, 392.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 16000, loss=0.220747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17043/50000 [00:44<01:26, 382.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 17000, loss=0.220762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18040/50000 [00:48<01:25, 373.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 18000, loss=0.22072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19035/50000 [00:51<01:23, 370.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 19000, loss=0.220764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20044/50000 [00:55<01:22, 363.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 20000, loss=0.220763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21053/50000 [00:58<01:20, 358.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 21000, loss=0.220782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22046/50000 [01:01<01:17, 361.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 22000, loss=0.220764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23046/50000 [01:03<01:14, 363.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 23000, loss=0.220794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24053/50000 [01:05<01:10, 365.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 24000, loss=0.220723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25045/50000 [01:08<01:08, 366.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 25000, loss=0.220794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26051/50000 [01:10<01:05, 367.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 26000, loss=0.220722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27048/50000 [01:13<01:02, 369.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 27000, loss=0.220734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28058/50000 [01:15<00:59, 370.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 28000, loss=0.220716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29063/50000 [01:18<00:56, 371.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 29000, loss=0.220777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30039/50000 [01:20<00:53, 372.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30000, loss=0.220772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31057/50000 [01:23<00:50, 372.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 31000, loss=0.220701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32055/50000 [01:26<00:48, 372.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 32000, loss=0.220762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33072/50000 [01:28<00:45, 372.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 33000, loss=0.220743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34044/50000 [01:31<00:42, 372.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 34000, loss=0.220721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35030/50000 [01:34<00:40, 370.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 35000, loss=0.220747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36022/50000 [01:38<00:38, 365.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 36000, loss=0.220718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37022/50000 [01:42<00:35, 362.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 37000, loss=0.220748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38056/50000 [01:46<00:33, 358.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 38000, loss=0.220723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39030/50000 [01:49<00:30, 356.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 39000, loss=0.220711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40054/50000 [01:52<00:27, 355.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40000, loss=0.220718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41048/50000 [01:55<00:25, 356.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 41000, loss=0.220726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42082/50000 [01:57<00:22, 357.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 42000, loss=0.220724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43064/50000 [02:00<00:19, 358.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 43000, loss=0.220739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44057/50000 [02:02<00:16, 359.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 44000, loss=0.220728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45061/50000 [02:05<00:13, 360.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 45000, loss=0.220733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46077/50000 [02:07<00:10, 361.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 46000, loss=0.220773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47059/50000 [02:10<00:08, 361.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 47000, loss=0.220719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48036/50000 [02:13<00:05, 359.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 48000, loss=0.220738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49068/50000 [02:17<00:02, 357.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 49000, loss=0.220737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [02:19<00:00, 358.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50000, loss=0.220737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def produce_targeted_adv_image(img, adv_target=0,adv_eps=0.07,adv_lr=1e-1,adv_steps=50000):\n",
    "    \n",
    "    #TODO: learning rate is currently hardcoded\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g3 = build_adv_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g3) as sess:\n",
    "        saver, init_global, init_local = g3.get_collection(\"save_init\")\n",
    "        X, Xx, y, training_op = g3.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g3.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g3.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g3.get_collection(\"test_loss\")\n",
    "        logz = g3.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g3, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "\n",
    "        # execution\n",
    "        assign_op, x, optim_step, loss, y_hat, epsilon, x_hat, project_step = g3.get_collection(\"adv\")\n",
    "\n",
    "        # initialization step\n",
    "        sess.run(assign_op, feed_dict={x: img})\n",
    "\n",
    "        # projected gradient descent\n",
    "        for i in tqdm(range(1, adv_steps+1)):\n",
    "            # gradient descent step\n",
    "            _, loss_value = sess.run(\n",
    "                [optim_step, loss],\n",
    "                feed_dict={y_hat: adv_target})\n",
    "            # project step\n",
    "            sess.run(project_step, feed_dict={x: img, epsilon: adv_eps})\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print('step %d, loss=%g' % (i+1, loss_value))\n",
    "\n",
    "        adv_out = x_hat.eval() # retrieve the adversarial example\n",
    "        \n",
    "    return adv_out\n",
    "adv_out = produce_targeted_adv_image(some_image.reshape(28,28,1), adv_target=9)\n",
    "adv_flat = adv_out.reshape((784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 88.889% acc: 0.000% loss: 1.70378\n",
      "true_class: [4]\n",
      "pred_class [9]\n",
      "confidence: 80.1897%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAEYCAYAAABGExyUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQAAkCwKGQAAkKz/D6oz5yj0ZijUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34c7a05908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_adversarial(img, label):\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g2 = build_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g2) as sess:\n",
    "        saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "        X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "        logz = g2.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "        Xb, yb = np.expand_dims(img,0), np.expand_dims(label, 0)\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "        pred_value, true_cls_value, pred_cls_value = sess.run([preds, y_true_cls, y_pred_cls],\n",
    "                                                              feed_dict={X:Xb,y:yb})\n",
    "        logits_val = sess.run([logz], feed_dict={X:Xb,y:yb})[0]\n",
    "\n",
    "        final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "        print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                                   final_test_acc*100,\n",
    "                                                                   final_test_loss))\n",
    "        pred_idx = pred_cls_value[0]\n",
    "        print(\"true_class: {}\\npred_class {}\".format(true_cls_value, pred_cls_value))\n",
    "        confidence = pred_value[0][pred_idx]*100\n",
    "        print(\"confidence: {:.4f}%\".format(confidence))\n",
    "\n",
    "        jack = np.argmax(pred_value[0])\n",
    "        name = \"mnist_\" + str(jack) + \"_conf_\" + str(confidence) + \"_adv\"\n",
    "        display_figure_and_prob(adv_flat.reshape(28, 28), pred_value[0], name)\n",
    "\n",
    "    return pred_idx, confidence\n",
    "\n",
    "a_pred_label, a_pred_confidence = test_adversarial(adv_flat, some_label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAAEtCAYAAAAP0yF9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34c94502b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_adv_array(img, adv, pred_label, pred_confidence, \n",
    "                   a_pred_label, a_pred_confidence):\n",
    "    diff = adv - some_digit_image\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "    ax1.imshow(img, cmap = matplotlib.cm.binary,\n",
    "                   interpolation=\"nearest\")\n",
    "    cmapx = plt.get_cmap('bwr')\n",
    "    ax1.set_title(\"Input\")\n",
    "    ax1.set_xlabel(\"Pred: [{}] Confidence: {:.3f}%\".format(pred_label, pred_confidence))\n",
    "    ax2.imshow(diff, cmap = cmapx,\n",
    "                   interpolation=\"nearest\")\n",
    "    ax2.set_title(\"Adversarial Generation: blue:-, red:+\")\n",
    "    ax2.set_xlabel(\"MAX delta: -[{:.4f}] +[{:.4f}]\".format(np.min(diff), np.max(diff)))\n",
    "    ax3.imshow(adv, cmap = matplotlib.cm.binary,\n",
    "                   interpolation=\"nearest\")\n",
    "    ax3.set_title(\"Altered Input\")\n",
    "    ax3.set_xlabel(\"Pred: [{}] Confidence: {:.3f}%\".format(a_pred_label, a_pred_confidence))\n",
    "    plt.grid('off')\n",
    "    plt.tight_layout()\n",
    "    name = \"./output_images/\" + \"adv_array_\" + str(pred_label) + \"_to_\" + str(a_pred_label) + \".png\"\n",
    "    plt.savefig(name, bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "plot_adv_array(some_digit_image, adv_flat.reshape(28, 28), pred_label, pred_confidence, a_pred_label, a_pred_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_edge",
   "language": "python",
   "name": "tf_edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
