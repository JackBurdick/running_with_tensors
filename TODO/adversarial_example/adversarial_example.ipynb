{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: (3, 5, 4, 'final', 0)\n",
      "TensorFlow: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# NOTE: this is a custom cell that contains the common imports I personally \n",
    "# use these may/may not be necessary for the following examples\n",
    "\n",
    "# DL framework\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# common packages\n",
    "import numpy as np\n",
    "import os # handling file i/o\n",
    "import sys\n",
    "import math\n",
    "import time # timing epochs\n",
    "import random\n",
    "\n",
    "# for ordered dict when building layer components\n",
    "import collections\n",
    "\n",
    "# plotting pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import colors # making colors consistent\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable # colorbar helper\n",
    "\n",
    "\n",
    "# from imageio import imread # read image from disk\n",
    "# + data augmentation\n",
    "from scipy import ndimage\n",
    "from scipy import misc\n",
    "\n",
    "\n",
    "import pickle # manually saving best params\n",
    "from sklearn.utils import shuffle # shuffling data batches\n",
    "from tqdm import tqdm # display training progress bar\n",
    "\n",
    "# const\n",
    "SEED = 42\n",
    "\n",
    "# Helper to make the output consistent\n",
    "def reset_graph(seed=SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# helper to create dirs if they don't already exist\n",
    "def maybe_create_dir(dir_path):\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print(\"{} created\".format(dir_path))\n",
    "    else:\n",
    "        print(\"{} already exists\".format(dir_path))\n",
    "    \n",
    "def make_standard_dirs(saver=True, best_params=True, tf_logs=True):\n",
    "    # `saver/` will hold tf saver files\n",
    "    maybe_create_dir(\"saver\")\n",
    "    # `best_params/` will hold a serialized version of the best params\n",
    "    # I like to keep this as a backup in case I run into issues with\n",
    "    # the saver files\n",
    "    maybe_create_dir(\"best_params\")\n",
    "    # `tf_logs/` will hold the logs that will be visable in tensorboard\n",
    "    maybe_create_dir(\"tf_logs\")\n",
    "\n",
    "    \n",
    "# set tf log level to supress messages, unless an error\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Important Version information\n",
    "print(\"Python: {}\".format(sys.version_info[:]))\n",
    "print('TensorFlow: {}'.format(tf.__version__))\n",
    "\n",
    "# Check if using GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saver already exists\n",
      "best_params already exists\n",
      "tf_logs already exists\n"
     ]
    }
   ],
   "source": [
    "make_standard_dirs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS_PATH = \"new_best_params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these two functions (get_model_params and restore_model_params) are \n",
    "# ad[a|o]pted from; \n",
    "# https://github.com/ageron/handson-ml/blob/master/11_deep_learning.ipynb\n",
    "def get_model_params():\n",
    "    global_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {global_vars.op.name: value for global_vars, value in \n",
    "            zip(global_vars, tf.get_default_session().run(global_vars))}\n",
    "\n",
    "def restore_model_params(model_params, g, sess):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: g.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    sess.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "# these two functions are used to manually save the best\n",
    "# model params to disk\n",
    "def save_obj(obj, name):\n",
    "    with open('best_params/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('best_params/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t10k-images-idx3-ubyte.gz\n",
      "t10k-labels-idx1-ubyte.gz\n",
      "train-images-idx3-ubyte.gz\n",
      "train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "ROOT_DATA = \"../../ROOT_DATA/\"\n",
    "DATA_DIR = \"mnist_data\"\n",
    "\n",
    "MNIST_TRAINING_PATH = os.path.join(ROOT_DATA, DATA_DIR)\n",
    "# ensure we have the correct directory\n",
    "for _, _, files in os.walk(MNIST_TRAINING_PATH):\n",
    "    files = sorted(files)\n",
    "    for filename in files:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../ROOT_DATA/mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../ROOT_DATA/mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "MNIST = input_data.read_data_sets(MNIST_TRAINING_PATH, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_hyper_params():\n",
    "    data_params = {}\n",
    "    data_params['n_epochs'] = 5\n",
    "    data_params['batch_size'] = 128\n",
    "    data_params['buffer_size'] = 128 # for shuffling\n",
    "\n",
    "    data_params['init_lr'] = 1e-2\n",
    "\n",
    "    return data_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(data_params):\n",
    "    g = tf.Graph()\n",
    "    n_outputs = 10\n",
    "    IMG_HEIGHT = 28\n",
    "    IMG_WIDTH = 28\n",
    "    CHANNELS = 1\n",
    "    with g.as_default():\n",
    "        with tf.name_scope(\"inputs\"):\n",
    "            X = tf.placeholder(tf.float32, shape=(None, 784), name=\"data\") # Input\n",
    "            X_reshaped = tf.reshape(X, shape=[-1, IMG_HEIGHT, IMG_WIDTH, CHANNELS])\n",
    "            y = tf.placeholder(tf.int32, shape=(None, n_outputs), name=\"labels\") # Target\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            h_1 = tf.layers.conv2d(X_reshaped, filters=32, kernel_size=3, activation=tf.nn.relu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_1\")\n",
    "            h_2 = tf.layers.conv2d(h_1, filters=64, kernel_size=3, activation=tf.nn.relu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_2\")\n",
    "            h_3 = tf.layers.conv2d(h_1, filters=36, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=2, name=\"conv_3\")\n",
    "            h_4 = tf.layers.max_pooling2d(h_3, pool_size=[2,2],\n",
    "                                          strides=2, name=\"max_pool_01\")\n",
    "            last_shape = int(np.prod(h_4.get_shape()[1:]))\n",
    "            h_4_flat = tf.reshape(h_4, shape=[-1, last_shape])\n",
    "            h_5 = tf.layers.dense(h_4_flat, 64, name=\"layer_05\", activation=tf.nn.relu)\n",
    "            logits = tf.layers.dense(h_5, n_outputs, name=\"logits\")\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            batch_loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(data_params['init_lr'])\n",
    "            training_op = optimizer.minimize(batch_loss)\n",
    "            \n",
    "        with tf.name_scope(\"save_session\"):\n",
    "            init_global = tf.global_variables_initializer()\n",
    "            init_local = tf.local_variables_initializer()\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "        # Ops: training metrics\n",
    "        with tf.name_scope(\"metrics\"):\n",
    "            # ================================== performance\n",
    "            with tf.name_scope(\"common\"):\n",
    "                preds = tf.nn.softmax(logits, name=\"prediction\")\n",
    "                y_true_cls = tf.argmax(y,1)\n",
    "                y_pred_cls = tf.argmax(preds,1)\n",
    "                correct_prediction = tf.equal(y_pred_cls, y_true_cls, name=\"correct_predictions\")\n",
    "                batch_acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            with tf.name_scope(\"train_metrics\") as scope:\n",
    "                train_auc, train_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                train_acc, train_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                train_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_met_reset_op = tf.variables_initializer(train_acc_vars, name=\"train_met_reset_op\")\n",
    "            with tf.name_scope(\"val_metrics\") as scope:\n",
    "                val_auc, val_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                val_acc, val_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                val_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_met_reset_op = tf.variables_initializer(val_acc_vars, name=\"val_met_reset_op\")\n",
    "            with tf.name_scope(\"test_metrics\") as scope:\n",
    "                test_auc, test_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                test_acc, test_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                test_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_acc_reset_op = tf.variables_initializer(test_acc_vars, name=\"test_met_reset_op\")\n",
    "\n",
    "            # =============================================== loss \n",
    "            with tf.name_scope(\"train_loss_eval\") as scope:\n",
    "                train_mean_loss, train_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                train_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_loss_reset_op = tf.variables_initializer(train_loss_vars, name=\"train_loss_reset_op\")\n",
    "            with tf.name_scope(\"val_loss_eval\") as scope:\n",
    "                val_mean_loss, val_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                val_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_loss_reset_op = tf.variables_initializer(val_loss_vars, name=\"val_loss_reset_op\")\n",
    "            with tf.name_scope(\"test_loss_eval\")as scope:\n",
    "                test_mean_loss, test_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                test_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_loss_reset_op = tf.variables_initializer(test_loss_vars, name=\"test_loss_rest_op\")\n",
    "\n",
    "        # --- create collections\n",
    "        for node in (saver, init_global, init_local):\n",
    "            g.add_to_collection(\"save_init\", node)\n",
    "        for node in (X, X_reshaped, y, training_op):\n",
    "            g.add_to_collection(\"main_ops\", node)\n",
    "        for node in (preds, y_true_cls, y_pred_cls):\n",
    "            g.add_to_collection(\"preds\", node)\n",
    "        for node in (train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op):\n",
    "            g.add_to_collection(\"train_metrics\", node)\n",
    "        for node in (val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op):\n",
    "            g.add_to_collection(\"val_metrics\", node)\n",
    "        for node in (test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op):\n",
    "            g.add_to_collection(\"test_metrics\", node)\n",
    "        for node in (train_mean_loss, train_mean_loss_update, train_loss_reset_op):\n",
    "            g.add_to_collection(\"train_loss\", node)\n",
    "        for node in (val_mean_loss, val_mean_loss_update, val_loss_reset_op):\n",
    "            g.add_to_collection(\"val_loss\", node)\n",
    "        for node in (test_mean_loss, test_mean_loss_update, test_loss_reset_op):\n",
    "            g.add_to_collection(\"test_loss\", node)\n",
    "        g.add_to_collection(\"logits\", logits)\n",
    "            \n",
    "        # ===================================== tensorboard\n",
    "        with tf.name_scope(\"tensorboard_writer\") as scope:\n",
    "            epoch_train_loss_scalar = tf.summary.scalar('train_epoch_loss', train_mean_loss)\n",
    "            epoch_train_acc_scalar = tf.summary.scalar('train_epoch_acc', train_acc)\n",
    "            epoch_train_auc_scalar = tf.summary.scalar('train_epoch_auc', train_auc)\n",
    "            epoch_train_write_op = tf.summary.merge([epoch_train_loss_scalar, epoch_train_acc_scalar, epoch_train_auc_scalar], name=\"epoch_train_write_op\")\n",
    "\n",
    "            # ===== epoch, validation\n",
    "            epoch_validation_loss_scalar = tf.summary.scalar('validation_epoch_loss', val_mean_loss)\n",
    "            epoch_validation_acc_scalar = tf.summary.scalar('validation_epoch_acc', val_acc)\n",
    "            epoch_validation_auc_scalar = tf.summary.scalar('validation_epoch_auc', val_auc)\n",
    "            epoch_validation_write_op = tf.summary.merge([epoch_validation_loss_scalar, epoch_validation_acc_scalar, epoch_validation_auc_scalar], name=\"epoch_validation_write_op\")\n",
    "        \n",
    "        for node in (epoch_train_write_op, epoch_validation_write_op):\n",
    "            g.add_to_collection(\"tensorboard\", node)\n",
    "            \n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_graph(g):\n",
    "    global BEST_PARAMS_PATH\n",
    "    saver, init_global, init_local = g.get_collection(\"save_init\")\n",
    "    X, X_reshaped, y, training_op = g.get_collection(\"main_ops\")\n",
    "    preds, y_true_cls, y_pred_cls = g.get_collection(\"preds\")\n",
    "    train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op = g.get_collection(\"train_metrics\")\n",
    "    val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op = g.get_collection(\"val_metrics\")\n",
    "    train_mean_loss, train_mean_loss_update, train_loss_reset_op = g.get_collection(\"train_loss\")\n",
    "    val_mean_loss, val_mean_loss_update, val_loss_reset_op = g.get_collection(\"val_loss\")\n",
    "    epoch_train_write_op, epoch_validation_write_op = g.get_collection(\"tensorboard\")\n",
    "\n",
    "    train_writer = tf.summary.FileWriter(os.path.join(\"tf_logs\",\"train\"))\n",
    "    val_writer = tf.summary.FileWriter(os.path.join(\"tf_logs\",\"validation\"))\n",
    "    \n",
    "    best_val_loss = np.inf\n",
    "    \n",
    "    with tf.Session(graph=g) as sess:\n",
    "        sess.run([init_global, init_local])\n",
    "        \n",
    "        for e in tqdm(range(1,data_params['n_epochs']+1)):\n",
    "            sess.run([val_met_reset_op,val_loss_reset_op,train_met_reset_op,train_loss_reset_op])\n",
    "            \n",
    "            n_batches = int(MNIST.train.num_examples/data_params['batch_size'])\n",
    "            for i in range(1, n_batches+1):\n",
    "                data, target = MNIST.train.next_batch(data_params['batch_size'])\n",
    "                sess.run([training_op, train_auc_update, train_acc_update, train_mean_loss_update], feed_dict={X:data, y:target})\n",
    "        \n",
    "            # write average for epoch\n",
    "            summary = sess.run(epoch_train_write_op)    \n",
    "            train_writer.add_summary(summary, e)\n",
    "            train_writer.flush()\n",
    "\n",
    "            # run validation\n",
    "            n_batches = int(MNIST.validation.num_examples/data_params['batch_size'])\n",
    "            for i in range(1,n_batches+1):\n",
    "                Xb, yb = MNIST.validation.next_batch(data_params['batch_size'])\n",
    "                sess.run([val_auc_update, val_acc_update, val_mean_loss_update], feed_dict={X:data, y:target})\n",
    "\n",
    "            # check for (and save) best validation params here\n",
    "            cur_loss, cur_acc = sess.run([val_mean_loss, val_acc])\n",
    "            if cur_loss < best_val_loss:\n",
    "                best_val_loss = cur_loss\n",
    "                best_params = get_model_params()\n",
    "                save_obj(best_params, BEST_PARAMS_PATH)\n",
    "                print(\"best params saved: acc: {:.3f}% loss: {:.4f}\".format(cur_acc*100, cur_loss))\n",
    "\n",
    "            summary = sess.run(epoch_validation_write_op) \n",
    "            val_writer.add_summary(summary, e)\n",
    "            val_writer.flush()\n",
    "        \n",
    "        train_writer.close()\n",
    "        val_writer.close()\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-f3a74a302cbd>:28: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:54<03:39, 54.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 88.281% loss: 0.3587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 2/5 [01:56<02:54, 58.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 90.625% loss: 0.3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 3/5 [02:56<01:57, 58.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params saved: acc: 96.875% loss: 0.1216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [05:07<00:00, 61.54s/it]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "data_params = create_hyper_params()\n",
    "g = build_graph(data_params)\n",
    "sess = train_graph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "This is a checkpoint - in that training can be skipped if previous best params are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:01<00:00, 58.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 99.426% acc: 91.967% loss: 0.26584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "data_params = create_hyper_params()\n",
    "g2 = build_graph(data_params)\n",
    "best_params = load_obj(BEST_PARAMS_PATH)\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "    X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "    preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "    test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "    test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "    \n",
    "    restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "    sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "    \n",
    "    n_batches = int(MNIST.test.num_examples/data_params['batch_size'])\n",
    "    for i in tqdm(range(n_batches)):\n",
    "        Xb, yb = MNIST.test.next_batch(data_params['batch_size'])\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "    # print\n",
    "    final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "    print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                              final_test_acc*100,\n",
    "                                                              final_test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Sample Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc0ef05668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_idx = 42\n",
    "some_image = MNIST.test.images[some_idx]\n",
    "some_label_enc = MNIST.test.labels[some_idx]\n",
    "some_label_dec = np.argmax(some_label_enc)\n",
    "some_digit_image = some_image.reshape(28, 28)\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does the current architecture classify the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function needs some work, but it currently serves it's purpose\n",
    "def display_figure_and_prob(img, probs, save_path):\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "    ax1.imshow(img, cmap = matplotlib.cm.binary,\n",
    "           interpolation=\"nearest\")\n",
    "    y_pos = np.arange(10)\n",
    "    ax2.bar(y_pos, probs, align='center', alpha=0.5)\n",
    "    plt.title('Confidence')\n",
    "    plt.grid('off')\n",
    "    plt.tight_layout()\n",
    "    save_path = \"./output_images/\" + save_path + \".png\"\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 100.000% acc: 100.000% loss: 0.36743\n",
      "true_class: [3]\n",
      "pred_class [3]\n",
      "confidence: 69.2513%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAEYCAYAAABGExyUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGWQkSVKzDDKSJKlZ/x8W5vDCXjCLCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc042b4f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_model(img, label):\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g2 = build_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g2) as sess:\n",
    "        saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "        X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "        logz = g2.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "        Xb, yb = np.expand_dims(img,0), np.expand_dims(label, 0)\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "        pred_value, true_cls_value, pred_cls_value = sess.run([preds, y_true_cls, y_pred_cls],\n",
    "                                                              feed_dict={X:Xb,y:yb})\n",
    "        logits_val = sess.run([logz], feed_dict={X:Xb,y:yb})[0]\n",
    "        print\n",
    "        final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "        print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                                   final_test_acc*100,\n",
    "                                                                   final_test_loss))\n",
    "        pred_idx = pred_cls_value[0]\n",
    "        print(\"true_class: {}\\npred_class {}\".format(true_cls_value, pred_cls_value))\n",
    "        \n",
    "        confidence = pred_value[0][pred_idx]*100\n",
    "        print(\"confidence: {:.4f}%\".format(confidence))\n",
    "\n",
    "        jack = np.argmax(pred_value[0])\n",
    "        name = \"mnist_\" + str(jack) + \"_conf_\" + str(confidence)\n",
    "        display_figure_and_prob(some_digit_image, pred_value[0], name)\n",
    "        \n",
    "    return pred_idx, confidence\n",
    "        \n",
    "pred_label, pred_confidence = test_model(some_image, some_label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_adv_graph(data_params):\n",
    "    g = tf.Graph()\n",
    "    n_outputs = 10\n",
    "    IMG_HEIGHT = 28\n",
    "    IMG_WIDTH = 28\n",
    "    CHANNELS = 1\n",
    "    with g.as_default():\n",
    "        with tf.name_scope(\"inputs\"):\n",
    "            #X = tf.placeholder(tf.float32, shape=(None, 784), name=\"data\") # Input\n",
    "            #X_reshaped = tf.reshape(X, shape=[-1, IMG_HEIGHT, IMG_WIDTH, CHANNELS])\n",
    "            Xx = tf.Variable(tf.zeros((28, 28, 1)))\n",
    "            Xxx = tf.expand_dims(Xx, 0)\n",
    "            y = tf.placeholder(tf.int32, shape=(None, n_outputs), name=\"labels\") # Target\n",
    "\n",
    "        with tf.name_scope(\"cnn\"):\n",
    "            h_1 = tf.layers.conv2d(Xxx, filters=32, kernel_size=3, activation=tf.nn.relu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_1\")\n",
    "            h_2 = tf.layers.conv2d(h_1, filters=64, kernel_size=3, activation=tf.nn.relu,\n",
    "                                   padding='SAME', strides=1, name=\"conv_2\")\n",
    "            h_3 = tf.layers.conv2d(h_1, filters=36, kernel_size=3, activation=tf.nn.elu,\n",
    "                                   padding='SAME', strides=2, name=\"conv_3\")\n",
    "            h_4 = tf.layers.max_pooling2d(h_3, pool_size=[2,2],\n",
    "                                          strides=2, name=\"max_pool_01\")\n",
    "            last_shape = int(np.prod(h_4.get_shape()[1:]))\n",
    "            h_4_flat = tf.reshape(h_4, shape=[-1, last_shape])\n",
    "            h_5 = tf.layers.dense(h_4_flat, 64, name=\"layer_05\", activation=tf.nn.relu)\n",
    "            logits = tf.layers.dense(h_5, n_outputs, name=\"logits\")\n",
    "\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            xentropy = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "            batch_loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "        \n",
    "        with tf.name_scope(\"train\"):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(data_params['init_lr'])\n",
    "            training_op = optimizer.minimize(batch_loss)\n",
    "            \n",
    "        with tf.name_scope(\"save_session\"):\n",
    "            init_global = tf.global_variables_initializer()\n",
    "            init_local = tf.local_variables_initializer()\n",
    "            saver = tf.train.Saver()\n",
    "        \n",
    "        with tf.name_scope(\"adv\"):\n",
    "            x = tf.placeholder(tf.float32, (28, 28, 1), name=\"jack\") # Input\n",
    "            x_hat = Xx\n",
    "            assign_op = tf.assign(x_hat, x)\n",
    "\n",
    "            y_hat = tf.placeholder(tf.int32, ())\n",
    "            labels = tf.one_hot(y_hat, 10)\n",
    "            loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels, name=\"adv_loss\")\n",
    "            optim_step = tf.train.GradientDescentOptimizer(1e-1).minimize(loss, var_list=[Xx])\n",
    "            \n",
    "            epsilon = tf.placeholder(tf.float32, ())\n",
    "            below = x - epsilon\n",
    "            above = x + epsilon\n",
    "            projected = tf.clip_by_value(tf.clip_by_value(x_hat, below, above), 0, 1)\n",
    "\n",
    "            with tf.control_dependencies([projected]):\n",
    "                project_step = tf.assign(x_hat, projected)\n",
    "                \n",
    "            for node in (assign_op, x, optim_step, loss, y_hat, epsilon, x_hat, project_step):\n",
    "                g.add_to_collection(\"adv\", node)\n",
    "\n",
    "        # Ops: training metrics\n",
    "        with tf.name_scope(\"metrics\"):\n",
    "            # ================================== performance\n",
    "            with tf.name_scope(\"common\"):\n",
    "                preds = tf.nn.softmax(logits, name=\"prediction\")\n",
    "                y_true_cls = tf.argmax(y,1)\n",
    "                y_pred_cls = tf.argmax(preds,1)\n",
    "                correct_prediction = tf.equal(y_pred_cls, y_true_cls, name=\"correct_predictions\")\n",
    "                batch_acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "            with tf.name_scope(\"train_metrics\") as scope:\n",
    "                train_auc, train_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                train_acc, train_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                train_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_met_reset_op = tf.variables_initializer(train_acc_vars, name=\"train_met_reset_op\")\n",
    "            with tf.name_scope(\"val_metrics\") as scope:\n",
    "                val_auc, val_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                val_acc, val_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                val_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_met_reset_op = tf.variables_initializer(val_acc_vars, name=\"val_met_reset_op\")\n",
    "            with tf.name_scope(\"test_metrics\") as scope:\n",
    "                test_auc, test_auc_update = tf.metrics.auc(labels=y, predictions=preds)\n",
    "                test_acc, test_acc_update = tf.metrics.accuracy(labels=y_true_cls, predictions=y_pred_cls)\n",
    "                test_acc_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_acc_reset_op = tf.variables_initializer(test_acc_vars, name=\"test_met_reset_op\")\n",
    "\n",
    "            # =============================================== loss \n",
    "            with tf.name_scope(\"train_loss_eval\") as scope:\n",
    "                train_mean_loss, train_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                train_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                train_loss_reset_op = tf.variables_initializer(train_loss_vars, name=\"train_loss_reset_op\")\n",
    "            with tf.name_scope(\"val_loss_eval\") as scope:\n",
    "                val_mean_loss, val_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                val_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                val_loss_reset_op = tf.variables_initializer(val_loss_vars, name=\"val_loss_reset_op\")\n",
    "            with tf.name_scope(\"test_loss_eval\")as scope:\n",
    "                test_mean_loss, test_mean_loss_update = tf.metrics.mean(batch_loss)\n",
    "                test_loss_vars = tf.contrib.framework.get_variables(scope, collection=tf.GraphKeys.LOCAL_VARIABLES)\n",
    "                test_loss_reset_op = tf.variables_initializer(test_loss_vars, name=\"test_loss_rest_op\")\n",
    "\n",
    "        # --- create collections\n",
    "        for node in (saver, init_global, init_local):\n",
    "            g.add_to_collection(\"save_init\", node)\n",
    "        for node in (X, Xx, y, training_op):\n",
    "            g.add_to_collection(\"main_ops\", node)\n",
    "        for node in (preds, y_true_cls, y_pred_cls):\n",
    "            g.add_to_collection(\"preds\", node)\n",
    "        for node in (train_auc, train_auc_update, train_acc, train_acc_update, train_met_reset_op):\n",
    "            g.add_to_collection(\"train_metrics\", node)\n",
    "        for node in (val_auc, val_auc_update, val_acc, val_acc_update, val_met_reset_op):\n",
    "            g.add_to_collection(\"val_metrics\", node)\n",
    "        for node in (test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op):\n",
    "            g.add_to_collection(\"test_metrics\", node)\n",
    "        for node in (train_mean_loss, train_mean_loss_update, train_loss_reset_op):\n",
    "            g.add_to_collection(\"train_loss\", node)\n",
    "        for node in (val_mean_loss, val_mean_loss_update, val_loss_reset_op):\n",
    "            g.add_to_collection(\"val_loss\", node)\n",
    "        for node in (test_mean_loss, test_mean_loss_update, test_loss_reset_op):\n",
    "            g.add_to_collection(\"test_loss\", node)\n",
    "        g.add_to_collection(\"logits\", logits)\n",
    "            \n",
    "        # ===================================== tensorboard\n",
    "        with tf.name_scope(\"tensorboard_writer\") as scope:\n",
    "            epoch_train_loss_scalar = tf.summary.scalar('train_epoch_loss', train_mean_loss)\n",
    "            epoch_train_acc_scalar = tf.summary.scalar('train_epoch_acc', train_acc)\n",
    "            epoch_train_auc_scalar = tf.summary.scalar('train_epoch_auc', train_auc)\n",
    "            epoch_train_write_op = tf.summary.merge([epoch_train_loss_scalar, epoch_train_acc_scalar, epoch_train_auc_scalar], name=\"epoch_train_write_op\")\n",
    "\n",
    "            # ===== epoch, validation\n",
    "            epoch_validation_loss_scalar = tf.summary.scalar('validation_epoch_loss', val_mean_loss)\n",
    "            epoch_validation_acc_scalar = tf.summary.scalar('validation_epoch_acc', val_acc)\n",
    "            epoch_validation_auc_scalar = tf.summary.scalar('validation_epoch_auc', val_auc)\n",
    "            epoch_validation_write_op = tf.summary.merge([epoch_validation_loss_scalar, epoch_validation_acc_scalar, epoch_validation_auc_scalar], name=\"epoch_validation_write_op\")\n",
    "        \n",
    "        for node in (epoch_train_write_op, epoch_validation_write_op):\n",
    "            g.add_to_collection(\"tensorboard\", node)\n",
    "            \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1083/10000 [00:02<00:20, 440.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1000, loss=0.0790386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2056/10000 [00:04<00:17, 445.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000, loss=0.0788002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3054/10000 [00:06<00:15, 442.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 3000, loss=0.0785734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4059/10000 [00:09<00:13, 442.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 4000, loss=0.0785454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5046/10000 [00:11<00:11, 438.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 5000, loss=0.0785278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6052/10000 [00:13<00:09, 432.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 6000, loss=0.0785159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7049/10000 [00:16<00:06, 434.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 7000, loss=0.0785182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 8070/10000 [00:18<00:04, 436.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 8000, loss=0.0785202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9048/10000 [00:21<00:02, 429.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 9000, loss=0.078514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 426.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10000, loss=0.0785135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def produce_targeted_adv_image(img, adv_target=0,adv_eps=0.07,adv_lr=1e-1,adv_steps=10000):\n",
    "    \n",
    "    #TODO: learning rate is currently hardcoded\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g3 = build_adv_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g3) as sess:\n",
    "        saver, init_global, init_local = g3.get_collection(\"save_init\")\n",
    "        X, Xx, y, training_op = g3.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g3.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g3.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g3.get_collection(\"test_loss\")\n",
    "        logz = g3.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g3, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "\n",
    "        # execution\n",
    "        assign_op, x, optim_step, loss, y_hat, epsilon, x_hat, project_step = g3.get_collection(\"adv\")\n",
    "\n",
    "        # initialization step\n",
    "        sess.run(assign_op, feed_dict={x: img})\n",
    "\n",
    "        # projected gradient descent\n",
    "        for i in tqdm(range(1, adv_steps+1)):\n",
    "            # gradient descent step\n",
    "            _, loss_value = sess.run(\n",
    "                [optim_step, loss],\n",
    "                feed_dict={y_hat: adv_target})\n",
    "            # project step\n",
    "            sess.run(project_step, feed_dict={x: img, epsilon: adv_eps})\n",
    "            if (i+1) % 1000 == 0:\n",
    "                print('step %d, loss=%g' % (i+1, loss_value))\n",
    "\n",
    "        adv_out = x_hat.eval() # retrieve the adversarial example\n",
    "        \n",
    "    return adv_out\n",
    "adv_out = produce_targeted_adv_image(some_image.reshape(28,28,1), adv_target=5)\n",
    "adv_flat = adv_out.reshape((784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test auc: 88.889% acc: 0.000% loss: 2.78591\n",
      "true_class: [3]\n",
      "pred_class [5]\n",
      "confidence: 92.4485%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAEYCAYAAABGExyUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc0f024f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def test_adversarial(img, label):\n",
    "    reset_graph()\n",
    "    data_params = create_hyper_params()\n",
    "    g2 = build_graph(data_params)\n",
    "    best_params = load_obj(BEST_PARAMS_PATH)\n",
    "    with tf.Session(graph=g2) as sess:\n",
    "        saver, init_global, init_local = g2.get_collection(\"save_init\")\n",
    "        X, X_reshaped, y, training_op = g2.get_collection(\"main_ops\")\n",
    "        preds, y_true_cls, y_pred_cls = g2.get_collection(\"preds\")\n",
    "        test_auc, test_auc_update, test_acc, test_acc_update, test_acc_reset_op = g2.get_collection(\"test_metrics\")\n",
    "        test_mean_loss, test_mean_loss_update, test_loss_reset_op = g2.get_collection(\"test_loss\")\n",
    "        logz = g2.get_collection(\"logits\")[0]\n",
    "\n",
    "        sess.run([init_global, init_local])\n",
    "\n",
    "        restore_model_params(model_params=best_params, g=g2, sess=sess)\n",
    "        sess.run([test_acc_reset_op, test_loss_reset_op])\n",
    "        Xb, yb = np.expand_dims(img,0), np.expand_dims(label, 0)\n",
    "        batch_accuracy, batch_loss, batch_auc = sess.run([test_acc_update, test_mean_loss_update, test_auc_update], \n",
    "                                                                  feed_dict={X:Xb,y:yb})\n",
    "        pred_value, true_cls_value, pred_cls_value = sess.run([preds, y_true_cls, y_pred_cls],\n",
    "                                                              feed_dict={X:Xb,y:yb})\n",
    "        logits_val = sess.run([logz], feed_dict={X:Xb,y:yb})[0]\n",
    "\n",
    "        final_test_acc, final_test_loss, final_test_auc = sess.run([test_acc, test_mean_loss, test_auc])\n",
    "        print(\"test auc: {:.3f}% acc: {:.3f}% loss: {:.5f}\".format(final_test_auc*100, \n",
    "                                                                   final_test_acc*100,\n",
    "                                                                   final_test_loss))\n",
    "        pred_idx = pred_cls_value[0]\n",
    "        print(\"true_class: {}\\npred_class {}\".format(true_cls_value, pred_cls_value))\n",
    "        confidence = pred_value[0][pred_idx]*100\n",
    "        print(\"confidence: {:.4f}%\".format(confidence))\n",
    "\n",
    "        jack = np.argmax(pred_value[0])\n",
    "        name = \"mnist_\" + str(jack) + \"_conf_\" + str(confidence) + \"_adv\"\n",
    "        display_figure_and_prob(adv_flat.reshape(28, 28), pred_value[0], name)\n",
    "\n",
    "    return pred_idx, confidence\n",
    "\n",
    "a_pred_label, a_pred_confidence = test_adversarial(adv_flat, some_label_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAAEtCAYAAAAP0yF9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBlQAAAAAUNH/B+gVUlqgqRmQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc0f1e9be0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_adv_array(img, adv, pred_label, pred_confidence, \n",
    "                   a_pred_label, a_pred_confidence):\n",
    "    diff = adv - some_digit_image\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
    "    ax1.imshow(img, cmap = matplotlib.cm.binary,\n",
    "                   interpolation=\"nearest\")\n",
    "    cmapx = plt.get_cmap('bwr')\n",
    "    ax1.set_title(\"Input\")\n",
    "    ax1.set_xlabel(\"Pred: [{}] Confidence: {:.3f}%\".format(pred_label, pred_confidence))\n",
    "    ax2.imshow(diff, cmap = cmapx,\n",
    "                   interpolation=\"nearest\")\n",
    "    ax2.set_title(\"Adversarial Generation: blue:-, red:+\")\n",
    "    ax2.set_xlabel(\"MAX delta: -[{:.4f}] +[{:.4f}]\".format(np.min(diff), np.max(diff)))\n",
    "    ax3.imshow(adv, cmap = matplotlib.cm.binary,\n",
    "                   interpolation=\"nearest\")\n",
    "    ax3.set_title(\"Altered Input\")\n",
    "    ax3.set_xlabel(\"Pred: [{}] Confidence: {:.3f}%\".format(a_pred_label, a_pred_confidence))\n",
    "    plt.grid('off')\n",
    "    plt.tight_layout()\n",
    "    name = \"./output_images/\" + \"adv_array_\" + str(pred_label) + \"_to_\" + str(a_pred_label) + \".png\"\n",
    "    plt.savefig(name, bbox_inches='tight', pad_inches=0, frameon=False)\n",
    "    plt.show()\n",
    "\n",
    "plot_adv_array(some_digit_image, adv_flat.reshape(28, 28), pred_label, pred_confidence, a_pred_label, a_pred_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_edge",
   "language": "python",
   "name": "tf_edge"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
