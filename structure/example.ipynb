{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "No GPU found\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# plotting pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper to make the output consistent\n",
    "SEED = 42\n",
    "def reset_graph(seed=SEED):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# set log level to supress messages, unless an error\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Check TensorFlow version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check if using GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    print('No GPU found')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../mnist_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../mnist_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../mnist_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../mnist_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5c1ca72198>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPxAU4QeCIvxAUIQfCIrwA0ERfiCo/wPa1H0FvypabAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c3e2adc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import dataset (should already be present)\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../mnist_data', validation_size=0)\n",
    "\n",
    "\n",
    "# ------ Make sure we're up and running\n",
    "# display, random, single image\n",
    "img = mnist.train.images[np.random.randint(6000, size=1)]\n",
    "\n",
    "# mnist is 28x28 = 784 and is grayscale\n",
    "# meaning, the 784 vector needs to be reshaped to 28,28\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n",
      "(0,)\n"
     ]
    }
   ],
   "source": [
    "# my validation size is off for some reason.....\n",
    "#  - will use test as validation (becuase we're not actually using this data for anything)\n",
    "print(mnist.train.labels.shape)\n",
    "print(mnist.test.labels.shape)\n",
    "print(mnist.validation.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer() # He initialization\n",
    "#Equivalent to:\n",
    "#he_init = lambda shape, dtype=tf.float32: tf.truncated_normal(shape, 0., stddev=np.sqrt(2/shape[0]))\n",
    "\n",
    "l2_regularizer = tf.contrib.layers.l2_regularizer(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "n_epochs = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "\n",
    "# activation function\n",
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model_params():\n",
    "    gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    return {gvar.op.name: value for gvar, value in zip(gvars, tf.get_default_session().run(gvars))}\n",
    "\n",
    "def restore_model_params(model_params):\n",
    "    gvar_names = list(model_params.keys())\n",
    "    assign_ops = {gvar_name: tf.get_default_graph().get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                  for gvar_name in gvar_names}\n",
    "    init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "    feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "    tf.get_default_session().run(assign_ops, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.984375 test accuracy: 0.9194\n",
      "1 Batch accuracy: 0.9375 test accuracy: 0.9319\n",
      "2 Batch accuracy: 0.921875 test accuracy: 0.9425\n",
      "3 Batch accuracy: 1.0 test accuracy: 0.9455\n",
      "4 Batch accuracy: 0.96875 test accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "means = mnist.train.images.mean(axis=0, keepdims=True)\n",
    "stds = mnist.train.images.std(axis=0, keepdims=True) + 1e-10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 1 == 0:\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            X_val_scaled = (mnist.test.images - means) / stds\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_val_scaled, y: mnist.test.labels})\n",
    "            print(epoch, \"Batch accuracy:\", acc_train, \"test accuracy:\", acc_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
